{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRm-USlsHgEV",
        "outputId": "1492e6ab-b0b7-4853-e3af-5042dd03a89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2503, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 2503 (delta 9), reused 12 (delta 4), pack-reused 2478\u001b[K\n",
            "Receiving objects: 100% (2503/2503), 8.20 MiB | 21.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1567/1567), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1EySlOXwwoa",
        "outputId": "6284f7f3-465a-46d9-92b7-682f3461ce11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.13.0+cu113)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading dominate-2.7.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.17.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 51.4 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 47.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 32.8 MB/s \n",
            "\u001b[?25hCollecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Building wheels for collected packages: visdom, pathtools, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=f03b860a57ba940cae5c2a27830d5d84d1c97bab815e28bea71914d1251c0f7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=74134c2af1c841934cb7ddf70fe6f718a660d0d0a9ddaf0baea37fb35147eade\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=05f10b647c7b4d47d51ead3c036919568e1199532bbae5e4142d5c370d25f873\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom pathtools torchfile\n",
            "Installing collected packages: smmap, jsonpointer, gitdb, websocket-client, torchfile, shortuuid, setproctitle, sentry-sdk, pathtools, jsonpatch, GitPython, docker-pycreds, wandb, visdom, dominate\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 dominate-2.7.0 gitdb-4.0.9 jsonpatch-1.32 jsonpointer-2.3 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.1 shortuuid-1.0.9 smmap-5.0.0 torchfile-0.1.0 visdom-0.1.8.9 wandb-0.13.0 websocket-client-1.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daqlgVhw29P"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Download one of the official datasets with:\n",
        "\n",
        "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
        "\n",
        "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrdOettJxaCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1995c629-cd6c-4054-e165-b5aa489f3a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specified [facades]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2022-08-05 21:58:04--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30168306 (29M) [application/x-gzip]\n",
            "Saving to: ‘./datasets/facades.tar.gz’\n",
            "\n",
            "./datasets/facades. 100%[===================>]  28.77M  4.45MB/s    in 9.8s    \n",
            "\n",
            "2022-08-05 21:58:14 (2.93 MB/s) - ‘./datasets/facades.tar.gz’ saved [30168306/30168306]\n",
            "\n",
            "facades/\n",
            "facades/test/\n",
            "facades/test/27.jpg\n",
            "facades/test/5.jpg\n",
            "facades/test/72.jpg\n",
            "facades/test/1.jpg\n",
            "facades/test/10.jpg\n",
            "facades/test/100.jpg\n",
            "facades/test/101.jpg\n",
            "facades/test/102.jpg\n",
            "facades/test/103.jpg\n",
            "facades/test/104.jpg\n",
            "facades/test/105.jpg\n",
            "facades/test/106.jpg\n",
            "facades/test/11.jpg\n",
            "facades/test/12.jpg\n",
            "facades/test/13.jpg\n",
            "facades/test/14.jpg\n",
            "facades/test/15.jpg\n",
            "facades/test/16.jpg\n",
            "facades/test/17.jpg\n",
            "facades/test/18.jpg\n",
            "facades/test/19.jpg\n",
            "facades/test/2.jpg\n",
            "facades/test/20.jpg\n",
            "facades/test/21.jpg\n",
            "facades/test/22.jpg\n",
            "facades/test/23.jpg\n",
            "facades/test/24.jpg\n",
            "facades/test/25.jpg\n",
            "facades/test/26.jpg\n",
            "facades/test/50.jpg\n",
            "facades/test/51.jpg\n",
            "facades/test/52.jpg\n",
            "facades/test/53.jpg\n",
            "facades/test/54.jpg\n",
            "facades/test/55.jpg\n",
            "facades/test/56.jpg\n",
            "facades/test/57.jpg\n",
            "facades/test/58.jpg\n",
            "facades/test/59.jpg\n",
            "facades/test/6.jpg\n",
            "facades/test/60.jpg\n",
            "facades/test/61.jpg\n",
            "facades/test/62.jpg\n",
            "facades/test/63.jpg\n",
            "facades/test/64.jpg\n",
            "facades/test/65.jpg\n",
            "facades/test/66.jpg\n",
            "facades/test/67.jpg\n",
            "facades/test/68.jpg\n",
            "facades/test/69.jpg\n",
            "facades/test/7.jpg\n",
            "facades/test/70.jpg\n",
            "facades/test/71.jpg\n",
            "facades/test/73.jpg\n",
            "facades/test/74.jpg\n",
            "facades/test/75.jpg\n",
            "facades/test/76.jpg\n",
            "facades/test/77.jpg\n",
            "facades/test/78.jpg\n",
            "facades/test/79.jpg\n",
            "facades/test/8.jpg\n",
            "facades/test/80.jpg\n",
            "facades/test/81.jpg\n",
            "facades/test/82.jpg\n",
            "facades/test/83.jpg\n",
            "facades/test/84.jpg\n",
            "facades/test/85.jpg\n",
            "facades/test/86.jpg\n",
            "facades/test/87.jpg\n",
            "facades/test/88.jpg\n",
            "facades/test/89.jpg\n",
            "facades/test/9.jpg\n",
            "facades/test/90.jpg\n",
            "facades/test/91.jpg\n",
            "facades/test/92.jpg\n",
            "facades/test/93.jpg\n",
            "facades/test/94.jpg\n",
            "facades/test/95.jpg\n",
            "facades/test/96.jpg\n",
            "facades/test/97.jpg\n",
            "facades/test/98.jpg\n",
            "facades/test/99.jpg\n",
            "facades/test/28.jpg\n",
            "facades/test/29.jpg\n",
            "facades/test/3.jpg\n",
            "facades/test/30.jpg\n",
            "facades/test/31.jpg\n",
            "facades/test/32.jpg\n",
            "facades/test/33.jpg\n",
            "facades/test/34.jpg\n",
            "facades/test/35.jpg\n",
            "facades/test/36.jpg\n",
            "facades/test/37.jpg\n",
            "facades/test/38.jpg\n",
            "facades/test/39.jpg\n",
            "facades/test/4.jpg\n",
            "facades/test/40.jpg\n",
            "facades/test/41.jpg\n",
            "facades/test/42.jpg\n",
            "facades/test/43.jpg\n",
            "facades/test/44.jpg\n",
            "facades/test/45.jpg\n",
            "facades/test/46.jpg\n",
            "facades/test/47.jpg\n",
            "facades/test/48.jpg\n",
            "facades/test/49.jpg\n",
            "facades/train/\n",
            "facades/train/1.jpg\n",
            "facades/train/10.jpg\n",
            "facades/train/100.jpg\n",
            "facades/train/101.jpg\n",
            "facades/train/102.jpg\n",
            "facades/train/103.jpg\n",
            "facades/train/104.jpg\n",
            "facades/train/105.jpg\n",
            "facades/train/106.jpg\n",
            "facades/train/107.jpg\n",
            "facades/train/108.jpg\n",
            "facades/train/109.jpg\n",
            "facades/train/11.jpg\n",
            "facades/train/110.jpg\n",
            "facades/train/111.jpg\n",
            "facades/train/112.jpg\n",
            "facades/train/113.jpg\n",
            "facades/train/114.jpg\n",
            "facades/train/115.jpg\n",
            "facades/train/116.jpg\n",
            "facades/train/117.jpg\n",
            "facades/train/118.jpg\n",
            "facades/train/119.jpg\n",
            "facades/train/12.jpg\n",
            "facades/train/120.jpg\n",
            "facades/train/121.jpg\n",
            "facades/train/122.jpg\n",
            "facades/train/123.jpg\n",
            "facades/train/124.jpg\n",
            "facades/train/125.jpg\n",
            "facades/train/126.jpg\n",
            "facades/train/309.jpg\n",
            "facades/train/31.jpg\n",
            "facades/train/310.jpg\n",
            "facades/train/311.jpg\n",
            "facades/train/312.jpg\n",
            "facades/train/313.jpg\n",
            "facades/train/314.jpg\n",
            "facades/train/315.jpg\n",
            "facades/train/316.jpg\n",
            "facades/train/317.jpg\n",
            "facades/train/318.jpg\n",
            "facades/train/319.jpg\n",
            "facades/train/32.jpg\n",
            "facades/train/320.jpg\n",
            "facades/train/321.jpg\n",
            "facades/train/322.jpg\n",
            "facades/train/323.jpg\n",
            "facades/train/324.jpg\n",
            "facades/train/325.jpg\n",
            "facades/train/326.jpg\n",
            "facades/train/327.jpg\n",
            "facades/train/328.jpg\n",
            "facades/train/329.jpg\n",
            "facades/train/390.jpg\n",
            "facades/train/391.jpg\n",
            "facades/train/392.jpg\n",
            "facades/train/393.jpg\n",
            "facades/train/394.jpg\n",
            "facades/train/395.jpg\n",
            "facades/train/396.jpg\n",
            "facades/train/397.jpg\n",
            "facades/train/398.jpg\n",
            "facades/train/399.jpg\n",
            "facades/train/4.jpg\n",
            "facades/train/40.jpg\n",
            "facades/train/400.jpg\n",
            "facades/train/41.jpg\n",
            "facades/train/42.jpg\n",
            "facades/train/43.jpg\n",
            "facades/train/44.jpg\n",
            "facades/train/45.jpg\n",
            "facades/train/46.jpg\n",
            "facades/train/47.jpg\n",
            "facades/train/48.jpg\n",
            "facades/train/49.jpg\n",
            "facades/train/5.jpg\n",
            "facades/train/50.jpg\n",
            "facades/train/51.jpg\n",
            "facades/train/52.jpg\n",
            "facades/train/53.jpg\n",
            "facades/train/54.jpg\n",
            "facades/train/55.jpg\n",
            "facades/train/56.jpg\n",
            "facades/train/57.jpg\n",
            "facades/train/58.jpg\n",
            "facades/train/59.jpg\n",
            "facades/train/6.jpg\n",
            "facades/train/60.jpg\n",
            "facades/train/61.jpg\n",
            "facades/train/222.jpg\n",
            "facades/train/223.jpg\n",
            "facades/train/224.jpg\n",
            "facades/train/225.jpg\n",
            "facades/train/226.jpg\n",
            "facades/train/227.jpg\n",
            "facades/train/228.jpg\n",
            "facades/train/229.jpg\n",
            "facades/train/23.jpg\n",
            "facades/train/230.jpg\n",
            "facades/train/231.jpg\n",
            "facades/train/232.jpg\n",
            "facades/train/233.jpg\n",
            "facades/train/234.jpg\n",
            "facades/train/235.jpg\n",
            "facades/train/236.jpg\n",
            "facades/train/237.jpg\n",
            "facades/train/238.jpg\n",
            "facades/train/239.jpg\n",
            "facades/train/24.jpg\n",
            "facades/train/240.jpg\n",
            "facades/train/241.jpg\n",
            "facades/train/242.jpg\n",
            "facades/train/243.jpg\n",
            "facades/train/244.jpg\n",
            "facades/train/245.jpg\n",
            "facades/train/156.jpg\n",
            "facades/train/157.jpg\n",
            "facades/train/158.jpg\n",
            "facades/train/159.jpg\n",
            "facades/train/16.jpg\n",
            "facades/train/160.jpg\n",
            "facades/train/161.jpg\n",
            "facades/train/162.jpg\n",
            "facades/train/163.jpg\n",
            "facades/train/164.jpg\n",
            "facades/train/165.jpg\n",
            "facades/train/166.jpg\n",
            "facades/train/167.jpg\n",
            "facades/train/168.jpg\n",
            "facades/train/169.jpg\n",
            "facades/train/17.jpg\n",
            "facades/train/170.jpg\n",
            "facades/train/171.jpg\n",
            "facades/train/172.jpg\n",
            "facades/train/173.jpg\n",
            "facades/train/174.jpg\n",
            "facades/train/175.jpg\n",
            "facades/train/176.jpg\n",
            "facades/train/177.jpg\n",
            "facades/train/178.jpg\n",
            "facades/train/179.jpg\n",
            "facades/train/18.jpg\n",
            "facades/train/180.jpg\n",
            "facades/train/181.jpg\n",
            "facades/train/182.jpg\n",
            "facades/train/183.jpg\n",
            "facades/train/184.jpg\n",
            "facades/train/185.jpg\n",
            "facades/train/186.jpg\n",
            "facades/train/187.jpg\n",
            "facades/train/188.jpg\n",
            "facades/train/189.jpg\n",
            "facades/train/19.jpg\n",
            "facades/train/127.jpg\n",
            "facades/train/155.jpg\n",
            "facades/train/190.jpg\n",
            "facades/train/221.jpg\n",
            "facades/train/246.jpg\n",
            "facades/train/27.jpg\n",
            "facades/train/29.jpg\n",
            "facades/train/308.jpg\n",
            "facades/train/33.jpg\n",
            "facades/train/350.jpg\n",
            "facades/train/370.jpg\n",
            "facades/train/39.jpg\n",
            "facades/train/62.jpg\n",
            "facades/train/270.jpg\n",
            "facades/train/271.jpg\n",
            "facades/train/272.jpg\n",
            "facades/train/273.jpg\n",
            "facades/train/274.jpg\n",
            "facades/train/275.jpg\n",
            "facades/train/276.jpg\n",
            "facades/train/277.jpg\n",
            "facades/train/278.jpg\n",
            "facades/train/279.jpg\n",
            "facades/train/28.jpg\n",
            "facades/train/280.jpg\n",
            "facades/train/281.jpg\n",
            "facades/train/282.jpg\n",
            "facades/train/283.jpg\n",
            "facades/train/284.jpg\n",
            "facades/train/285.jpg\n",
            "facades/train/286.jpg\n",
            "facades/train/287.jpg\n",
            "facades/train/288.jpg\n",
            "facades/train/289.jpg\n",
            "facades/train/351.jpg\n",
            "facades/train/352.jpg\n",
            "facades/train/353.jpg\n",
            "facades/train/354.jpg\n",
            "facades/train/355.jpg\n",
            "facades/train/356.jpg\n",
            "facades/train/357.jpg\n",
            "facades/train/358.jpg\n",
            "facades/train/359.jpg\n",
            "facades/train/36.jpg\n",
            "facades/train/360.jpg\n",
            "facades/train/361.jpg\n",
            "facades/train/362.jpg\n",
            "facades/train/363.jpg\n",
            "facades/train/364.jpg\n",
            "facades/train/365.jpg\n",
            "facades/train/366.jpg\n",
            "facades/train/367.jpg\n",
            "facades/train/368.jpg\n",
            "facades/train/369.jpg\n",
            "facades/train/37.jpg\n",
            "facades/train/63.jpg\n",
            "facades/train/64.jpg\n",
            "facades/train/65.jpg\n",
            "facades/train/66.jpg\n",
            "facades/train/67.jpg\n",
            "facades/train/68.jpg\n",
            "facades/train/69.jpg\n",
            "facades/train/7.jpg\n",
            "facades/train/70.jpg\n",
            "facades/train/71.jpg\n",
            "facades/train/72.jpg\n",
            "facades/train/73.jpg\n",
            "facades/train/74.jpg\n",
            "facades/train/75.jpg\n",
            "facades/train/76.jpg\n",
            "facades/train/77.jpg\n",
            "facades/train/78.jpg\n",
            "facades/train/79.jpg\n",
            "facades/train/8.jpg\n",
            "facades/train/80.jpg\n",
            "facades/train/81.jpg\n",
            "facades/train/82.jpg\n",
            "facades/train/83.jpg\n",
            "facades/train/84.jpg\n",
            "facades/train/85.jpg\n",
            "facades/train/86.jpg\n",
            "facades/train/87.jpg\n",
            "facades/train/88.jpg\n",
            "facades/train/89.jpg\n",
            "facades/train/9.jpg\n",
            "facades/train/90.jpg\n",
            "facades/train/91.jpg\n",
            "facades/train/92.jpg\n",
            "facades/train/93.jpg\n",
            "facades/train/94.jpg\n",
            "facades/train/95.jpg\n",
            "facades/train/96.jpg\n",
            "facades/train/97.jpg\n",
            "facades/train/98.jpg\n",
            "facades/train/99.jpg\n",
            "facades/train/128.jpg\n",
            "facades/train/129.jpg\n",
            "facades/train/13.jpg\n",
            "facades/train/130.jpg\n",
            "facades/train/131.jpg\n",
            "facades/train/132.jpg\n",
            "facades/train/133.jpg\n",
            "facades/train/134.jpg\n",
            "facades/train/135.jpg\n",
            "facades/train/136.jpg\n",
            "facades/train/137.jpg\n",
            "facades/train/138.jpg\n",
            "facades/train/139.jpg\n",
            "facades/train/14.jpg\n",
            "facades/train/140.jpg\n",
            "facades/train/141.jpg\n",
            "facades/train/142.jpg\n",
            "facades/train/143.jpg\n",
            "facades/train/144.jpg\n",
            "facades/train/145.jpg\n",
            "facades/train/146.jpg\n",
            "facades/train/147.jpg\n",
            "facades/train/148.jpg\n",
            "facades/train/149.jpg\n",
            "facades/train/15.jpg\n",
            "facades/train/150.jpg\n",
            "facades/train/151.jpg\n",
            "facades/train/152.jpg\n",
            "facades/train/153.jpg\n",
            "facades/train/154.jpg\n",
            "facades/train/191.jpg\n",
            "facades/train/192.jpg\n",
            "facades/train/193.jpg\n",
            "facades/train/194.jpg\n",
            "facades/train/195.jpg\n",
            "facades/train/196.jpg\n",
            "facades/train/197.jpg\n",
            "facades/train/198.jpg\n",
            "facades/train/199.jpg\n",
            "facades/train/2.jpg\n",
            "facades/train/20.jpg\n",
            "facades/train/200.jpg\n",
            "facades/train/201.jpg\n",
            "facades/train/202.jpg\n",
            "facades/train/203.jpg\n",
            "facades/train/204.jpg\n",
            "facades/train/205.jpg\n",
            "facades/train/206.jpg\n",
            "facades/train/207.jpg\n",
            "facades/train/208.jpg\n",
            "facades/train/209.jpg\n",
            "facades/train/21.jpg\n",
            "facades/train/210.jpg\n",
            "facades/train/211.jpg\n",
            "facades/train/212.jpg\n",
            "facades/train/213.jpg\n",
            "facades/train/214.jpg\n",
            "facades/train/215.jpg\n",
            "facades/train/216.jpg\n",
            "facades/train/217.jpg\n",
            "facades/train/218.jpg\n",
            "facades/train/219.jpg\n",
            "facades/train/22.jpg\n",
            "facades/train/220.jpg\n",
            "facades/train/247.jpg\n",
            "facades/train/248.jpg\n",
            "facades/train/249.jpg\n",
            "facades/train/25.jpg\n",
            "facades/train/250.jpg\n",
            "facades/train/251.jpg\n",
            "facades/train/252.jpg\n",
            "facades/train/253.jpg\n",
            "facades/train/254.jpg\n",
            "facades/train/255.jpg\n",
            "facades/train/256.jpg\n",
            "facades/train/257.jpg\n",
            "facades/train/258.jpg\n",
            "facades/train/259.jpg\n",
            "facades/train/26.jpg\n",
            "facades/train/260.jpg\n",
            "facades/train/261.jpg\n",
            "facades/train/262.jpg\n",
            "facades/train/263.jpg\n",
            "facades/train/264.jpg\n",
            "facades/train/265.jpg\n",
            "facades/train/266.jpg\n",
            "facades/train/267.jpg\n",
            "facades/train/268.jpg\n",
            "facades/train/269.jpg\n",
            "facades/train/330.jpg\n",
            "facades/train/331.jpg\n",
            "facades/train/332.jpg\n",
            "facades/train/333.jpg\n",
            "facades/train/334.jpg\n",
            "facades/train/335.jpg\n",
            "facades/train/336.jpg\n",
            "facades/train/337.jpg\n",
            "facades/train/338.jpg\n",
            "facades/train/339.jpg\n",
            "facades/train/34.jpg\n",
            "facades/train/340.jpg\n",
            "facades/train/341.jpg\n",
            "facades/train/342.jpg\n",
            "facades/train/343.jpg\n",
            "facades/train/344.jpg\n",
            "facades/train/345.jpg\n",
            "facades/train/346.jpg\n",
            "facades/train/347.jpg\n",
            "facades/train/348.jpg\n",
            "facades/train/349.jpg\n",
            "facades/train/35.jpg\n",
            "facades/train/290.jpg\n",
            "facades/train/291.jpg\n",
            "facades/train/292.jpg\n",
            "facades/train/293.jpg\n",
            "facades/train/294.jpg\n",
            "facades/train/295.jpg\n",
            "facades/train/296.jpg\n",
            "facades/train/297.jpg\n",
            "facades/train/298.jpg\n",
            "facades/train/299.jpg\n",
            "facades/train/3.jpg\n",
            "facades/train/30.jpg\n",
            "facades/train/300.jpg\n",
            "facades/train/301.jpg\n",
            "facades/train/302.jpg\n",
            "facades/train/303.jpg\n",
            "facades/train/304.jpg\n",
            "facades/train/305.jpg\n",
            "facades/train/306.jpg\n",
            "facades/train/307.jpg\n",
            "facades/train/371.jpg\n",
            "facades/train/372.jpg\n",
            "facades/train/373.jpg\n",
            "facades/train/374.jpg\n",
            "facades/train/375.jpg\n",
            "facades/train/376.jpg\n",
            "facades/train/377.jpg\n",
            "facades/train/378.jpg\n",
            "facades/train/379.jpg\n",
            "facades/train/38.jpg\n",
            "facades/train/380.jpg\n",
            "facades/train/381.jpg\n",
            "facades/train/382.jpg\n",
            "facades/train/383.jpg\n",
            "facades/train/384.jpg\n",
            "facades/train/385.jpg\n",
            "facades/train/386.jpg\n",
            "facades/train/387.jpg\n",
            "facades/train/388.jpg\n",
            "facades/train/389.jpg\n",
            "facades/val/\n",
            "facades/val/30.jpg\n",
            "facades/val/50.jpg\n",
            "facades/val/73.jpg\n",
            "facades/val/1.jpg\n",
            "facades/val/10.jpg\n",
            "facades/val/100.jpg\n",
            "facades/val/11.jpg\n",
            "facades/val/12.jpg\n",
            "facades/val/13.jpg\n",
            "facades/val/14.jpg\n",
            "facades/val/15.jpg\n",
            "facades/val/16.jpg\n",
            "facades/val/17.jpg\n",
            "facades/val/18.jpg\n",
            "facades/val/19.jpg\n",
            "facades/val/2.jpg\n",
            "facades/val/20.jpg\n",
            "facades/val/21.jpg\n",
            "facades/val/22.jpg\n",
            "facades/val/23.jpg\n",
            "facades/val/24.jpg\n",
            "facades/val/25.jpg\n",
            "facades/val/26.jpg\n",
            "facades/val/27.jpg\n",
            "facades/val/28.jpg\n",
            "facades/val/29.jpg\n",
            "facades/val/3.jpg\n",
            "facades/val/51.jpg\n",
            "facades/val/52.jpg\n",
            "facades/val/53.jpg\n",
            "facades/val/54.jpg\n",
            "facades/val/55.jpg\n",
            "facades/val/56.jpg\n",
            "facades/val/57.jpg\n",
            "facades/val/58.jpg\n",
            "facades/val/59.jpg\n",
            "facades/val/6.jpg\n",
            "facades/val/60.jpg\n",
            "facades/val/61.jpg\n",
            "facades/val/62.jpg\n",
            "facades/val/63.jpg\n",
            "facades/val/64.jpg\n",
            "facades/val/65.jpg\n",
            "facades/val/66.jpg\n",
            "facades/val/67.jpg\n",
            "facades/val/68.jpg\n",
            "facades/val/69.jpg\n",
            "facades/val/7.jpg\n",
            "facades/val/70.jpg\n",
            "facades/val/71.jpg\n",
            "facades/val/72.jpg\n",
            "facades/val/74.jpg\n",
            "facades/val/75.jpg\n",
            "facades/val/76.jpg\n",
            "facades/val/77.jpg\n",
            "facades/val/78.jpg\n",
            "facades/val/79.jpg\n",
            "facades/val/8.jpg\n",
            "facades/val/80.jpg\n",
            "facades/val/81.jpg\n",
            "facades/val/82.jpg\n",
            "facades/val/83.jpg\n",
            "facades/val/84.jpg\n",
            "facades/val/85.jpg\n",
            "facades/val/86.jpg\n",
            "facades/val/87.jpg\n",
            "facades/val/88.jpg\n",
            "facades/val/89.jpg\n",
            "facades/val/9.jpg\n",
            "facades/val/90.jpg\n",
            "facades/val/91.jpg\n",
            "facades/val/92.jpg\n",
            "facades/val/93.jpg\n",
            "facades/val/94.jpg\n",
            "facades/val/95.jpg\n",
            "facades/val/96.jpg\n",
            "facades/val/97.jpg\n",
            "facades/val/98.jpg\n",
            "facades/val/99.jpg\n",
            "facades/val/31.jpg\n",
            "facades/val/32.jpg\n",
            "facades/val/33.jpg\n",
            "facades/val/34.jpg\n",
            "facades/val/35.jpg\n",
            "facades/val/36.jpg\n",
            "facades/val/37.jpg\n",
            "facades/val/38.jpg\n",
            "facades/val/39.jpg\n",
            "facades/val/4.jpg\n",
            "facades/val/40.jpg\n",
            "facades/val/41.jpg\n",
            "facades/val/42.jpg\n",
            "facades/val/43.jpg\n",
            "facades/val/44.jpg\n",
            "facades/val/45.jpg\n",
            "facades/val/46.jpg\n",
            "facades/val/47.jpg\n",
            "facades/val/48.jpg\n",
            "facades/val/49.jpg\n",
            "facades/val/5.jpg\n"
          ]
        }
      ],
      "source": [
        "!bash ./datasets/download_pix2pix_dataset.sh facades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdUz4116xhpm"
      },
      "source": [
        "# Pretrained models\n",
        "\n",
        "Download one of the official pretrained models with:\n",
        "\n",
        "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
        "\n",
        "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC2DEP4M0OsS",
        "outputId": "af6c083b-b713-42e9-ac8e-1087d6442df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
            "Specified [facades_label2photo]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2022-08-05 21:58:26--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/facades_label2photo.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217704720 (208M)\n",
            "Saving to: ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/facad 100%[===================>] 207.62M  66.6MB/s    in 3.4s    \n",
            "\n",
            "2022-08-05 21:58:30 (61.0 MB/s) - ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’ saved [217704720/217704720]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!bash ./scripts/download_pix2pix_model.sh facades_label2photo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/feed.zip"
      ],
      "metadata": {
        "id": "qRAyKLShXHw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5fBhniyp_Bi",
        "outputId": "3623a303-ea2d-44cf-f4ee-963aaa112091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff123903-9ea1-4e28-d1e5-7c8ed0b404b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./new_roof/                   \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: BtoA                          \t[default: AtoB]\n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: facades_pix2pix               \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: True                          \t[default: False]\n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "The number of training images = 1000\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "[Network D] Total number of parameters : 2.769 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f7fa939c0d0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7fa939c0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f7fa939c0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/wandb/run-20220805_215951-26jejaw0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfacades_pix2pix\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kshitizkhanal7/CycleGAN-and-pix2pix\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kshitizkhanal7/CycleGAN-and-pix2pix/runs/26jejaw0\u001b[0m\n",
            "create web directory ./checkpoints/facades_pix2pix/web...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "(epoch: 1, iters: 100, time: 0.057, data: 0.238) G_GAN: 3.751 G_L1: 55.110 D_real: 0.031 D_fake: 0.047 \n",
            "(epoch: 1, iters: 200, time: 0.058, data: 0.008) G_GAN: 0.660 G_L1: 3.343 D_real: 0.583 D_fake: 0.613 \n",
            "(epoch: 1, iters: 300, time: 0.059, data: 0.004) G_GAN: 1.188 G_L1: 67.368 D_real: 0.011 D_fake: 0.525 \n",
            "(epoch: 1, iters: 400, time: 0.549, data: 0.002) G_GAN: 1.919 G_L1: 33.901 D_real: 0.010 D_fake: 0.258 \n",
            "(epoch: 1, iters: 500, time: 0.058, data: 0.012) G_GAN: 0.967 G_L1: 24.901 D_real: 0.007 D_fake: 0.577 \n",
            "(epoch: 1, iters: 600, time: 0.059, data: 0.002) G_GAN: 0.627 G_L1: 0.094 D_real: 0.636 D_fake: 0.767 \n",
            "(epoch: 1, iters: 700, time: 0.052, data: 0.006) G_GAN: 0.718 G_L1: 0.044 D_real: 0.688 D_fake: 0.715 \n",
            "(epoch: 1, iters: 800, time: 0.159, data: 0.002) G_GAN: 1.718 G_L1: 72.834 D_real: 0.002 D_fake: 0.286 \n",
            "(epoch: 1, iters: 900, time: 0.060, data: 0.002) G_GAN: 0.633 G_L1: 0.034 D_real: 0.638 D_fake: 0.756 \n",
            "(epoch: 1, iters: 1000, time: 0.056, data: 0.003) G_GAN: 0.778 G_L1: 40.813 D_real: 0.001 D_fake: 0.713 \n",
            "End of epoch 1 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.058, data: 0.155) G_GAN: 0.828 G_L1: 0.073 D_real: 0.850 D_fake: 0.578 \n",
            "(epoch: 2, iters: 200, time: 0.373, data: 0.003) G_GAN: 1.757 G_L1: 74.519 D_real: 0.002 D_fake: 0.319 \n",
            "(epoch: 2, iters: 300, time: 0.059, data: 0.010) G_GAN: 0.669 G_L1: 0.059 D_real: 0.647 D_fake: 0.746 \n",
            "(epoch: 2, iters: 400, time: 0.058, data: 0.006) G_GAN: 1.145 G_L1: 0.042 D_real: 1.695 D_fake: 0.220 \n",
            "(epoch: 2, iters: 500, time: 0.055, data: 0.002) G_GAN: 0.770 G_L1: 0.104 D_real: 1.204 D_fake: 0.377 \n",
            "(epoch: 2, iters: 600, time: 0.161, data: 0.002) G_GAN: 0.729 G_L1: 0.006 D_real: 0.805 D_fake: 0.612 \n",
            "(epoch: 2, iters: 700, time: 0.057, data: 0.005) G_GAN: 1.375 G_L1: 0.020 D_real: 2.399 D_fake: 0.103 \n",
            "(epoch: 2, iters: 800, time: 0.058, data: 0.002) G_GAN: 3.119 G_L1: 197.959 D_real: 0.010 D_fake: 0.059 \n",
            "(epoch: 2, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.939 G_L1: 0.007 D_real: 1.081 D_fake: 0.428 \n",
            "(epoch: 2, iters: 1000, time: 0.236, data: 0.003) G_GAN: 1.774 G_L1: 87.387 D_real: 0.001 D_fake: 0.257 \n",
            "End of epoch 2 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.056, data: 0.203) G_GAN: 2.870 G_L1: 114.615 D_real: 0.001 D_fake: 0.075 \n",
            "(epoch: 3, iters: 200, time: 0.055, data: 0.002) G_GAN: 1.995 G_L1: 43.979 D_real: 0.001 D_fake: 0.190 \n",
            "(epoch: 3, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.682 G_L1: 0.006 D_real: 0.691 D_fake: 0.701 \n",
            "(epoch: 3, iters: 400, time: 0.393, data: 0.006) G_GAN: 0.786 G_L1: 0.002 D_real: 0.778 D_fake: 0.622 \n",
            "(epoch: 3, iters: 500, time: 0.058, data: 0.011) G_GAN: 0.687 G_L1: 0.000 D_real: 0.718 D_fake: 0.690 \n",
            "(epoch: 3, iters: 600, time: 0.058, data: 0.003) G_GAN: 3.009 G_L1: 167.107 D_real: 0.010 D_fake: 0.066 \n",
            "(epoch: 3, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.718 G_L1: 0.004 D_real: 0.769 D_fake: 0.687 \n",
            "(epoch: 3, iters: 800, time: 0.163, data: 0.003) G_GAN: 1.055 G_L1: 78.460 D_real: 0.006 D_fake: 0.602 \n",
            "(epoch: 3, iters: 900, time: 0.058, data: 0.006) G_GAN: 1.112 G_L1: 0.001 D_real: 1.847 D_fake: 0.194 \n",
            "(epoch: 3, iters: 1000, time: 0.057, data: 0.003) G_GAN: 1.628 G_L1: 26.897 D_real: 0.001 D_fake: 0.253 \n",
            "End of epoch 3 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.055, data: 0.172) G_GAN: 1.014 G_L1: 0.001 D_real: 1.252 D_fake: 0.346 \n",
            "(epoch: 4, iters: 200, time: 0.344, data: 0.003) G_GAN: 0.835 G_L1: 0.000 D_real: 0.891 D_fake: 0.530 \n",
            "(epoch: 4, iters: 300, time: 0.059, data: 0.003) G_GAN: 3.781 G_L1: 168.811 D_real: 0.002 D_fake: 0.030 \n",
            "(epoch: 4, iters: 400, time: 0.057, data: 0.002) G_GAN: 0.797 G_L1: 0.010 D_real: 0.811 D_fake: 0.593 \n",
            "(epoch: 4, iters: 500, time: 0.061, data: 0.003) G_GAN: 2.300 G_L1: 80.394 D_real: 0.001 D_fake: 0.186 \n",
            "(epoch: 4, iters: 600, time: 0.162, data: 0.003) G_GAN: 4.738 G_L1: 135.562 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 4, iters: 700, time: 0.058, data: 0.003) G_GAN: 2.736 G_L1: 82.511 D_real: 0.000 D_fake: 0.074 \n",
            "(epoch: 4, iters: 800, time: 0.058, data: 0.004) G_GAN: 0.684 G_L1: 0.003 D_real: 0.720 D_fake: 0.733 \n",
            "(epoch: 4, iters: 900, time: 0.058, data: 0.002) G_GAN: 2.167 G_L1: 47.511 D_real: 0.005 D_fake: 0.182 \n",
            "(epoch: 4, iters: 1000, time: 0.245, data: 0.003) G_GAN: 0.848 G_L1: 0.012 D_real: 1.351 D_fake: 0.309 \n",
            "End of epoch 4 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.053, data: 0.170) G_GAN: 0.855 G_L1: 0.002 D_real: 0.962 D_fake: 0.487 \n",
            "(epoch: 5, iters: 200, time: 0.059, data: 0.003) G_GAN: 0.633 G_L1: 0.000 D_real: 0.597 D_fake: 0.807 \n",
            "(epoch: 5, iters: 300, time: 0.058, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
            "(epoch: 5, iters: 400, time: 0.426, data: 0.003) G_GAN: 0.608 G_L1: 0.001 D_real: 0.526 D_fake: 0.904 \n",
            "(epoch: 5, iters: 500, time: 0.058, data: 0.009) G_GAN: 3.923 G_L1: 143.362 D_real: 0.001 D_fake: 0.026 \n",
            "(epoch: 5, iters: 600, time: 0.055, data: 0.002) G_GAN: 1.363 G_L1: 47.624 D_real: 0.000 D_fake: 0.381 \n",
            "(epoch: 5, iters: 700, time: 0.058, data: 0.003) G_GAN: 2.957 G_L1: 50.046 D_real: 0.001 D_fake: 0.074 \n",
            "(epoch: 5, iters: 800, time: 0.161, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.663 D_fake: 0.733 \n",
            "(epoch: 5, iters: 900, time: 0.055, data: 0.003) G_GAN: 0.675 G_L1: 0.001 D_real: 0.673 D_fake: 0.719 \n",
            "(epoch: 5, iters: 1000, time: 0.058, data: 0.005) G_GAN: 1.601 G_L1: 20.844 D_real: 0.000 D_fake: 0.297 \n",
            "saving the latest model (epoch 5, total_iters 5000)\n",
            "saving the model at the end of epoch 5, iters 5000\n",
            "End of epoch 5 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.058, data: 0.258) G_GAN: 3.823 G_L1: 155.598 D_real: 0.001 D_fake: 0.031 \n",
            "(epoch: 6, iters: 200, time: 0.408, data: 0.006) G_GAN: 0.771 G_L1: 0.001 D_real: 0.781 D_fake: 0.632 \n",
            "(epoch: 6, iters: 300, time: 0.066, data: 0.004) G_GAN: 0.938 G_L1: 0.001 D_real: 0.988 D_fake: 0.472 \n",
            "(epoch: 6, iters: 400, time: 0.059, data: 0.003) G_GAN: 2.518 G_L1: 116.177 D_real: 0.000 D_fake: 0.103 \n",
            "(epoch: 6, iters: 500, time: 0.058, data: 0.002) G_GAN: 1.697 G_L1: 74.522 D_real: 0.000 D_fake: 0.245 \n",
            "(epoch: 6, iters: 600, time: 0.171, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.838 D_fake: 0.576 \n",
            "(epoch: 6, iters: 700, time: 0.058, data: 0.007) G_GAN: 1.094 G_L1: 73.488 D_real: 0.000 D_fake: 0.567 \n",
            "(epoch: 6, iters: 800, time: 0.059, data: 0.002) G_GAN: 1.522 G_L1: 56.578 D_real: 0.000 D_fake: 0.342 \n",
            "(epoch: 6, iters: 900, time: 0.059, data: 0.003) G_GAN: 1.048 G_L1: 0.000 D_real: 1.295 D_fake: 0.333 \n",
            "(epoch: 6, iters: 1000, time: 0.253, data: 0.006) G_GAN: 1.337 G_L1: 67.219 D_real: 0.000 D_fake: 0.496 \n",
            "End of epoch 6 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.059, data: 0.233) G_GAN: 1.042 G_L1: 0.000 D_real: 1.264 D_fake: 0.353 \n",
            "(epoch: 7, iters: 200, time: 0.059, data: 0.003) G_GAN: 1.653 G_L1: 30.397 D_real: 0.000 D_fake: 0.243 \n",
            "(epoch: 7, iters: 300, time: 0.056, data: 0.003) G_GAN: 1.201 G_L1: 47.825 D_real: 1.237 D_fake: 0.402 \n",
            "(epoch: 7, iters: 400, time: 0.455, data: 0.003) G_GAN: 3.106 G_L1: 141.558 D_real: 0.002 D_fake: 0.049 \n",
            "(epoch: 7, iters: 500, time: 0.053, data: 0.015) G_GAN: 2.003 G_L1: 112.982 D_real: 0.001 D_fake: 0.178 \n",
            "(epoch: 7, iters: 600, time: 0.057, data: 0.002) G_GAN: 1.399 G_L1: 40.751 D_real: 0.001 D_fake: 0.356 \n",
            "(epoch: 7, iters: 700, time: 0.051, data: 0.003) G_GAN: 2.156 G_L1: 35.423 D_real: 0.001 D_fake: 0.149 \n",
            "(epoch: 7, iters: 800, time: 0.168, data: 0.003) G_GAN: 0.724 G_L1: 0.000 D_real: 0.763 D_fake: 0.642 \n",
            "(epoch: 7, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.719 D_fake: 0.672 \n",
            "(epoch: 7, iters: 1000, time: 0.059, data: 0.003) G_GAN: 0.973 G_L1: 0.000 D_real: 1.042 D_fake: 0.445 \n",
            "End of epoch 7 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.059, data: 0.185) G_GAN: 0.711 G_L1: 0.001 D_real: 0.764 D_fake: 0.639 \n",
            "(epoch: 8, iters: 200, time: 0.390, data: 0.002) G_GAN: 2.250 G_L1: 32.204 D_real: 0.001 D_fake: 0.142 \n",
            "(epoch: 8, iters: 300, time: 0.060, data: 0.008) G_GAN: 4.894 G_L1: 119.996 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 8, iters: 400, time: 0.058, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.799 D_fake: 0.606 \n",
            "(epoch: 8, iters: 500, time: 0.063, data: 0.003) G_GAN: 4.147 G_L1: 137.316 D_real: 0.000 D_fake: 0.020 \n",
            "(epoch: 8, iters: 600, time: 0.161, data: 0.002) G_GAN: 0.722 G_L1: 0.004 D_real: 0.743 D_fake: 0.648 \n",
            "(epoch: 8, iters: 700, time: 0.059, data: 0.008) G_GAN: 1.807 G_L1: 64.296 D_real: 0.000 D_fake: 0.289 \n",
            "(epoch: 8, iters: 800, time: 0.059, data: 0.003) G_GAN: 0.648 G_L1: 0.000 D_real: 0.609 D_fake: 0.799 \n",
            "(epoch: 8, iters: 900, time: 0.059, data: 0.002) G_GAN: 3.640 G_L1: 194.042 D_real: 0.003 D_fake: 0.030 \n",
            "(epoch: 8, iters: 1000, time: 0.250, data: 0.002) G_GAN: 0.826 G_L1: 0.000 D_real: 0.853 D_fake: 0.564 \n",
            "End of epoch 8 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.061, data: 0.159) G_GAN: 3.061 G_L1: 46.513 D_real: 0.000 D_fake: 0.065 \n",
            "(epoch: 9, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.755 G_L1: 0.000 D_real: 0.772 D_fake: 0.628 \n",
            "(epoch: 9, iters: 300, time: 0.059, data: 0.003) G_GAN: 2.999 G_L1: 110.782 D_real: 0.000 D_fake: 0.056 \n",
            "(epoch: 9, iters: 400, time: 0.381, data: 0.003) G_GAN: 0.868 G_L1: 0.000 D_real: 0.946 D_fake: 0.502 \n",
            "(epoch: 9, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.989 G_L1: 0.018 D_real: 1.158 D_fake: 0.383 \n",
            "(epoch: 9, iters: 600, time: 0.059, data: 0.002) G_GAN: 0.867 G_L1: 0.000 D_real: 1.009 D_fake: 0.466 \n",
            "(epoch: 9, iters: 700, time: 0.059, data: 0.004) G_GAN: 0.746 G_L1: 0.000 D_real: 0.778 D_fake: 0.619 \n",
            "(epoch: 9, iters: 800, time: 0.178, data: 0.002) G_GAN: 4.841 G_L1: 88.705 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 9, iters: 900, time: 0.056, data: 0.009) G_GAN: 0.920 G_L1: 0.000 D_real: 0.976 D_fake: 0.501 \n",
            "(epoch: 9, iters: 1000, time: 0.058, data: 0.005) G_GAN: 0.838 G_L1: 0.000 D_real: 0.832 D_fake: 0.576 \n",
            "End of epoch 9 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.056, data: 0.178) G_GAN: 0.825 G_L1: 0.000 D_real: 0.883 D_fake: 0.549 \n",
            "(epoch: 10, iters: 200, time: 0.404, data: 0.003) G_GAN: 4.933 G_L1: 160.205 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 10, iters: 300, time: 0.061, data: 0.005) G_GAN: 1.024 G_L1: 0.000 D_real: 1.170 D_fake: 0.377 \n",
            "(epoch: 10, iters: 400, time: 0.064, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.762 D_fake: 0.632 \n",
            "(epoch: 10, iters: 500, time: 0.056, data: 0.002) G_GAN: 2.374 G_L1: 44.832 D_real: 0.000 D_fake: 0.121 \n",
            "(epoch: 10, iters: 600, time: 0.164, data: 0.003) G_GAN: 5.127 G_L1: 140.727 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 10, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.753 D_fake: 0.644 \n",
            "(epoch: 10, iters: 800, time: 0.057, data: 0.002) G_GAN: 1.433 G_L1: 0.000 D_real: 2.066 D_fake: 0.148 \n",
            "(epoch: 10, iters: 900, time: 0.053, data: 0.003) G_GAN: 0.772 G_L1: 0.000 D_real: 0.810 D_fake: 0.592 \n",
            "(epoch: 10, iters: 1000, time: 0.243, data: 0.003) G_GAN: 5.338 G_L1: 140.873 D_real: 0.000 D_fake: 0.006 \n",
            "saving the latest model (epoch 10, total_iters 10000)\n",
            "saving the model at the end of epoch 10, iters 10000\n",
            "End of epoch 10 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.059, data: 0.172) G_GAN: 4.453 G_L1: 151.232 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 11, iters: 200, time: 0.059, data: 0.002) G_GAN: 0.621 G_L1: 0.000 D_real: 0.607 D_fake: 0.799 \n",
            "(epoch: 11, iters: 300, time: 0.057, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.784 D_fake: 0.615 \n",
            "(epoch: 11, iters: 400, time: 0.427, data: 0.002) G_GAN: 1.653 G_L1: 11.885 D_real: 0.001 D_fake: 0.268 \n",
            "(epoch: 11, iters: 500, time: 0.055, data: 0.008) G_GAN: 3.090 G_L1: 82.299 D_real: 0.000 D_fake: 0.053 \n",
            "(epoch: 11, iters: 600, time: 0.057, data: 0.002) G_GAN: 0.788 G_L1: 0.000 D_real: 0.849 D_fake: 0.570 \n",
            "(epoch: 11, iters: 700, time: 0.059, data: 0.005) G_GAN: 0.783 G_L1: 0.000 D_real: 0.793 D_fake: 0.632 \n",
            "(epoch: 11, iters: 800, time: 0.163, data: 0.002) G_GAN: 3.215 G_L1: 26.704 D_real: 0.000 D_fake: 0.049 \n",
            "(epoch: 11, iters: 900, time: 0.056, data: 0.002) G_GAN: 4.087 G_L1: 77.844 D_real: 0.000 D_fake: 0.020 \n",
            "(epoch: 11, iters: 1000, time: 0.059, data: 0.003) G_GAN: 2.247 G_L1: 108.961 D_real: 0.000 D_fake: 0.143 \n",
            "End of epoch 11 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.056, data: 0.160) G_GAN: 4.443 G_L1: 81.915 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 12, iters: 200, time: 0.403, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.699 D_fake: 0.690 \n",
            "(epoch: 12, iters: 300, time: 0.060, data: 0.003) G_GAN: 5.110 G_L1: 109.879 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 12, iters: 400, time: 0.058, data: 0.002) G_GAN: 1.043 G_L1: 0.000 D_real: 1.739 D_fake: 0.203 \n",
            "(epoch: 12, iters: 500, time: 0.059, data: 0.002) G_GAN: 2.448 G_L1: 56.501 D_real: 0.000 D_fake: 0.112 \n",
            "(epoch: 12, iters: 600, time: 0.170, data: 0.003) G_GAN: 0.736 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
            "(epoch: 12, iters: 700, time: 0.056, data: 0.008) G_GAN: 0.636 G_L1: 0.000 D_real: 0.622 D_fake: 0.777 \n",
            "(epoch: 12, iters: 800, time: 0.060, data: 0.003) G_GAN: 0.791 G_L1: 0.000 D_real: 0.822 D_fake: 0.590 \n",
            "(epoch: 12, iters: 900, time: 0.057, data: 0.002) G_GAN: 2.779 G_L1: 26.975 D_real: 0.000 D_fake: 0.091 \n",
            "(epoch: 12, iters: 1000, time: 0.250, data: 0.003) G_GAN: 2.342 G_L1: 100.104 D_real: 0.000 D_fake: 0.162 \n",
            "End of epoch 12 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.057, data: 0.159) G_GAN: 0.692 G_L1: 0.000 D_real: 0.702 D_fake: 0.690 \n",
            "(epoch: 13, iters: 200, time: 0.055, data: 0.003) G_GAN: 0.980 G_L1: 1.885 D_real: 0.001 D_fake: 0.537 \n",
            "(epoch: 13, iters: 300, time: 0.057, data: 0.004) G_GAN: 0.783 G_L1: 0.000 D_real: 0.867 D_fake: 0.555 \n",
            "(epoch: 13, iters: 400, time: 0.404, data: 0.002) G_GAN: 1.520 G_L1: 0.389 D_real: 0.017 D_fake: 0.354 \n",
            "(epoch: 13, iters: 500, time: 0.053, data: 0.003) G_GAN: 0.656 G_L1: 0.000 D_real: 0.623 D_fake: 0.780 \n",
            "(epoch: 13, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.783 G_L1: 0.000 D_real: 0.856 D_fake: 0.561 \n",
            "(epoch: 13, iters: 700, time: 0.056, data: 0.003) G_GAN: 5.318 G_L1: 139.577 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 13, iters: 800, time: 0.164, data: 0.004) G_GAN: 0.748 G_L1: 0.000 D_real: 0.853 D_fake: 0.563 \n",
            "(epoch: 13, iters: 900, time: 0.056, data: 0.003) G_GAN: 1.282 G_L1: 4.977 D_real: 0.001 D_fake: 0.387 \n",
            "(epoch: 13, iters: 1000, time: 0.059, data: 0.003) G_GAN: 4.562 G_L1: 101.929 D_real: 0.000 D_fake: 0.013 \n",
            "End of epoch 13 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.059, data: 0.190) G_GAN: 0.940 G_L1: 0.000 D_real: 1.311 D_fake: 0.326 \n",
            "(epoch: 14, iters: 200, time: 0.411, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.650 D_fake: 0.760 \n",
            "(epoch: 14, iters: 300, time: 0.054, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.802 D_fake: 0.628 \n",
            "(epoch: 14, iters: 400, time: 0.058, data: 0.002) G_GAN: 1.924 G_L1: 77.355 D_real: 0.000 D_fake: 0.253 \n",
            "(epoch: 14, iters: 500, time: 0.059, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
            "(epoch: 14, iters: 600, time: 0.173, data: 0.002) G_GAN: 4.766 G_L1: 134.081 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 14, iters: 700, time: 0.060, data: 0.003) G_GAN: 6.083 G_L1: 127.452 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 14, iters: 800, time: 0.057, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.823 D_fake: 0.585 \n",
            "(epoch: 14, iters: 900, time: 0.056, data: 0.002) G_GAN: 2.076 G_L1: 42.485 D_real: 0.000 D_fake: 0.174 \n",
            "(epoch: 14, iters: 1000, time: 0.235, data: 0.002) G_GAN: 0.642 G_L1: 0.000 D_real: 0.641 D_fake: 0.764 \n",
            "End of epoch 14 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.058, data: 0.169) G_GAN: 2.782 G_L1: 49.677 D_real: 0.000 D_fake: 0.077 \n",
            "(epoch: 15, iters: 200, time: 0.059, data: 0.004) G_GAN: 0.849 G_L1: 0.000 D_real: 0.885 D_fake: 0.539 \n",
            "(epoch: 15, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.987 G_L1: 0.000 D_real: 1.091 D_fake: 0.419 \n",
            "(epoch: 15, iters: 400, time: 0.501, data: 0.002) G_GAN: 0.664 G_L1: 0.000 D_real: 0.676 D_fake: 0.725 \n",
            "(epoch: 15, iters: 500, time: 0.064, data: 0.003) G_GAN: 1.685 G_L1: 0.000 D_real: 2.532 D_fake: 0.088 \n",
            "(epoch: 15, iters: 600, time: 0.058, data: 0.004) G_GAN: 1.985 G_L1: 22.136 D_real: 0.000 D_fake: 0.197 \n",
            "(epoch: 15, iters: 700, time: 0.057, data: 0.003) G_GAN: 1.007 G_L1: 0.000 D_real: 1.407 D_fake: 0.315 \n",
            "(epoch: 15, iters: 800, time: 0.165, data: 0.003) G_GAN: 0.784 G_L1: 0.000 D_real: 0.836 D_fake: 0.576 \n",
            "(epoch: 15, iters: 900, time: 0.055, data: 0.010) G_GAN: 1.015 G_L1: 4.434 D_real: 0.000 D_fake: 0.580 \n",
            "(epoch: 15, iters: 1000, time: 0.059, data: 0.003) G_GAN: 0.748 G_L1: 0.000 D_real: 0.777 D_fake: 0.635 \n",
            "saving the latest model (epoch 15, total_iters 15000)\n",
            "saving the model at the end of epoch 15, iters 15000\n",
            "End of epoch 15 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.056, data: 0.226) G_GAN: 0.912 G_L1: 2.523 D_real: 0.001 D_fake: 0.672 \n",
            "(epoch: 16, iters: 200, time: 0.432, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.814 D_fake: 0.615 \n",
            "(epoch: 16, iters: 300, time: 0.060, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.716 D_fake: 0.678 \n",
            "(epoch: 16, iters: 400, time: 0.057, data: 0.003) G_GAN: 3.362 G_L1: 84.913 D_real: 0.000 D_fake: 0.045 \n",
            "(epoch: 16, iters: 500, time: 0.061, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.794 D_fake: 0.607 \n",
            "(epoch: 16, iters: 600, time: 0.166, data: 0.004) G_GAN: 4.586 G_L1: 77.820 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 16, iters: 700, time: 0.057, data: 0.003) G_GAN: 3.649 G_L1: 178.367 D_real: 0.000 D_fake: 0.032 \n",
            "(epoch: 16, iters: 800, time: 0.056, data: 0.003) G_GAN: 1.898 G_L1: 38.930 D_real: 0.000 D_fake: 0.201 \n",
            "(epoch: 16, iters: 900, time: 0.055, data: 0.004) G_GAN: 1.212 G_L1: 0.405 D_real: 0.002 D_fake: 0.638 \n",
            "(epoch: 16, iters: 1000, time: 0.270, data: 0.004) G_GAN: 2.162 G_L1: 4.426 D_real: 0.001 D_fake: 0.157 \n",
            "End of epoch 16 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.056, data: 0.202) G_GAN: 0.674 G_L1: 0.000 D_real: 0.666 D_fake: 0.726 \n",
            "(epoch: 17, iters: 200, time: 0.054, data: 0.004) G_GAN: 0.657 G_L1: 0.000 D_real: 0.718 D_fake: 0.699 \n",
            "(epoch: 17, iters: 300, time: 0.059, data: 0.003) G_GAN: 4.697 G_L1: 156.160 D_real: 0.001 D_fake: 0.010 \n",
            "(epoch: 17, iters: 400, time: 0.431, data: 0.003) G_GAN: 3.071 G_L1: 40.867 D_real: 0.000 D_fake: 0.058 \n",
            "(epoch: 17, iters: 500, time: 0.056, data: 0.005) G_GAN: 0.657 G_L1: 0.000 D_real: 0.666 D_fake: 0.735 \n",
            "(epoch: 17, iters: 600, time: 0.055, data: 0.007) G_GAN: 0.667 G_L1: 0.000 D_real: 0.659 D_fake: 0.732 \n",
            "(epoch: 17, iters: 700, time: 0.056, data: 0.003) G_GAN: 1.731 G_L1: 4.751 D_real: 0.001 D_fake: 0.238 \n",
            "(epoch: 17, iters: 800, time: 0.161, data: 0.012) G_GAN: 4.990 G_L1: 75.507 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 17, iters: 900, time: 0.057, data: 0.011) G_GAN: 0.706 G_L1: 0.000 D_real: 0.704 D_fake: 0.686 \n",
            "(epoch: 17, iters: 1000, time: 0.056, data: 0.002) G_GAN: 4.824 G_L1: 111.648 D_real: 0.000 D_fake: 0.010 \n",
            "End of epoch 17 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.053, data: 0.205) G_GAN: 1.681 G_L1: 137.822 D_real: 0.000 D_fake: 0.257 \n",
            "(epoch: 18, iters: 200, time: 0.421, data: 0.003) G_GAN: 4.883 G_L1: 108.535 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 18, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.815 G_L1: 0.000 D_real: 0.917 D_fake: 0.533 \n",
            "(epoch: 18, iters: 400, time: 0.056, data: 0.004) G_GAN: 5.153 G_L1: 98.510 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 18, iters: 500, time: 0.054, data: 0.003) G_GAN: 1.061 G_L1: 0.000 D_real: 1.322 D_fake: 0.315 \n",
            "(epoch: 18, iters: 600, time: 0.166, data: 0.002) G_GAN: 0.853 G_L1: 0.000 D_real: 0.985 D_fake: 0.475 \n",
            "(epoch: 18, iters: 700, time: 0.058, data: 0.020) G_GAN: 0.787 G_L1: 0.000 D_real: 0.834 D_fake: 0.574 \n",
            "(epoch: 18, iters: 800, time: 0.056, data: 0.003) G_GAN: 4.500 G_L1: 151.287 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 18, iters: 900, time: 0.053, data: 0.003) G_GAN: 3.551 G_L1: 67.607 D_real: 0.000 D_fake: 0.031 \n",
            "(epoch: 18, iters: 1000, time: 0.284, data: 0.003) G_GAN: 0.614 G_L1: 0.000 D_real: 0.600 D_fake: 0.801 \n",
            "End of epoch 18 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.056, data: 0.190) G_GAN: 2.824 G_L1: 61.977 D_real: 0.000 D_fake: 0.075 \n",
            "(epoch: 19, iters: 200, time: 0.056, data: 0.002) G_GAN: 5.171 G_L1: 120.219 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 19, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 1.066 D_fake: 0.430 \n",
            "(epoch: 19, iters: 400, time: 0.416, data: 0.002) G_GAN: 0.847 G_L1: 0.000 D_real: 0.966 D_fake: 0.484 \n",
            "(epoch: 19, iters: 500, time: 0.058, data: 0.003) G_GAN: 1.543 G_L1: 88.309 D_real: 0.000 D_fake: 0.351 \n",
            "(epoch: 19, iters: 600, time: 0.057, data: 0.003) G_GAN: 5.059 G_L1: 74.313 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 19, iters: 700, time: 0.056, data: 0.004) G_GAN: 0.682 G_L1: 0.000 D_real: 0.669 D_fake: 0.731 \n",
            "(epoch: 19, iters: 800, time: 0.158, data: 0.003) G_GAN: 5.428 G_L1: 146.202 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 19, iters: 900, time: 0.056, data: 0.014) G_GAN: 2.096 G_L1: 19.747 D_real: 0.000 D_fake: 0.197 \n",
            "(epoch: 19, iters: 1000, time: 0.058, data: 0.005) G_GAN: 0.705 G_L1: 0.000 D_real: 0.707 D_fake: 0.684 \n",
            "End of epoch 19 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.058, data: 0.164) G_GAN: 0.596 G_L1: 0.000 D_real: 0.569 D_fake: 0.842 \n",
            "(epoch: 20, iters: 200, time: 0.428, data: 0.003) G_GAN: 2.292 G_L1: 134.295 D_real: 0.000 D_fake: 0.141 \n",
            "(epoch: 20, iters: 300, time: 0.062, data: 0.003) G_GAN: 0.628 G_L1: 0.000 D_real: 0.615 D_fake: 0.787 \n",
            "(epoch: 20, iters: 400, time: 0.056, data: 0.004) G_GAN: 0.841 G_L1: 0.000 D_real: 1.029 D_fake: 0.473 \n",
            "(epoch: 20, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.782 D_fake: 0.663 \n",
            "(epoch: 20, iters: 600, time: 0.161, data: 0.003) G_GAN: 4.609 G_L1: 200.000 D_real: 0.003 D_fake: 0.012 \n",
            "(epoch: 20, iters: 700, time: 0.056, data: 0.003) G_GAN: 0.811 G_L1: 0.000 D_real: 0.852 D_fake: 0.562 \n",
            "(epoch: 20, iters: 800, time: 0.052, data: 0.003) G_GAN: 0.661 G_L1: 0.000 D_real: 0.639 D_fake: 0.762 \n",
            "(epoch: 20, iters: 900, time: 0.052, data: 0.003) G_GAN: 0.603 G_L1: 0.000 D_real: 0.603 D_fake: 0.798 \n",
            "(epoch: 20, iters: 1000, time: 0.503, data: 0.002) G_GAN: 4.582 G_L1: 106.006 D_real: 0.000 D_fake: 0.010 \n",
            "saving the latest model (epoch 20, total_iters 20000)\n",
            "saving the model at the end of epoch 20, iters 20000\n",
            "End of epoch 20 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.060, data: 0.222) G_GAN: 2.653 G_L1: 52.990 D_real: 0.000 D_fake: 0.062 \n",
            "(epoch: 21, iters: 200, time: 0.055, data: 0.002) G_GAN: 0.658 G_L1: 0.000 D_real: 0.647 D_fake: 0.749 \n",
            "(epoch: 21, iters: 300, time: 0.057, data: 0.004) G_GAN: 2.464 G_L1: 24.700 D_real: 0.000 D_fake: 0.120 \n",
            "(epoch: 21, iters: 400, time: 0.569, data: 0.003) G_GAN: 4.556 G_L1: 142.496 D_real: 0.000 D_fake: 0.014 \n",
            "(epoch: 21, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.936 D_fake: 0.504 \n",
            "(epoch: 21, iters: 600, time: 0.056, data: 0.003) G_GAN: 1.123 G_L1: 0.000 D_real: 1.492 D_fake: 0.268 \n",
            "(epoch: 21, iters: 700, time: 0.056, data: 0.003) G_GAN: 4.876 G_L1: 143.127 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 21, iters: 800, time: 0.179, data: 0.003) G_GAN: 0.676 G_L1: 0.000 D_real: 0.667 D_fake: 0.723 \n",
            "(epoch: 21, iters: 900, time: 0.057, data: 0.012) G_GAN: 0.770 G_L1: 0.000 D_real: 0.822 D_fake: 0.594 \n",
            "(epoch: 21, iters: 1000, time: 0.056, data: 0.003) G_GAN: 1.979 G_L1: 7.001 D_real: 0.001 D_fake: 0.224 \n",
            "End of epoch 21 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.057, data: 0.183) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.651 \n",
            "(epoch: 22, iters: 200, time: 0.557, data: 0.003) G_GAN: 0.740 G_L1: 0.000 D_real: 0.775 D_fake: 0.620 \n",
            "(epoch: 22, iters: 300, time: 0.057, data: 0.011) G_GAN: 6.806 G_L1: 143.457 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 22, iters: 400, time: 0.056, data: 0.004) G_GAN: 2.652 G_L1: 23.065 D_real: 0.000 D_fake: 0.098 \n",
            "(epoch: 22, iters: 500, time: 0.056, data: 0.004) G_GAN: 3.700 G_L1: 30.285 D_real: 0.000 D_fake: 0.036 \n",
            "(epoch: 22, iters: 600, time: 0.177, data: 0.002) G_GAN: 4.210 G_L1: 108.961 D_real: 0.000 D_fake: 0.018 \n",
            "(epoch: 22, iters: 700, time: 0.057, data: 0.022) G_GAN: 0.704 G_L1: 0.000 D_real: 0.701 D_fake: 0.689 \n",
            "(epoch: 22, iters: 800, time: 0.057, data: 0.004) G_GAN: 0.722 G_L1: 0.000 D_real: 0.734 D_fake: 0.671 \n",
            "(epoch: 22, iters: 900, time: 0.057, data: 0.003) G_GAN: 0.597 G_L1: 0.000 D_real: 0.690 D_fake: 0.780 \n",
            "(epoch: 22, iters: 1000, time: 0.428, data: 0.003) G_GAN: 2.679 G_L1: 170.821 D_real: 0.000 D_fake: 0.102 \n",
            "End of epoch 22 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.058, data: 0.192) G_GAN: 1.050 G_L1: 2.982 D_real: 0.001 D_fake: 0.605 \n",
            "(epoch: 23, iters: 200, time: 0.056, data: 0.003) G_GAN: 0.658 G_L1: 0.000 D_real: 0.632 D_fake: 0.760 \n",
            "(epoch: 23, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.821 G_L1: 0.000 D_real: 1.187 D_fake: 0.371 \n",
            "(epoch: 23, iters: 400, time: 0.567, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.742 D_fake: 0.653 \n",
            "(epoch: 23, iters: 500, time: 0.055, data: 0.006) G_GAN: 3.613 G_L1: 35.741 D_real: 0.000 D_fake: 0.032 \n",
            "(epoch: 23, iters: 600, time: 0.054, data: 0.003) G_GAN: 3.427 G_L1: 88.556 D_real: 0.000 D_fake: 0.017 \n",
            "(epoch: 23, iters: 700, time: 0.055, data: 0.002) G_GAN: 4.372 G_L1: 87.373 D_real: 0.000 D_fake: 0.014 \n",
            "(epoch: 23, iters: 800, time: 0.178, data: 0.003) G_GAN: 2.628 G_L1: 13.932 D_real: 0.000 D_fake: 0.091 \n",
            "(epoch: 23, iters: 900, time: 0.056, data: 0.007) G_GAN: 0.869 G_L1: 0.000 D_real: 0.880 D_fake: 0.547 \n",
            "(epoch: 23, iters: 1000, time: 0.059, data: 0.002) G_GAN: 2.863 G_L1: 44.255 D_real: 0.000 D_fake: 0.069 \n",
            "End of epoch 23 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.059, data: 0.173) G_GAN: 1.945 G_L1: 36.261 D_real: 0.000 D_fake: 0.234 \n",
            "(epoch: 24, iters: 200, time: 0.588, data: 0.004) G_GAN: 0.706 G_L1: 0.000 D_real: 0.699 D_fake: 0.695 \n",
            "(epoch: 24, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.719 D_fake: 0.673 \n",
            "(epoch: 24, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.874 G_L1: 0.000 D_real: 0.939 D_fake: 0.530 \n",
            "(epoch: 24, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.718 D_fake: 0.676 \n",
            "(epoch: 24, iters: 600, time: 0.190, data: 0.003) G_GAN: 2.799 G_L1: 26.552 D_real: 0.000 D_fake: 0.078 \n",
            "(epoch: 24, iters: 700, time: 0.058, data: 0.016) G_GAN: 3.629 G_L1: 159.327 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 24, iters: 800, time: 0.058, data: 0.002) G_GAN: 4.869 G_L1: 142.628 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 24, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.816 G_L1: 0.000 D_real: 0.811 D_fake: 0.597 \n",
            "(epoch: 24, iters: 1000, time: 0.448, data: 0.002) G_GAN: 0.865 G_L1: 0.000 D_real: 1.257 D_fake: 0.343 \n",
            "End of epoch 24 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.058, data: 0.197) G_GAN: 2.516 G_L1: 7.053 D_real: 0.000 D_fake: 0.107 \n",
            "(epoch: 25, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.564 G_L1: 0.000 D_real: 0.580 D_fake: 0.860 \n",
            "(epoch: 25, iters: 300, time: 0.057, data: 0.002) G_GAN: 3.172 G_L1: 200.000 D_real: 0.000 D_fake: 0.050 \n",
            "(epoch: 25, iters: 400, time: 0.652, data: 0.003) G_GAN: 0.784 G_L1: 0.000 D_real: 0.803 D_fake: 0.602 \n",
            "(epoch: 25, iters: 500, time: 0.055, data: 0.005) G_GAN: 1.012 G_L1: 1.107 D_real: 0.001 D_fake: 0.640 \n",
            "(epoch: 25, iters: 600, time: 0.054, data: 0.003) G_GAN: 0.825 G_L1: 0.000 D_real: 0.901 D_fake: 0.535 \n",
            "(epoch: 25, iters: 700, time: 0.060, data: 0.002) G_GAN: 4.277 G_L1: 70.828 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 25, iters: 800, time: 0.177, data: 0.005) G_GAN: 0.760 G_L1: 0.000 D_real: 0.815 D_fake: 0.597 \n",
            "(epoch: 25, iters: 900, time: 0.056, data: 0.007) G_GAN: 0.701 G_L1: 0.000 D_real: 0.691 D_fake: 0.700 \n",
            "(epoch: 25, iters: 1000, time: 0.058, data: 0.004) G_GAN: 0.691 G_L1: 0.000 D_real: 0.675 D_fake: 0.723 \n",
            "saving the latest model (epoch 25, total_iters 25000)\n",
            "saving the model at the end of epoch 25, iters 25000\n",
            "End of epoch 25 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.059, data: 0.232) G_GAN: 0.676 G_L1: 0.000 D_real: 0.676 D_fake: 0.716 \n",
            "(epoch: 26, iters: 200, time: 0.611, data: 0.003) G_GAN: 0.688 G_L1: 0.000 D_real: 0.685 D_fake: 0.704 \n",
            "(epoch: 26, iters: 300, time: 0.055, data: 0.004) G_GAN: 2.435 G_L1: 138.997 D_real: 0.000 D_fake: 0.116 \n",
            "(epoch: 26, iters: 400, time: 0.055, data: 0.003) G_GAN: 3.724 G_L1: 47.359 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 26, iters: 500, time: 0.057, data: 0.005) G_GAN: 1.550 G_L1: 5.527 D_real: 0.000 D_fake: 0.297 \n",
            "(epoch: 26, iters: 600, time: 0.192, data: 0.002) G_GAN: 5.667 G_L1: 95.486 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 26, iters: 700, time: 0.056, data: 0.019) G_GAN: 0.683 G_L1: 0.000 D_real: 0.667 D_fake: 0.728 \n",
            "(epoch: 26, iters: 800, time: 0.065, data: 0.003) G_GAN: 0.510 G_L1: 0.000 D_real: 0.492 D_fake: 0.986 \n",
            "(epoch: 26, iters: 900, time: 0.062, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 1.026 D_fake: 0.454 \n",
            "(epoch: 26, iters: 1000, time: 0.483, data: 0.003) G_GAN: 0.610 G_L1: 0.000 D_real: 0.596 D_fake: 0.825 \n",
            "End of epoch 26 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.054, data: 0.225) G_GAN: 6.235 G_L1: 90.431 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 27, iters: 200, time: 0.055, data: 0.003) G_GAN: 0.690 G_L1: 0.000 D_real: 0.671 D_fake: 0.719 \n",
            "(epoch: 27, iters: 300, time: 0.052, data: 0.002) G_GAN: 0.834 G_L1: 0.000 D_real: 0.892 D_fake: 0.531 \n",
            "(epoch: 27, iters: 400, time: 0.619, data: 0.003) G_GAN: 0.632 G_L1: 0.000 D_real: 0.646 D_fake: 0.750 \n",
            "(epoch: 27, iters: 500, time: 0.058, data: 0.004) G_GAN: 0.655 G_L1: 0.000 D_real: 0.646 D_fake: 0.744 \n",
            "(epoch: 27, iters: 600, time: 0.056, data: 0.003) G_GAN: 0.806 G_L1: 0.000 D_real: 1.075 D_fake: 0.438 \n",
            "(epoch: 27, iters: 700, time: 0.054, data: 0.003) G_GAN: 0.776 G_L1: 0.000 D_real: 0.776 D_fake: 0.625 \n",
            "(epoch: 27, iters: 800, time: 0.172, data: 0.003) G_GAN: 0.833 G_L1: 0.000 D_real: 0.865 D_fake: 0.553 \n",
            "(epoch: 27, iters: 900, time: 0.063, data: 0.004) G_GAN: 0.787 G_L1: 0.000 D_real: 0.815 D_fake: 0.603 \n",
            "(epoch: 27, iters: 1000, time: 0.059, data: 0.004) G_GAN: 0.778 G_L1: 0.000 D_real: 0.838 D_fake: 0.572 \n",
            "End of epoch 27 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.055, data: 0.246) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.678 \n",
            "(epoch: 28, iters: 200, time: 0.621, data: 0.002) G_GAN: 3.155 G_L1: 21.972 D_real: 0.000 D_fake: 0.056 \n",
            "(epoch: 28, iters: 300, time: 0.050, data: 0.006) G_GAN: 0.738 G_L1: 0.000 D_real: 0.756 D_fake: 0.646 \n",
            "(epoch: 28, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
            "(epoch: 28, iters: 500, time: 0.048, data: 0.003) G_GAN: 5.129 G_L1: 200.000 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 28, iters: 600, time: 0.161, data: 0.002) G_GAN: 2.307 G_L1: 34.303 D_real: 0.000 D_fake: 0.139 \n",
            "(epoch: 28, iters: 700, time: 0.055, data: 0.005) G_GAN: 0.780 G_L1: 0.000 D_real: 0.820 D_fake: 0.586 \n",
            "(epoch: 28, iters: 800, time: 0.053, data: 0.003) G_GAN: 3.034 G_L1: 140.913 D_real: 0.000 D_fake: 0.064 \n",
            "(epoch: 28, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.786 G_L1: 0.000 D_real: 0.873 D_fake: 0.547 \n",
            "(epoch: 28, iters: 1000, time: 0.346, data: 0.004) G_GAN: 3.059 G_L1: 84.232 D_real: 0.000 D_fake: 0.085 \n",
            "End of epoch 28 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.058, data: 0.232) G_GAN: 1.874 G_L1: 32.214 D_real: 0.000 D_fake: 0.316 \n",
            "(epoch: 29, iters: 200, time: 0.055, data: 0.003) G_GAN: 0.635 G_L1: 0.000 D_real: 0.625 D_fake: 0.769 \n",
            "(epoch: 29, iters: 300, time: 0.056, data: 0.003) G_GAN: 1.640 G_L1: 54.695 D_real: 0.000 D_fake: 0.294 \n",
            "(epoch: 29, iters: 400, time: 0.464, data: 0.004) G_GAN: 0.680 G_L1: 0.000 D_real: 0.674 D_fake: 0.715 \n",
            "(epoch: 29, iters: 500, time: 0.056, data: 0.003) G_GAN: 1.972 G_L1: 10.153 D_real: 0.000 D_fake: 0.175 \n",
            "(epoch: 29, iters: 600, time: 0.057, data: 0.005) G_GAN: 0.624 G_L1: 0.000 D_real: 0.585 D_fake: 0.819 \n",
            "(epoch: 29, iters: 700, time: 0.057, data: 0.002) G_GAN: 6.165 G_L1: 149.550 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 29, iters: 800, time: 0.175, data: 0.002) G_GAN: 2.950 G_L1: 57.098 D_real: 0.000 D_fake: 0.064 \n",
            "(epoch: 29, iters: 900, time: 0.053, data: 0.004) G_GAN: 0.687 G_L1: 0.000 D_real: 0.681 D_fake: 0.712 \n",
            "(epoch: 29, iters: 1000, time: 0.057, data: 0.002) G_GAN: 4.821 G_L1: 60.491 D_real: 0.000 D_fake: 0.011 \n",
            "End of epoch 29 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.057, data: 0.247) G_GAN: 0.816 G_L1: 0.000 D_real: 0.897 D_fake: 0.532 \n",
            "(epoch: 30, iters: 200, time: 0.479, data: 0.003) G_GAN: 5.021 G_L1: 77.954 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 30, iters: 300, time: 0.056, data: 0.003) G_GAN: 3.141 G_L1: 56.501 D_real: 0.000 D_fake: 0.057 \n",
            "(epoch: 30, iters: 400, time: 0.056, data: 0.002) G_GAN: 2.904 G_L1: 15.810 D_real: 0.000 D_fake: 0.064 \n",
            "(epoch: 30, iters: 500, time: 0.059, data: 0.003) G_GAN: 3.246 G_L1: 52.153 D_real: 0.000 D_fake: 0.040 \n",
            "(epoch: 30, iters: 600, time: 0.167, data: 0.002) G_GAN: 3.848 G_L1: 10.433 D_real: 0.001 D_fake: 0.028 \n",
            "(epoch: 30, iters: 700, time: 0.055, data: 0.005) G_GAN: 0.736 G_L1: 0.000 D_real: 0.767 D_fake: 0.629 \n",
            "(epoch: 30, iters: 800, time: 0.056, data: 0.005) G_GAN: 5.843 G_L1: 105.153 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 30, iters: 900, time: 0.054, data: 0.003) G_GAN: 1.301 G_L1: 0.000 D_real: 2.111 D_fake: 0.169 \n",
            "(epoch: 30, iters: 1000, time: 0.351, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.679 \n",
            "saving the latest model (epoch 30, total_iters 30000)\n",
            "saving the model at the end of epoch 30, iters 30000\n",
            "End of epoch 30 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.057, data: 0.210) G_GAN: 0.899 G_L1: 4.651 D_real: 0.000 D_fake: 0.687 \n",
            "(epoch: 31, iters: 200, time: 0.055, data: 0.002) G_GAN: 3.366 G_L1: 80.118 D_real: 0.000 D_fake: 0.039 \n",
            "(epoch: 31, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.724 G_L1: 0.000 D_real: 0.775 D_fake: 0.626 \n",
            "(epoch: 31, iters: 400, time: 0.751, data: 0.003) G_GAN: 0.660 G_L1: 0.000 D_real: 0.653 D_fake: 0.741 \n",
            "(epoch: 31, iters: 500, time: 0.054, data: 0.003) G_GAN: 3.605 G_L1: 58.994 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 31, iters: 600, time: 0.054, data: 0.002) G_GAN: 3.157 G_L1: 18.045 D_real: 0.000 D_fake: 0.050 \n",
            "(epoch: 31, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
            "(epoch: 31, iters: 800, time: 0.177, data: 0.002) G_GAN: 5.357 G_L1: 63.102 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 31, iters: 900, time: 0.053, data: 0.007) G_GAN: 3.553 G_L1: 46.800 D_real: 0.000 D_fake: 0.039 \n",
            "(epoch: 31, iters: 1000, time: 0.057, data: 0.008) G_GAN: 0.824 G_L1: 0.000 D_real: 1.039 D_fake: 0.446 \n",
            "End of epoch 31 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.053, data: 0.192) G_GAN: 0.733 G_L1: 0.000 D_real: 0.751 D_fake: 0.644 \n",
            "(epoch: 32, iters: 200, time: 0.650, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.752 D_fake: 0.644 \n",
            "(epoch: 32, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.586 G_L1: 0.000 D_real: 0.563 D_fake: 0.849 \n",
            "(epoch: 32, iters: 400, time: 0.054, data: 0.004) G_GAN: 0.774 G_L1: 0.000 D_real: 0.791 D_fake: 0.612 \n",
            "(epoch: 32, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.690 G_L1: 0.000 D_real: 0.678 D_fake: 0.717 \n",
            "(epoch: 32, iters: 600, time: 0.189, data: 0.002) G_GAN: 0.969 G_L1: 1.821 D_real: 0.001 D_fake: 0.592 \n",
            "(epoch: 32, iters: 700, time: 0.058, data: 0.003) G_GAN: 1.392 G_L1: 2.900 D_real: 0.000 D_fake: 0.382 \n",
            "(epoch: 32, iters: 800, time: 0.051, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.694 D_fake: 0.707 \n",
            "(epoch: 32, iters: 900, time: 0.054, data: 0.006) G_GAN: 0.839 G_L1: 0.000 D_real: 0.895 D_fake: 0.540 \n",
            "(epoch: 32, iters: 1000, time: 0.538, data: 0.003) G_GAN: 0.819 G_L1: 0.000 D_real: 1.204 D_fake: 0.364 \n",
            "End of epoch 32 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.057, data: 0.244) G_GAN: 0.667 G_L1: 0.000 D_real: 0.662 D_fake: 0.731 \n",
            "(epoch: 33, iters: 200, time: 0.056, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.663 D_fake: 0.729 \n",
            "(epoch: 33, iters: 300, time: 0.053, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.681 D_fake: 0.712 \n",
            "(epoch: 33, iters: 400, time: 0.672, data: 0.004) G_GAN: 2.627 G_L1: 52.465 D_real: 0.000 D_fake: 0.095 \n",
            "(epoch: 33, iters: 500, time: 0.058, data: 0.006) G_GAN: 0.702 G_L1: 0.000 D_real: 0.714 D_fake: 0.682 \n",
            "(epoch: 33, iters: 600, time: 0.055, data: 0.006) G_GAN: 5.229 G_L1: 83.257 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 33, iters: 700, time: 0.056, data: 0.003) G_GAN: 0.710 G_L1: 0.000 D_real: 0.724 D_fake: 0.675 \n",
            "(epoch: 33, iters: 800, time: 0.180, data: 0.004) G_GAN: 0.746 G_L1: 0.000 D_real: 0.778 D_fake: 0.620 \n",
            "(epoch: 33, iters: 900, time: 0.055, data: 0.002) G_GAN: 0.830 G_L1: 0.000 D_real: 0.906 D_fake: 0.522 \n",
            "(epoch: 33, iters: 1000, time: 0.058, data: 0.004) G_GAN: 5.677 G_L1: 101.027 D_real: 0.000 D_fake: 0.005 \n",
            "End of epoch 33 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.055, data: 0.187) G_GAN: 2.378 G_L1: 122.185 D_real: 0.000 D_fake: 0.132 \n",
            "(epoch: 34, iters: 200, time: 0.678, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.772 D_fake: 0.624 \n",
            "(epoch: 34, iters: 300, time: 0.052, data: 0.003) G_GAN: 0.952 G_L1: 5.981 D_real: 0.000 D_fake: 0.590 \n",
            "(epoch: 34, iters: 400, time: 0.055, data: 0.003) G_GAN: 0.834 G_L1: 0.000 D_real: 0.870 D_fake: 0.554 \n",
            "(epoch: 34, iters: 500, time: 0.054, data: 0.003) G_GAN: 3.076 G_L1: 41.610 D_real: 0.000 D_fake: 0.061 \n",
            "(epoch: 34, iters: 600, time: 0.176, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.706 \n",
            "(epoch: 34, iters: 700, time: 0.054, data: 0.004) G_GAN: 1.804 G_L1: 34.815 D_real: 0.000 D_fake: 0.232 \n",
            "(epoch: 34, iters: 800, time: 0.058, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.727 D_fake: 0.663 \n",
            "(epoch: 34, iters: 900, time: 0.057, data: 0.003) G_GAN: 0.668 G_L1: 0.000 D_real: 0.694 D_fake: 0.705 \n",
            "(epoch: 34, iters: 1000, time: 0.340, data: 0.004) G_GAN: 0.667 G_L1: 0.000 D_real: 0.673 D_fake: 0.724 \n",
            "End of epoch 34 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.058, data: 0.191) G_GAN: 3.338 G_L1: 18.125 D_real: 0.000 D_fake: 0.049 \n",
            "(epoch: 35, iters: 200, time: 0.060, data: 0.006) G_GAN: 0.698 G_L1: 0.000 D_real: 0.758 D_fake: 0.650 \n",
            "(epoch: 35, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.725 D_fake: 0.672 \n",
            "(epoch: 35, iters: 400, time: 0.485, data: 0.003) G_GAN: 0.815 G_L1: 0.000 D_real: 0.788 D_fake: 0.615 \n",
            "(epoch: 35, iters: 500, time: 0.058, data: 0.003) G_GAN: 6.925 G_L1: 144.065 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 35, iters: 600, time: 0.054, data: 0.003) G_GAN: 0.673 G_L1: 0.000 D_real: 0.674 D_fake: 0.721 \n",
            "(epoch: 35, iters: 700, time: 0.059, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.796 D_fake: 0.608 \n",
            "(epoch: 35, iters: 800, time: 0.168, data: 0.003) G_GAN: 0.805 G_L1: 0.000 D_real: 0.888 D_fake: 0.536 \n",
            "(epoch: 35, iters: 900, time: 0.057, data: 0.003) G_GAN: 1.154 G_L1: 8.467 D_real: 0.000 D_fake: 0.579 \n",
            "(epoch: 35, iters: 1000, time: 0.056, data: 0.003) G_GAN: 2.353 G_L1: 172.817 D_real: 0.000 D_fake: 0.137 \n",
            "saving the latest model (epoch 35, total_iters 35000)\n",
            "saving the model at the end of epoch 35, iters 35000\n",
            "End of epoch 35 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.055, data: 0.246) G_GAN: 0.885 G_L1: 0.000 D_real: 1.178 D_fake: 0.406 \n",
            "(epoch: 36, iters: 200, time: 0.482, data: 0.004) G_GAN: 7.656 G_L1: 137.491 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 36, iters: 300, time: 0.059, data: 0.003) G_GAN: 2.311 G_L1: 46.076 D_real: 0.000 D_fake: 0.146 \n",
            "(epoch: 36, iters: 400, time: 0.058, data: 0.002) G_GAN: 3.542 G_L1: 26.552 D_real: 0.000 D_fake: 0.037 \n",
            "(epoch: 36, iters: 500, time: 0.061, data: 0.006) G_GAN: 0.681 G_L1: 0.000 D_real: 0.683 D_fake: 0.708 \n",
            "(epoch: 36, iters: 600, time: 0.170, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.793 D_fake: 0.609 \n",
            "(epoch: 36, iters: 700, time: 0.057, data: 0.007) G_GAN: 0.779 G_L1: 0.000 D_real: 0.852 D_fake: 0.563 \n",
            "(epoch: 36, iters: 800, time: 0.055, data: 0.004) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
            "(epoch: 36, iters: 900, time: 0.059, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.677 D_fake: 0.712 \n",
            "(epoch: 36, iters: 1000, time: 0.352, data: 0.003) G_GAN: 1.050 G_L1: 0.000 D_real: 1.412 D_fake: 0.289 \n",
            "End of epoch 36 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.059, data: 0.223) G_GAN: 0.768 G_L1: 0.000 D_real: 0.784 D_fake: 0.617 \n",
            "(epoch: 37, iters: 200, time: 0.059, data: 0.005) G_GAN: 0.662 G_L1: 0.000 D_real: 0.640 D_fake: 0.764 \n",
            "(epoch: 37, iters: 300, time: 0.057, data: 0.002) G_GAN: 2.929 G_L1: 23.990 D_real: 0.000 D_fake: 0.067 \n",
            "(epoch: 37, iters: 400, time: 0.484, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.755 D_fake: 0.641 \n",
            "(epoch: 37, iters: 500, time: 0.059, data: 0.003) G_GAN: 4.279 G_L1: 76.973 D_real: 0.000 D_fake: 0.017 \n",
            "(epoch: 37, iters: 600, time: 0.059, data: 0.002) G_GAN: 0.636 G_L1: 0.000 D_real: 0.647 D_fake: 0.752 \n",
            "(epoch: 37, iters: 700, time: 0.056, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
            "(epoch: 37, iters: 800, time: 0.155, data: 0.003) G_GAN: 5.574 G_L1: 60.752 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 37, iters: 900, time: 0.059, data: 0.003) G_GAN: 6.497 G_L1: 86.761 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 37, iters: 1000, time: 0.057, data: 0.002) G_GAN: 4.573 G_L1: 80.388 D_real: 0.000 D_fake: 0.012 \n",
            "End of epoch 37 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.056, data: 0.203) G_GAN: 0.677 G_L1: 0.000 D_real: 0.667 D_fake: 0.726 \n",
            "(epoch: 38, iters: 200, time: 0.497, data: 0.003) G_GAN: 2.440 G_L1: 68.771 D_real: 0.000 D_fake: 0.166 \n",
            "(epoch: 38, iters: 300, time: 0.058, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.820 D_fake: 0.585 \n",
            "(epoch: 38, iters: 400, time: 0.056, data: 0.003) G_GAN: 0.804 G_L1: 0.000 D_real: 0.856 D_fake: 0.577 \n",
            "(epoch: 38, iters: 500, time: 0.058, data: 0.002) G_GAN: 7.565 G_L1: 138.481 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 38, iters: 600, time: 0.164, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.722 D_fake: 0.672 \n",
            "(epoch: 38, iters: 700, time: 0.058, data: 0.014) G_GAN: 5.874 G_L1: 73.393 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 38, iters: 800, time: 0.057, data: 0.002) G_GAN: 7.402 G_L1: 116.452 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 38, iters: 900, time: 0.053, data: 0.002) G_GAN: 6.685 G_L1: 108.371 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 38, iters: 1000, time: 0.381, data: 0.006) G_GAN: 0.708 G_L1: 0.000 D_real: 0.725 D_fake: 0.682 \n",
            "End of epoch 38 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.058, data: 0.186) G_GAN: 0.647 G_L1: 0.000 D_real: 0.698 D_fake: 0.711 \n",
            "(epoch: 39, iters: 200, time: 0.056, data: 0.002) G_GAN: 1.664 G_L1: 14.940 D_real: 0.000 D_fake: 0.292 \n",
            "(epoch: 39, iters: 300, time: 0.061, data: 0.002) G_GAN: 6.130 G_L1: 115.629 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 39, iters: 400, time: 0.561, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.712 D_fake: 0.680 \n",
            "(epoch: 39, iters: 500, time: 0.054, data: 0.003) G_GAN: 0.690 G_L1: 0.000 D_real: 0.701 D_fake: 0.691 \n",
            "(epoch: 39, iters: 600, time: 0.058, data: 0.005) G_GAN: 5.523 G_L1: 115.968 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 39, iters: 700, time: 0.062, data: 0.002) G_GAN: 0.864 G_L1: 0.000 D_real: 1.208 D_fake: 0.368 \n",
            "(epoch: 39, iters: 800, time: 0.164, data: 0.003) G_GAN: 0.672 G_L1: 0.000 D_real: 0.664 D_fake: 0.728 \n",
            "(epoch: 39, iters: 900, time: 0.059, data: 0.004) G_GAN: 0.766 G_L1: 0.000 D_real: 0.807 D_fake: 0.597 \n",
            "(epoch: 39, iters: 1000, time: 0.058, data: 0.003) G_GAN: 3.790 G_L1: 51.192 D_real: 0.000 D_fake: 0.025 \n",
            "End of epoch 39 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.060, data: 0.198) G_GAN: 0.647 G_L1: 0.000 D_real: 0.627 D_fake: 0.774 \n",
            "(epoch: 40, iters: 200, time: 0.603, data: 0.006) G_GAN: 7.059 G_L1: 92.271 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 40, iters: 300, time: 0.056, data: 0.005) G_GAN: 3.777 G_L1: 41.251 D_real: 0.000 D_fake: 0.025 \n",
            "(epoch: 40, iters: 400, time: 0.059, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.714 D_fake: 0.679 \n",
            "(epoch: 40, iters: 500, time: 0.053, data: 0.003) G_GAN: 0.759 G_L1: 0.000 D_real: 1.268 D_fake: 0.345 \n",
            "(epoch: 40, iters: 600, time: 0.164, data: 0.003) G_GAN: 5.216 G_L1: 76.971 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 40, iters: 700, time: 0.061, data: 0.002) G_GAN: 3.361 G_L1: 33.637 D_real: 0.000 D_fake: 0.043 \n",
            "(epoch: 40, iters: 800, time: 0.058, data: 0.004) G_GAN: 0.655 G_L1: 0.000 D_real: 0.655 D_fake: 0.754 \n",
            "(epoch: 40, iters: 900, time: 0.059, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.758 D_fake: 0.647 \n",
            "(epoch: 40, iters: 1000, time: 0.370, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.620 D_fake: 0.780 \n",
            "saving the latest model (epoch 40, total_iters 40000)\n",
            "saving the model at the end of epoch 40, iters 40000\n",
            "End of epoch 40 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.058, data: 0.188) G_GAN: 1.202 G_L1: 4.462 D_real: 0.000 D_fake: 0.460 \n",
            "(epoch: 41, iters: 200, time: 0.059, data: 0.002) G_GAN: 0.642 G_L1: 0.000 D_real: 0.663 D_fake: 0.729 \n",
            "(epoch: 41, iters: 300, time: 0.055, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.810 D_fake: 0.609 \n",
            "(epoch: 41, iters: 400, time: 0.473, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
            "(epoch: 41, iters: 500, time: 0.059, data: 0.005) G_GAN: 0.708 G_L1: 0.000 D_real: 0.722 D_fake: 0.674 \n",
            "(epoch: 41, iters: 600, time: 0.056, data: 0.002) G_GAN: 0.856 G_L1: 0.000 D_real: 0.936 D_fake: 0.506 \n",
            "(epoch: 41, iters: 700, time: 0.050, data: 0.003) G_GAN: 5.038 G_L1: 22.927 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 41, iters: 800, time: 0.177, data: 0.003) G_GAN: 5.270 G_L1: 50.747 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 41, iters: 900, time: 0.058, data: 0.009) G_GAN: 0.567 G_L1: 0.000 D_real: 0.527 D_fake: 0.913 \n",
            "(epoch: 41, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.653 G_L1: 0.000 D_real: 0.645 D_fake: 0.749 \n",
            "End of epoch 41 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.059, data: 0.190) G_GAN: 0.727 G_L1: 0.000 D_real: 0.778 D_fake: 0.624 \n",
            "(epoch: 42, iters: 200, time: 0.489, data: 0.003) G_GAN: 0.834 G_L1: 0.000 D_real: 1.063 D_fake: 0.432 \n",
            "(epoch: 42, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.936 G_L1: 0.000 D_real: 1.171 D_fake: 0.381 \n",
            "(epoch: 42, iters: 400, time: 0.059, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.762 D_fake: 0.639 \n",
            "(epoch: 42, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.630 G_L1: 0.000 D_real: 0.610 D_fake: 0.794 \n",
            "(epoch: 42, iters: 600, time: 0.166, data: 0.005) G_GAN: 4.352 G_L1: 29.805 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 42, iters: 700, time: 0.059, data: 0.012) G_GAN: 0.797 G_L1: 0.000 D_real: 0.869 D_fake: 0.549 \n",
            "(epoch: 42, iters: 800, time: 0.059, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.707 D_fake: 0.683 \n",
            "(epoch: 42, iters: 900, time: 0.056, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.768 D_fake: 0.629 \n",
            "(epoch: 42, iters: 1000, time: 0.381, data: 0.003) G_GAN: 1.781 G_L1: 11.613 D_real: 0.000 D_fake: 0.326 \n",
            "End of epoch 42 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.059, data: 0.225) G_GAN: 0.649 G_L1: 0.000 D_real: 0.624 D_fake: 0.772 \n",
            "(epoch: 43, iters: 200, time: 0.055, data: 0.003) G_GAN: 2.934 G_L1: 49.439 D_real: 0.000 D_fake: 0.068 \n",
            "(epoch: 43, iters: 300, time: 0.055, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.756 D_fake: 0.640 \n",
            "(epoch: 43, iters: 400, time: 0.500, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.743 D_fake: 0.658 \n",
            "(epoch: 43, iters: 500, time: 0.058, data: 0.004) G_GAN: 0.756 G_L1: 0.000 D_real: 0.776 D_fake: 0.620 \n",
            "(epoch: 43, iters: 600, time: 0.059, data: 0.003) G_GAN: 0.711 G_L1: 0.000 D_real: 0.835 D_fake: 0.592 \n",
            "(epoch: 43, iters: 700, time: 0.060, data: 0.002) G_GAN: 4.815 G_L1: 109.427 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 43, iters: 800, time: 0.175, data: 0.002) G_GAN: 4.001 G_L1: 44.599 D_real: 0.000 D_fake: 0.025 \n",
            "(epoch: 43, iters: 900, time: 0.058, data: 0.004) G_GAN: 1.116 G_L1: 36.155 D_real: 0.000 D_fake: 0.565 \n",
            "(epoch: 43, iters: 1000, time: 0.058, data: 0.002) G_GAN: 2.924 G_L1: 26.552 D_real: 0.000 D_fake: 0.072 \n",
            "End of epoch 43 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.059, data: 0.168) G_GAN: 4.055 G_L1: 53.344 D_real: 0.000 D_fake: 0.025 \n",
            "(epoch: 44, iters: 200, time: 0.509, data: 0.003) G_GAN: 0.849 G_L1: 0.000 D_real: 0.859 D_fake: 0.559 \n",
            "(epoch: 44, iters: 300, time: 0.056, data: 0.009) G_GAN: 3.396 G_L1: 19.491 D_real: 0.000 D_fake: 0.040 \n",
            "(epoch: 44, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.733 G_L1: 0.000 D_real: 0.888 D_fake: 0.553 \n",
            "(epoch: 44, iters: 500, time: 0.057, data: 0.004) G_GAN: 0.687 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
            "(epoch: 44, iters: 600, time: 0.164, data: 0.003) G_GAN: 1.704 G_L1: 3.468 D_real: 0.000 D_fake: 0.246 \n",
            "(epoch: 44, iters: 700, time: 0.056, data: 0.003) G_GAN: 0.671 G_L1: 0.000 D_real: 0.657 D_fake: 0.736 \n",
            "(epoch: 44, iters: 800, time: 0.056, data: 0.003) G_GAN: 4.008 G_L1: 47.082 D_real: 0.000 D_fake: 0.023 \n",
            "(epoch: 44, iters: 900, time: 0.058, data: 0.003) G_GAN: 3.264 G_L1: 41.810 D_real: 0.000 D_fake: 0.046 \n",
            "(epoch: 44, iters: 1000, time: 0.384, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.677 D_fake: 0.717 \n",
            "End of epoch 44 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.059, data: 0.206) G_GAN: 0.779 G_L1: 0.000 D_real: 0.825 D_fake: 0.583 \n",
            "(epoch: 45, iters: 200, time: 0.056, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.705 D_fake: 0.685 \n",
            "(epoch: 45, iters: 300, time: 0.058, data: 0.003) G_GAN: 3.774 G_L1: 62.136 D_real: 0.000 D_fake: 0.026 \n",
            "(epoch: 45, iters: 400, time: 0.496, data: 0.004) G_GAN: 0.821 G_L1: 0.000 D_real: 0.852 D_fake: 0.576 \n",
            "(epoch: 45, iters: 500, time: 0.059, data: 0.010) G_GAN: 0.639 G_L1: 0.000 D_real: 0.803 D_fake: 0.621 \n",
            "(epoch: 45, iters: 600, time: 0.058, data: 0.003) G_GAN: 7.017 G_L1: 137.849 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 45, iters: 700, time: 0.061, data: 0.005) G_GAN: 4.379 G_L1: 27.590 D_real: 0.000 D_fake: 0.017 \n",
            "(epoch: 45, iters: 800, time: 0.172, data: 0.003) G_GAN: 1.691 G_L1: 28.661 D_real: 0.000 D_fake: 0.271 \n",
            "(epoch: 45, iters: 900, time: 0.058, data: 0.007) G_GAN: 3.934 G_L1: 125.922 D_real: 0.000 D_fake: 0.023 \n",
            "(epoch: 45, iters: 1000, time: 0.057, data: 0.005) G_GAN: 0.712 G_L1: 0.000 D_real: 0.725 D_fake: 0.672 \n",
            "saving the latest model (epoch 45, total_iters 45000)\n",
            "saving the model at the end of epoch 45, iters 45000\n",
            "End of epoch 45 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.058, data: 0.210) G_GAN: 1.010 G_L1: 5.646 D_real: 0.000 D_fake: 0.570 \n",
            "(epoch: 46, iters: 200, time: 0.528, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.718 D_fake: 0.676 \n",
            "(epoch: 46, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.748 G_L1: 0.000 D_real: 0.773 D_fake: 0.629 \n",
            "(epoch: 46, iters: 400, time: 0.056, data: 0.003) G_GAN: 0.791 G_L1: 1.361 D_real: 0.000 D_fake: 0.787 \n",
            "(epoch: 46, iters: 500, time: 0.054, data: 0.002) G_GAN: 5.293 G_L1: 52.963 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 46, iters: 600, time: 0.171, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.780 D_fake: 0.619 \n",
            "(epoch: 46, iters: 700, time: 0.059, data: 0.014) G_GAN: 0.709 G_L1: 0.000 D_real: 0.728 D_fake: 0.664 \n",
            "(epoch: 46, iters: 800, time: 0.057, data: 0.003) G_GAN: 5.766 G_L1: 135.602 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 46, iters: 900, time: 0.054, data: 0.003) G_GAN: 1.062 G_L1: 1.522 D_real: 0.000 D_fake: 0.534 \n",
            "(epoch: 46, iters: 1000, time: 0.396, data: 0.002) G_GAN: 0.622 G_L1: 0.000 D_real: 0.614 D_fake: 0.785 \n",
            "End of epoch 46 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.059, data: 0.193) G_GAN: 2.882 G_L1: 26.552 D_real: 0.000 D_fake: 0.074 \n",
            "(epoch: 47, iters: 200, time: 0.056, data: 0.003) G_GAN: 5.396 G_L1: 67.226 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 47, iters: 300, time: 0.057, data: 0.003) G_GAN: 1.221 G_L1: 0.000 D_real: 1.830 D_fake: 0.182 \n",
            "(epoch: 47, iters: 400, time: 0.616, data: 0.004) G_GAN: 4.157 G_L1: 30.123 D_real: 0.000 D_fake: 0.019 \n",
            "(epoch: 47, iters: 500, time: 0.058, data: 0.003) G_GAN: 6.326 G_L1: 155.728 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 47, iters: 600, time: 0.053, data: 0.003) G_GAN: 3.918 G_L1: 118.722 D_real: 0.000 D_fake: 0.026 \n",
            "(epoch: 47, iters: 700, time: 0.057, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.750 D_fake: 0.648 \n",
            "(epoch: 47, iters: 800, time: 0.160, data: 0.007) G_GAN: 0.624 G_L1: 0.000 D_real: 0.603 D_fake: 0.802 \n",
            "(epoch: 47, iters: 900, time: 0.055, data: 0.002) G_GAN: 6.043 G_L1: 131.796 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 47, iters: 1000, time: 0.059, data: 0.003) G_GAN: 0.705 G_L1: 0.000 D_real: 0.716 D_fake: 0.703 \n",
            "End of epoch 47 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.057, data: 0.221) G_GAN: 0.533 G_L1: 0.000 D_real: 0.558 D_fake: 0.879 \n",
            "(epoch: 48, iters: 200, time: 0.510, data: 0.002) G_GAN: 0.652 G_L1: 0.000 D_real: 0.640 D_fake: 0.752 \n",
            "(epoch: 48, iters: 300, time: 0.054, data: 0.003) G_GAN: 2.982 G_L1: 40.344 D_real: 0.000 D_fake: 0.063 \n",
            "(epoch: 48, iters: 400, time: 0.056, data: 0.003) G_GAN: 5.766 G_L1: 75.642 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 48, iters: 500, time: 0.057, data: 0.005) G_GAN: 0.664 G_L1: 0.000 D_real: 0.656 D_fake: 0.740 \n",
            "(epoch: 48, iters: 600, time: 0.167, data: 0.003) G_GAN: 5.197 G_L1: 58.017 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 48, iters: 700, time: 0.058, data: 0.004) G_GAN: 1.438 G_L1: 11.015 D_real: 0.000 D_fake: 0.344 \n",
            "(epoch: 48, iters: 800, time: 0.059, data: 0.003) G_GAN: 1.866 G_L1: 5.977 D_real: 0.000 D_fake: 0.316 \n",
            "(epoch: 48, iters: 900, time: 0.056, data: 0.002) G_GAN: 2.307 G_L1: 17.145 D_real: 0.000 D_fake: 0.116 \n",
            "(epoch: 48, iters: 1000, time: 0.397, data: 0.003) G_GAN: 5.966 G_L1: 157.439 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 48 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.056, data: 0.231) G_GAN: 3.553 G_L1: 56.005 D_real: 0.000 D_fake: 0.033 \n",
            "(epoch: 49, iters: 200, time: 0.059, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
            "(epoch: 49, iters: 300, time: 0.056, data: 0.002) G_GAN: 1.248 G_L1: 10.147 D_real: 0.000 D_fake: 0.458 \n",
            "(epoch: 49, iters: 400, time: 0.520, data: 0.003) G_GAN: 4.985 G_L1: 49.951 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 49, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.776 D_fake: 0.622 \n",
            "(epoch: 49, iters: 600, time: 0.056, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.761 D_fake: 0.637 \n",
            "(epoch: 49, iters: 700, time: 0.057, data: 0.002) G_GAN: 0.816 G_L1: 0.000 D_real: 0.873 D_fake: 0.551 \n",
            "(epoch: 49, iters: 800, time: 0.171, data: 0.002) G_GAN: 7.555 G_L1: 88.555 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 49, iters: 900, time: 0.053, data: 0.003) G_GAN: 0.786 G_L1: 0.000 D_real: 0.796 D_fake: 0.616 \n",
            "(epoch: 49, iters: 1000, time: 0.059, data: 0.003) G_GAN: 1.752 G_L1: 18.317 D_real: 0.000 D_fake: 0.316 \n",
            "End of epoch 49 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.060, data: 0.187) G_GAN: 1.242 G_L1: 64.279 D_real: 0.000 D_fake: 0.646 \n",
            "(epoch: 50, iters: 200, time: 0.522, data: 0.002) G_GAN: 6.957 G_L1: 137.532 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 50, iters: 300, time: 0.058, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.716 D_fake: 0.677 \n",
            "(epoch: 50, iters: 400, time: 0.050, data: 0.003) G_GAN: 0.714 G_L1: 0.000 D_real: 0.722 D_fake: 0.669 \n",
            "(epoch: 50, iters: 500, time: 0.058, data: 0.004) G_GAN: 1.511 G_L1: 0.000 D_real: 2.492 D_fake: 0.107 \n",
            "(epoch: 50, iters: 600, time: 0.165, data: 0.003) G_GAN: 0.724 G_L1: 0.000 D_real: 0.706 D_fake: 0.689 \n",
            "(epoch: 50, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.687 G_L1: 0.000 D_real: 0.676 D_fake: 0.715 \n",
            "(epoch: 50, iters: 800, time: 0.055, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.778 D_fake: 0.632 \n",
            "(epoch: 50, iters: 900, time: 0.056, data: 0.003) G_GAN: 0.665 G_L1: 0.000 D_real: 0.643 D_fake: 0.769 \n",
            "(epoch: 50, iters: 1000, time: 0.386, data: 0.003) G_GAN: 0.760 G_L1: 0.000 D_real: 0.815 D_fake: 0.590 \n",
            "saving the latest model (epoch 50, total_iters 50000)\n",
            "saving the model at the end of epoch 50, iters 50000\n",
            "End of epoch 50 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.055, data: 0.250) G_GAN: 0.681 G_L1: 0.000 D_real: 0.675 D_fake: 0.717 \n",
            "(epoch: 51, iters: 200, time: 0.059, data: 0.005) G_GAN: 5.026 G_L1: 89.229 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 51, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.677 \n",
            "(epoch: 51, iters: 400, time: 0.531, data: 0.004) G_GAN: 0.661 G_L1: 0.000 D_real: 0.657 D_fake: 0.736 \n",
            "(epoch: 51, iters: 500, time: 0.058, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.723 D_fake: 0.677 \n",
            "(epoch: 51, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
            "(epoch: 51, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
            "(epoch: 51, iters: 800, time: 0.179, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.673 D_fake: 0.720 \n",
            "(epoch: 51, iters: 900, time: 0.053, data: 0.008) G_GAN: 0.611 G_L1: 0.000 D_real: 0.563 D_fake: 0.855 \n",
            "(epoch: 51, iters: 1000, time: 0.057, data: 0.004) G_GAN: 0.883 G_L1: 0.000 D_real: 1.139 D_fake: 0.402 \n",
            "End of epoch 51 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.053, data: 0.159) G_GAN: 4.036 G_L1: 6.694 D_real: 0.000 D_fake: 0.022 \n",
            "(epoch: 52, iters: 200, time: 0.681, data: 0.002) G_GAN: 4.203 G_L1: 47.835 D_real: 0.000 D_fake: 0.018 \n",
            "(epoch: 52, iters: 300, time: 0.048, data: 0.009) G_GAN: 0.894 G_L1: 0.000 D_real: 0.956 D_fake: 0.497 \n",
            "(epoch: 52, iters: 400, time: 0.053, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.757 D_fake: 0.639 \n",
            "(epoch: 52, iters: 500, time: 0.052, data: 0.002) G_GAN: 5.046 G_L1: 101.504 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 52, iters: 600, time: 0.153, data: 0.003) G_GAN: 0.772 G_L1: 0.000 D_real: 0.900 D_fake: 0.531 \n",
            "(epoch: 52, iters: 700, time: 0.058, data: 0.002) G_GAN: 0.845 G_L1: 0.000 D_real: 0.945 D_fake: 0.499 \n",
            "(epoch: 52, iters: 800, time: 0.054, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.736 D_fake: 0.656 \n",
            "(epoch: 52, iters: 900, time: 0.056, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.715 D_fake: 0.677 \n",
            "(epoch: 52, iters: 1000, time: 0.404, data: 0.003) G_GAN: 0.655 G_L1: 0.000 D_real: 0.651 D_fake: 0.744 \n",
            "End of epoch 52 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.060, data: 0.202) G_GAN: 0.780 G_L1: 0.000 D_real: 0.812 D_fake: 0.595 \n",
            "(epoch: 53, iters: 200, time: 0.057, data: 0.002) G_GAN: 0.796 G_L1: 0.000 D_real: 0.857 D_fake: 0.567 \n",
            "(epoch: 53, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.687 G_L1: 0.000 D_real: 0.686 D_fake: 0.704 \n",
            "(epoch: 53, iters: 400, time: 0.528, data: 0.003) G_GAN: 6.158 G_L1: 200.000 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 53, iters: 500, time: 0.062, data: 0.003) G_GAN: 0.660 G_L1: 0.000 D_real: 0.638 D_fake: 0.759 \n",
            "(epoch: 53, iters: 600, time: 0.057, data: 0.003) G_GAN: 3.451 G_L1: 22.217 D_real: 0.000 D_fake: 0.040 \n",
            "(epoch: 53, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.695 D_fake: 0.701 \n",
            "(epoch: 53, iters: 800, time: 0.159, data: 0.003) G_GAN: 0.802 G_L1: 0.000 D_real: 0.775 D_fake: 0.629 \n",
            "(epoch: 53, iters: 900, time: 0.059, data: 0.005) G_GAN: 0.694 G_L1: 0.000 D_real: 0.683 D_fake: 0.712 \n",
            "(epoch: 53, iters: 1000, time: 0.062, data: 0.003) G_GAN: 0.652 G_L1: 0.000 D_real: 0.651 D_fake: 0.743 \n",
            "End of epoch 53 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.060, data: 0.204) G_GAN: 0.733 G_L1: 0.000 D_real: 0.748 D_fake: 0.649 \n",
            "(epoch: 54, iters: 200, time: 0.513, data: 0.002) G_GAN: 0.627 G_L1: 0.000 D_real: 0.641 D_fake: 0.757 \n",
            "(epoch: 54, iters: 300, time: 0.053, data: 0.003) G_GAN: 0.644 G_L1: 0.000 D_real: 0.639 D_fake: 0.760 \n",
            "(epoch: 54, iters: 400, time: 0.054, data: 0.003) G_GAN: 3.879 G_L1: 200.000 D_real: 0.000 D_fake: 0.024 \n",
            "(epoch: 54, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.673 G_L1: 0.000 D_real: 0.673 D_fake: 0.723 \n",
            "(epoch: 54, iters: 600, time: 0.170, data: 0.003) G_GAN: 6.532 G_L1: 101.485 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 54, iters: 700, time: 0.056, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.736 D_fake: 0.660 \n",
            "(epoch: 54, iters: 800, time: 0.056, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.697 D_fake: 0.691 \n",
            "(epoch: 54, iters: 900, time: 0.057, data: 0.003) G_GAN: 1.769 G_L1: 10.810 D_real: 0.000 D_fake: 0.262 \n",
            "(epoch: 54, iters: 1000, time: 0.415, data: 0.002) G_GAN: 2.235 G_L1: 6.179 D_real: 0.000 D_fake: 0.138 \n",
            "End of epoch 54 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.054, data: 0.175) G_GAN: 0.743 G_L1: 0.000 D_real: 0.653 D_fake: 0.747 \n",
            "(epoch: 55, iters: 200, time: 0.059, data: 0.003) G_GAN: 2.921 G_L1: 5.117 D_real: 0.000 D_fake: 0.061 \n",
            "(epoch: 55, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.747 D_fake: 0.649 \n",
            "(epoch: 55, iters: 400, time: 0.524, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.762 D_fake: 0.632 \n",
            "(epoch: 55, iters: 500, time: 0.056, data: 0.002) G_GAN: 0.842 G_L1: 0.000 D_real: 0.888 D_fake: 0.537 \n",
            "(epoch: 55, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.845 G_L1: 0.000 D_real: 0.923 D_fake: 0.516 \n",
            "(epoch: 55, iters: 700, time: 0.046, data: 0.003) G_GAN: 0.786 G_L1: 0.000 D_real: 0.770 D_fake: 0.633 \n",
            "(epoch: 55, iters: 800, time: 0.166, data: 0.003) G_GAN: 6.117 G_L1: 73.189 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 55, iters: 900, time: 0.053, data: 0.006) G_GAN: 4.352 G_L1: 96.744 D_real: 0.000 D_fake: 0.018 \n",
            "(epoch: 55, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.677 G_L1: 0.000 D_real: 0.675 D_fake: 0.719 \n",
            "saving the latest model (epoch 55, total_iters 55000)\n",
            "saving the model at the end of epoch 55, iters 55000\n",
            "End of epoch 55 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.056, data: 0.232) G_GAN: 0.663 G_L1: 0.000 D_real: 0.651 D_fake: 0.740 \n",
            "(epoch: 56, iters: 200, time: 0.544, data: 0.004) G_GAN: 0.789 G_L1: 0.000 D_real: 0.863 D_fake: 0.554 \n",
            "(epoch: 56, iters: 300, time: 0.059, data: 0.007) G_GAN: 3.946 G_L1: 25.858 D_real: 0.000 D_fake: 0.023 \n",
            "(epoch: 56, iters: 400, time: 0.059, data: 0.003) G_GAN: 0.626 G_L1: 0.000 D_real: 0.603 D_fake: 0.799 \n",
            "(epoch: 56, iters: 500, time: 0.055, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 1.041 D_fake: 0.456 \n",
            "(epoch: 56, iters: 600, time: 0.165, data: 0.004) G_GAN: 0.809 G_L1: 0.000 D_real: 1.028 D_fake: 0.453 \n",
            "(epoch: 56, iters: 700, time: 0.059, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.685 D_fake: 0.708 \n",
            "(epoch: 56, iters: 800, time: 0.059, data: 0.003) G_GAN: 2.844 G_L1: 45.592 D_real: 0.000 D_fake: 0.071 \n",
            "(epoch: 56, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.741 D_fake: 0.656 \n",
            "(epoch: 56, iters: 1000, time: 0.422, data: 0.003) G_GAN: 0.809 G_L1: 0.000 D_real: 0.882 D_fake: 0.556 \n",
            "End of epoch 56 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.059, data: 0.172) G_GAN: 0.766 G_L1: 0.000 D_real: 0.947 D_fake: 0.503 \n",
            "(epoch: 57, iters: 200, time: 0.058, data: 0.004) G_GAN: 0.737 G_L1: 0.000 D_real: 0.789 D_fake: 0.611 \n",
            "(epoch: 57, iters: 300, time: 0.056, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 1.122 D_fake: 0.408 \n",
            "(epoch: 57, iters: 400, time: 0.683, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.671 \n",
            "(epoch: 57, iters: 500, time: 0.058, data: 0.006) G_GAN: 0.651 G_L1: 0.000 D_real: 0.629 D_fake: 0.773 \n",
            "(epoch: 57, iters: 600, time: 0.060, data: 0.003) G_GAN: 1.348 G_L1: 4.018 D_real: 0.000 D_fake: 0.391 \n",
            "(epoch: 57, iters: 700, time: 0.057, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.820 D_fake: 0.585 \n",
            "(epoch: 57, iters: 800, time: 0.169, data: 0.003) G_GAN: 3.097 G_L1: 64.476 D_real: 0.000 D_fake: 0.058 \n",
            "(epoch: 57, iters: 900, time: 0.054, data: 0.009) G_GAN: 3.285 G_L1: 137.491 D_real: 0.000 D_fake: 0.048 \n",
            "(epoch: 57, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.710 D_fake: 0.688 \n",
            "End of epoch 57 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.055, data: 0.195) G_GAN: 0.741 G_L1: 0.000 D_real: 0.804 D_fake: 0.600 \n",
            "(epoch: 58, iters: 200, time: 0.551, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.745 D_fake: 0.649 \n",
            "(epoch: 58, iters: 300, time: 0.058, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.724 D_fake: 0.674 \n",
            "(epoch: 58, iters: 400, time: 0.055, data: 0.003) G_GAN: 3.108 G_L1: 9.991 D_real: 0.000 D_fake: 0.056 \n",
            "(epoch: 58, iters: 500, time: 0.057, data: 0.004) G_GAN: 0.680 G_L1: 0.000 D_real: 0.674 D_fake: 0.715 \n",
            "(epoch: 58, iters: 600, time: 0.175, data: 0.003) G_GAN: 0.811 G_L1: 0.000 D_real: 0.879 D_fake: 0.542 \n",
            "(epoch: 58, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
            "(epoch: 58, iters: 800, time: 0.054, data: 0.004) G_GAN: 0.696 G_L1: 0.000 D_real: 0.695 D_fake: 0.694 \n",
            "(epoch: 58, iters: 900, time: 0.056, data: 0.003) G_GAN: 4.238 G_L1: 63.745 D_real: 0.000 D_fake: 0.020 \n",
            "(epoch: 58, iters: 1000, time: 0.422, data: 0.006) G_GAN: 5.879 G_L1: 147.404 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 58 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.057, data: 0.197) G_GAN: 7.065 G_L1: 144.887 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 59, iters: 200, time: 0.056, data: 0.002) G_GAN: 0.867 G_L1: 0.000 D_real: 0.905 D_fake: 0.527 \n",
            "(epoch: 59, iters: 300, time: 0.059, data: 0.004) G_GAN: 3.384 G_L1: 45.564 D_real: 0.000 D_fake: 0.046 \n",
            "(epoch: 59, iters: 400, time: 0.533, data: 0.004) G_GAN: 0.624 G_L1: 0.000 D_real: 1.605 D_fake: 0.233 \n",
            "(epoch: 59, iters: 500, time: 0.059, data: 0.014) G_GAN: 4.996 G_L1: 39.372 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 59, iters: 600, time: 0.058, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.811 D_fake: 0.599 \n",
            "(epoch: 59, iters: 700, time: 0.056, data: 0.003) G_GAN: 0.800 G_L1: 0.000 D_real: 0.879 D_fake: 0.542 \n",
            "(epoch: 59, iters: 800, time: 0.168, data: 0.003) G_GAN: 3.139 G_L1: 42.244 D_real: 0.000 D_fake: 0.051 \n",
            "(epoch: 59, iters: 900, time: 0.058, data: 0.007) G_GAN: 0.719 G_L1: 0.000 D_real: 0.718 D_fake: 0.675 \n",
            "(epoch: 59, iters: 1000, time: 0.054, data: 0.003) G_GAN: 0.784 G_L1: 0.000 D_real: 0.799 D_fake: 0.602 \n",
            "End of epoch 59 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.058, data: 0.189) G_GAN: 5.910 G_L1: 37.696 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 60, iters: 200, time: 0.537, data: 0.002) G_GAN: 0.648 G_L1: 0.000 D_real: 0.631 D_fake: 0.764 \n",
            "(epoch: 60, iters: 300, time: 0.059, data: 0.009) G_GAN: 0.734 G_L1: 0.000 D_real: 0.740 D_fake: 0.658 \n",
            "(epoch: 60, iters: 400, time: 0.057, data: 0.003) G_GAN: 2.252 G_L1: 41.378 D_real: 0.000 D_fake: 0.148 \n",
            "(epoch: 60, iters: 500, time: 0.058, data: 0.003) G_GAN: 7.355 G_L1: 105.369 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 60, iters: 600, time: 0.167, data: 0.003) G_GAN: 0.663 G_L1: 0.000 D_real: 0.641 D_fake: 0.755 \n",
            "(epoch: 60, iters: 700, time: 0.060, data: 0.009) G_GAN: 6.651 G_L1: 86.188 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 60, iters: 800, time: 0.057, data: 0.003) G_GAN: 6.586 G_L1: 53.694 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 60, iters: 900, time: 0.060, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.737 D_fake: 0.659 \n",
            "(epoch: 60, iters: 1000, time: 0.418, data: 0.002) G_GAN: 3.811 G_L1: 200.000 D_real: 0.001 D_fake: 0.027 \n",
            "saving the latest model (epoch 60, total_iters 60000)\n",
            "saving the model at the end of epoch 60, iters 60000\n",
            "End of epoch 60 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.057, data: 0.227) G_GAN: 6.676 G_L1: 110.182 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 61, iters: 200, time: 0.059, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.775 D_fake: 0.625 \n",
            "(epoch: 61, iters: 300, time: 0.055, data: 0.002) G_GAN: 1.676 G_L1: 6.470 D_real: 0.000 D_fake: 0.254 \n",
            "(epoch: 61, iters: 400, time: 0.677, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.698 D_fake: 0.692 \n",
            "(epoch: 61, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.647 G_L1: 0.000 D_real: 0.628 D_fake: 0.770 \n",
            "(epoch: 61, iters: 600, time: 0.060, data: 0.005) G_GAN: 7.020 G_L1: 127.273 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 61, iters: 700, time: 0.056, data: 0.003) G_GAN: 0.714 G_L1: 0.000 D_real: 0.705 D_fake: 0.683 \n",
            "(epoch: 61, iters: 800, time: 0.170, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.656 D_fake: 0.736 \n",
            "(epoch: 61, iters: 900, time: 0.058, data: 0.009) G_GAN: 4.940 G_L1: 190.103 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 61, iters: 1000, time: 0.057, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.683 \n",
            "End of epoch 61 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.056, data: 0.173) G_GAN: 6.403 G_L1: 57.380 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 62, iters: 200, time: 0.571, data: 0.002) G_GAN: 5.204 G_L1: 165.590 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 62, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.656 G_L1: 0.000 D_real: 0.784 D_fake: 0.641 \n",
            "(epoch: 62, iters: 400, time: 0.057, data: 0.002) G_GAN: 8.056 G_L1: 94.155 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 62, iters: 500, time: 0.056, data: 0.004) G_GAN: 3.675 G_L1: 42.346 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 62, iters: 600, time: 0.170, data: 0.003) G_GAN: 1.993 G_L1: 26.260 D_real: 0.000 D_fake: 0.157 \n",
            "(epoch: 62, iters: 700, time: 0.059, data: 0.002) G_GAN: 3.707 G_L1: 103.604 D_real: 0.000 D_fake: 0.036 \n",
            "(epoch: 62, iters: 800, time: 0.057, data: 0.002) G_GAN: 0.630 G_L1: 0.000 D_real: 0.631 D_fake: 0.817 \n",
            "(epoch: 62, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.805 G_L1: 0.000 D_real: 1.120 D_fake: 0.410 \n",
            "(epoch: 62, iters: 1000, time: 0.441, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.815 D_fake: 0.591 \n",
            "End of epoch 62 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.057, data: 0.173) G_GAN: 1.995 G_L1: 37.099 D_real: 0.000 D_fake: 0.324 \n",
            "(epoch: 63, iters: 200, time: 0.056, data: 0.003) G_GAN: 7.121 G_L1: 141.941 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 63, iters: 300, time: 0.058, data: 0.002) G_GAN: 5.637 G_L1: 76.516 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 63, iters: 400, time: 0.606, data: 0.004) G_GAN: 0.781 G_L1: 0.000 D_real: 0.808 D_fake: 0.600 \n",
            "(epoch: 63, iters: 500, time: 0.055, data: 0.005) G_GAN: 0.789 G_L1: 0.000 D_real: 0.866 D_fake: 0.552 \n",
            "(epoch: 63, iters: 600, time: 0.054, data: 0.002) G_GAN: 4.442 G_L1: 88.787 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 63, iters: 700, time: 0.056, data: 0.006) G_GAN: 2.810 G_L1: 41.404 D_real: 0.000 D_fake: 0.082 \n",
            "(epoch: 63, iters: 800, time: 0.188, data: 0.003) G_GAN: 0.664 G_L1: 0.000 D_real: 0.653 D_fake: 0.739 \n",
            "(epoch: 63, iters: 900, time: 0.053, data: 0.004) G_GAN: 0.757 G_L1: 0.000 D_real: 0.766 D_fake: 0.629 \n",
            "(epoch: 63, iters: 1000, time: 0.058, data: 0.006) G_GAN: 0.638 G_L1: 0.000 D_real: 0.615 D_fake: 0.780 \n",
            "End of epoch 63 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 0.057, data: 0.197) G_GAN: 3.232 G_L1: 136.606 D_real: 0.000 D_fake: 0.050 \n",
            "(epoch: 64, iters: 200, time: 0.575, data: 0.003) G_GAN: 0.919 G_L1: 0.000 D_real: 1.056 D_fake: 0.437 \n",
            "(epoch: 64, iters: 300, time: 0.057, data: 0.008) G_GAN: 0.667 G_L1: 0.000 D_real: 0.658 D_fake: 0.737 \n",
            "(epoch: 64, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.700 D_fake: 0.690 \n",
            "(epoch: 64, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
            "(epoch: 64, iters: 600, time: 0.169, data: 0.003) G_GAN: 0.764 G_L1: 0.000 D_real: 0.846 D_fake: 0.569 \n",
            "(epoch: 64, iters: 700, time: 0.057, data: 0.002) G_GAN: 6.467 G_L1: 155.647 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 64, iters: 800, time: 0.058, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.733 D_fake: 0.658 \n",
            "(epoch: 64, iters: 900, time: 0.059, data: 0.003) G_GAN: 7.022 G_L1: 142.542 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 64, iters: 1000, time: 0.460, data: 0.003) G_GAN: 7.151 G_L1: 115.134 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 64 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.053, data: 0.208) G_GAN: 3.697 G_L1: 25.409 D_real: 0.000 D_fake: 0.031 \n",
            "(epoch: 65, iters: 200, time: 0.059, data: 0.003) G_GAN: 0.789 G_L1: 0.000 D_real: 0.845 D_fake: 0.573 \n",
            "(epoch: 65, iters: 300, time: 0.057, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.648 D_fake: 0.746 \n",
            "(epoch: 65, iters: 400, time: 0.591, data: 0.003) G_GAN: 0.620 G_L1: 0.000 D_real: 0.598 D_fake: 0.802 \n",
            "(epoch: 65, iters: 500, time: 0.063, data: 0.006) G_GAN: 0.697 G_L1: 0.000 D_real: 0.684 D_fake: 0.704 \n",
            "(epoch: 65, iters: 600, time: 0.057, data: 0.003) G_GAN: 3.897 G_L1: 73.770 D_real: 0.000 D_fake: 0.026 \n",
            "(epoch: 65, iters: 700, time: 0.056, data: 0.002) G_GAN: 0.598 G_L1: 0.000 D_real: 0.599 D_fake: 0.805 \n",
            "(epoch: 65, iters: 800, time: 0.270, data: 0.003) G_GAN: 7.081 G_L1: 121.824 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 65, iters: 900, time: 0.055, data: 0.009) G_GAN: 0.692 G_L1: 0.000 D_real: 0.675 D_fake: 0.727 \n",
            "(epoch: 65, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.704 D_fake: 0.692 \n",
            "saving the latest model (epoch 65, total_iters 65000)\n",
            "saving the model at the end of epoch 65, iters 65000\n",
            "End of epoch 65 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.056, data: 0.206) G_GAN: 0.684 G_L1: 0.000 D_real: 0.678 D_fake: 0.713 \n",
            "(epoch: 66, iters: 200, time: 0.593, data: 0.003) G_GAN: 0.780 G_L1: 0.000 D_real: 0.792 D_fake: 0.605 \n",
            "(epoch: 66, iters: 300, time: 0.057, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.678 D_fake: 0.714 \n",
            "(epoch: 66, iters: 400, time: 0.057, data: 0.003) G_GAN: 7.508 G_L1: 96.107 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 66, iters: 500, time: 0.057, data: 0.003) G_GAN: 3.041 G_L1: 14.488 D_real: 0.000 D_fake: 0.063 \n",
            "(epoch: 66, iters: 600, time: 0.170, data: 0.002) G_GAN: 0.834 G_L1: 0.000 D_real: 1.046 D_fake: 0.438 \n",
            "(epoch: 66, iters: 700, time: 0.057, data: 0.012) G_GAN: 5.597 G_L1: 110.114 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 66, iters: 800, time: 0.058, data: 0.004) G_GAN: 5.368 G_L1: 156.383 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 66, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.663 G_L1: 0.000 D_real: 0.676 D_fake: 0.724 \n",
            "(epoch: 66, iters: 1000, time: 0.468, data: 0.003) G_GAN: 3.053 G_L1: 25.288 D_real: 0.000 D_fake: 0.064 \n",
            "End of epoch 66 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.058, data: 0.184) G_GAN: 2.626 G_L1: 175.256 D_real: 0.000 D_fake: 0.110 \n",
            "(epoch: 67, iters: 200, time: 0.050, data: 0.002) G_GAN: 4.621 G_L1: 141.136 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 67, iters: 300, time: 0.059, data: 0.003) G_GAN: 1.902 G_L1: 4.056 D_real: 0.000 D_fake: 0.317 \n",
            "(epoch: 67, iters: 400, time: 0.612, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.658 D_fake: 0.732 \n",
            "(epoch: 67, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.692 D_fake: 0.698 \n",
            "(epoch: 67, iters: 600, time: 0.059, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.687 D_fake: 0.725 \n",
            "(epoch: 67, iters: 700, time: 0.059, data: 0.002) G_GAN: 6.521 G_L1: 97.023 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 67, iters: 800, time: 0.176, data: 0.003) G_GAN: 0.991 G_L1: 9.067 D_real: 0.000 D_fake: 0.564 \n",
            "(epoch: 67, iters: 900, time: 0.059, data: 0.004) G_GAN: 7.039 G_L1: 72.436 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 67, iters: 1000, time: 0.059, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 1.071 D_fake: 0.468 \n",
            "End of epoch 67 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.059, data: 0.221) G_GAN: 0.804 G_L1: 0.000 D_real: 0.844 D_fake: 0.567 \n",
            "(epoch: 68, iters: 200, time: 0.599, data: 0.003) G_GAN: 0.861 G_L1: 0.000 D_real: 1.357 D_fake: 0.305 \n",
            "(epoch: 68, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.647 G_L1: 0.000 D_real: 0.660 D_fake: 0.731 \n",
            "(epoch: 68, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.800 G_L1: 0.000 D_real: 0.858 D_fake: 0.558 \n",
            "(epoch: 68, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.628 G_L1: 0.000 D_real: 0.615 D_fake: 0.791 \n",
            "(epoch: 68, iters: 600, time: 0.166, data: 0.002) G_GAN: 5.381 G_L1: 118.587 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 68, iters: 700, time: 0.060, data: 0.007) G_GAN: 5.125 G_L1: 198.339 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 68, iters: 800, time: 0.057, data: 0.003) G_GAN: 3.252 G_L1: 41.585 D_real: 0.000 D_fake: 0.048 \n",
            "(epoch: 68, iters: 900, time: 0.056, data: 0.003) G_GAN: 4.822 G_L1: 106.940 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 68, iters: 1000, time: 0.456, data: 0.002) G_GAN: 0.651 G_L1: 0.000 D_real: 1.168 D_fake: 0.387 \n",
            "End of epoch 68 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.058, data: 0.185) G_GAN: 4.761 G_L1: 55.375 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 69, iters: 200, time: 0.058, data: 0.003) G_GAN: 0.684 G_L1: 0.000 D_real: 0.686 D_fake: 0.704 \n",
            "(epoch: 69, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.648 G_L1: 0.000 D_real: 0.634 D_fake: 0.761 \n",
            "(epoch: 69, iters: 400, time: 0.650, data: 0.003) G_GAN: 4.469 G_L1: 89.227 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 69, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.687 D_fake: 0.702 \n",
            "(epoch: 69, iters: 600, time: 0.056, data: 0.004) G_GAN: 0.675 G_L1: 0.000 D_real: 0.627 D_fake: 0.780 \n",
            "(epoch: 69, iters: 700, time: 0.055, data: 0.005) G_GAN: 0.726 G_L1: 0.000 D_real: 0.732 D_fake: 0.660 \n",
            "(epoch: 69, iters: 800, time: 0.263, data: 0.003) G_GAN: 3.575 G_L1: 39.393 D_real: 0.000 D_fake: 0.029 \n",
            "(epoch: 69, iters: 900, time: 0.060, data: 0.003) G_GAN: 0.776 G_L1: 0.000 D_real: 0.814 D_fake: 0.597 \n",
            "(epoch: 69, iters: 1000, time: 0.054, data: 0.002) G_GAN: 6.081 G_L1: 150.090 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 69 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.059, data: 0.182) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.649 \n",
            "(epoch: 70, iters: 200, time: 0.596, data: 0.003) G_GAN: 3.104 G_L1: 200.000 D_real: 0.000 D_fake: 0.063 \n",
            "(epoch: 70, iters: 300, time: 0.055, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.736 D_fake: 0.661 \n",
            "(epoch: 70, iters: 400, time: 0.069, data: 0.004) G_GAN: 0.629 G_L1: 0.000 D_real: 0.607 D_fake: 0.797 \n",
            "(epoch: 70, iters: 500, time: 0.058, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.807 D_fake: 0.595 \n",
            "(epoch: 70, iters: 600, time: 0.167, data: 0.003) G_GAN: 0.754 G_L1: 0.000 D_real: 0.789 D_fake: 0.614 \n",
            "(epoch: 70, iters: 700, time: 0.057, data: 0.011) G_GAN: 0.670 G_L1: 0.000 D_real: 0.673 D_fake: 0.729 \n",
            "(epoch: 70, iters: 800, time: 0.056, data: 0.003) G_GAN: 1.867 G_L1: 37.772 D_real: 0.000 D_fake: 0.294 \n",
            "(epoch: 70, iters: 900, time: 0.056, data: 0.003) G_GAN: 5.293 G_L1: 29.640 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 70, iters: 1000, time: 0.470, data: 0.002) G_GAN: 4.390 G_L1: 30.938 D_real: 0.000 D_fake: 0.017 \n",
            "saving the latest model (epoch 70, total_iters 70000)\n",
            "saving the model at the end of epoch 70, iters 70000\n",
            "End of epoch 70 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.057, data: 0.294) G_GAN: 0.756 G_L1: 0.000 D_real: 1.196 D_fake: 0.369 \n",
            "(epoch: 71, iters: 200, time: 0.058, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.753 D_fake: 0.646 \n",
            "(epoch: 71, iters: 300, time: 0.056, data: 0.004) G_GAN: 0.623 G_L1: 0.000 D_real: 0.623 D_fake: 0.777 \n",
            "(epoch: 71, iters: 400, time: 0.645, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.971 D_fake: 0.526 \n",
            "(epoch: 71, iters: 500, time: 0.060, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
            "(epoch: 71, iters: 600, time: 0.066, data: 0.003) G_GAN: 0.767 G_L1: 0.000 D_real: 0.819 D_fake: 0.601 \n",
            "(epoch: 71, iters: 700, time: 0.059, data: 0.004) G_GAN: 0.869 G_L1: 0.000 D_real: 0.995 D_fake: 0.483 \n",
            "(epoch: 71, iters: 800, time: 0.154, data: 0.003) G_GAN: 1.726 G_L1: 16.968 D_real: 0.000 D_fake: 0.305 \n",
            "(epoch: 71, iters: 900, time: 0.056, data: 0.002) G_GAN: 1.856 G_L1: 3.681 D_real: 0.000 D_fake: 0.208 \n",
            "(epoch: 71, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.627 G_L1: 0.000 D_real: 0.605 D_fake: 0.799 \n",
            "End of epoch 71 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 0.059, data: 0.229) G_GAN: 3.725 G_L1: 30.178 D_real: 0.000 D_fake: 0.030 \n",
            "(epoch: 72, iters: 200, time: 0.585, data: 0.004) G_GAN: 0.671 G_L1: 0.000 D_real: 0.666 D_fake: 0.726 \n",
            "(epoch: 72, iters: 300, time: 0.069, data: 0.003) G_GAN: 3.376 G_L1: 75.513 D_real: 0.000 D_fake: 0.050 \n",
            "(epoch: 72, iters: 400, time: 0.057, data: 0.004) G_GAN: 7.012 G_L1: 126.382 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 72, iters: 500, time: 0.055, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.750 D_fake: 0.644 \n",
            "(epoch: 72, iters: 600, time: 0.180, data: 0.003) G_GAN: 5.609 G_L1: 65.455 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 72, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.676 D_fake: 0.713 \n",
            "(epoch: 72, iters: 800, time: 0.058, data: 0.005) G_GAN: 0.697 G_L1: 0.000 D_real: 0.691 D_fake: 0.702 \n",
            "(epoch: 72, iters: 900, time: 0.056, data: 0.003) G_GAN: 6.587 G_L1: 99.544 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 72, iters: 1000, time: 0.463, data: 0.003) G_GAN: 0.645 G_L1: 0.000 D_real: 0.637 D_fake: 0.764 \n",
            "End of epoch 72 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.056, data: 0.180) G_GAN: 2.407 G_L1: 51.412 D_real: 0.000 D_fake: 0.139 \n",
            "(epoch: 73, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.680 G_L1: 0.000 D_real: 0.672 D_fake: 0.721 \n",
            "(epoch: 73, iters: 300, time: 0.057, data: 0.003) G_GAN: 3.736 G_L1: 88.969 D_real: 0.000 D_fake: 0.029 \n",
            "(epoch: 73, iters: 400, time: 0.700, data: 0.002) G_GAN: 6.825 G_L1: 200.000 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 73, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.831 G_L1: 0.000 D_real: 0.856 D_fake: 0.576 \n",
            "(epoch: 73, iters: 600, time: 0.056, data: 0.003) G_GAN: 0.759 G_L1: 0.000 D_real: 0.785 D_fake: 0.613 \n",
            "(epoch: 73, iters: 700, time: 0.056, data: 0.003) G_GAN: 7.279 G_L1: 133.485 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 73, iters: 800, time: 0.175, data: 0.002) G_GAN: 0.639 G_L1: 0.000 D_real: 0.638 D_fake: 0.754 \n",
            "(epoch: 73, iters: 900, time: 0.055, data: 0.016) G_GAN: 4.405 G_L1: 200.000 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 73, iters: 1000, time: 0.056, data: 0.004) G_GAN: 0.958 G_L1: 0.000 D_real: 1.144 D_fake: 0.390 \n",
            "End of epoch 73 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.056, data: 0.183) G_GAN: 0.758 G_L1: 0.000 D_real: 0.844 D_fake: 0.569 \n",
            "(epoch: 74, iters: 200, time: 0.607, data: 0.006) G_GAN: 0.753 G_L1: 0.000 D_real: 0.765 D_fake: 0.629 \n",
            "(epoch: 74, iters: 300, time: 0.053, data: 0.003) G_GAN: 5.240 G_L1: 24.333 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 74, iters: 400, time: 0.058, data: 0.004) G_GAN: 4.624 G_L1: 130.211 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 74, iters: 500, time: 0.057, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.687 D_fake: 0.704 \n",
            "(epoch: 74, iters: 600, time: 0.160, data: 0.003) G_GAN: 0.622 G_L1: 0.000 D_real: 0.591 D_fake: 0.815 \n",
            "(epoch: 74, iters: 700, time: 0.055, data: 0.013) G_GAN: 0.678 G_L1: 0.000 D_real: 0.673 D_fake: 0.720 \n",
            "(epoch: 74, iters: 800, time: 0.056, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.766 D_fake: 0.637 \n",
            "(epoch: 74, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.752 D_fake: 0.642 \n",
            "(epoch: 74, iters: 1000, time: 0.470, data: 0.003) G_GAN: 0.672 G_L1: 0.000 D_real: 0.669 D_fake: 0.721 \n",
            "End of epoch 74 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.061, data: 0.189) G_GAN: 4.555 G_L1: 26.896 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 75, iters: 200, time: 0.061, data: 0.003) G_GAN: 6.988 G_L1: 110.077 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 75, iters: 300, time: 0.060, data: 0.005) G_GAN: 6.844 G_L1: 159.190 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 75, iters: 400, time: 0.639, data: 0.003) G_GAN: 3.075 G_L1: 10.318 D_real: 0.000 D_fake: 0.060 \n",
            "(epoch: 75, iters: 500, time: 0.055, data: 0.003) G_GAN: 0.609 G_L1: 0.000 D_real: 0.532 D_fake: 0.907 \n",
            "(epoch: 75, iters: 600, time: 0.059, data: 0.003) G_GAN: 6.905 G_L1: 66.706 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 75, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.656 G_L1: 0.000 D_real: 0.634 D_fake: 0.786 \n",
            "(epoch: 75, iters: 800, time: 0.173, data: 0.004) G_GAN: 0.685 G_L1: 0.000 D_real: 0.687 D_fake: 0.704 \n",
            "(epoch: 75, iters: 900, time: 0.058, data: 0.005) G_GAN: 0.891 G_L1: 0.000 D_real: 1.004 D_fake: 0.469 \n",
            "(epoch: 75, iters: 1000, time: 0.058, data: 0.008) G_GAN: 3.579 G_L1: 40.289 D_real: 0.000 D_fake: 0.035 \n",
            "saving the latest model (epoch 75, total_iters 75000)\n",
            "saving the model at the end of epoch 75, iters 75000\n",
            "End of epoch 75 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.058, data: 0.331) G_GAN: 5.186 G_L1: 116.417 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 76, iters: 200, time: 0.688, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.685 D_fake: 0.707 \n",
            "(epoch: 76, iters: 300, time: 0.054, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.712 D_fake: 0.678 \n",
            "(epoch: 76, iters: 400, time: 0.058, data: 0.003) G_GAN: 3.874 G_L1: 41.553 D_real: 0.000 D_fake: 0.025 \n",
            "(epoch: 76, iters: 500, time: 0.057, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.722 D_fake: 0.671 \n",
            "(epoch: 76, iters: 600, time: 0.176, data: 0.003) G_GAN: 0.644 G_L1: 0.000 D_real: 1.025 D_fake: 0.486 \n",
            "(epoch: 76, iters: 700, time: 0.057, data: 0.004) G_GAN: 3.377 G_L1: 28.257 D_real: 0.000 D_fake: 0.043 \n",
            "(epoch: 76, iters: 800, time: 0.057, data: 0.003) G_GAN: 0.666 G_L1: 0.000 D_real: 0.655 D_fake: 0.737 \n",
            "(epoch: 76, iters: 900, time: 0.055, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.720 D_fake: 0.680 \n",
            "(epoch: 76, iters: 1000, time: 0.482, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.724 D_fake: 0.668 \n",
            "End of epoch 76 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.057, data: 0.229) G_GAN: 3.085 G_L1: 30.314 D_real: 0.000 D_fake: 0.044 \n",
            "(epoch: 77, iters: 200, time: 0.055, data: 0.004) G_GAN: 0.695 G_L1: 0.000 D_real: 0.701 D_fake: 0.692 \n",
            "(epoch: 77, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.640 G_L1: 0.000 D_real: 0.620 D_fake: 0.776 \n",
            "(epoch: 77, iters: 400, time: 0.747, data: 0.002) G_GAN: 1.370 G_L1: 8.955 D_real: 0.000 D_fake: 0.432 \n",
            "(epoch: 77, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.582 G_L1: 0.000 D_real: 0.552 D_fake: 0.862 \n",
            "(epoch: 77, iters: 600, time: 0.059, data: 0.003) G_GAN: 0.644 G_L1: 0.000 D_real: 0.617 D_fake: 0.786 \n",
            "(epoch: 77, iters: 700, time: 0.058, data: 0.003) G_GAN: 6.253 G_L1: 109.683 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 77, iters: 800, time: 0.172, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
            "(epoch: 77, iters: 900, time: 0.059, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.661 D_fake: 0.745 \n",
            "(epoch: 77, iters: 1000, time: 0.054, data: 0.003) G_GAN: 9.443 G_L1: 96.533 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 77 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.054, data: 0.194) G_GAN: 4.142 G_L1: 80.520 D_real: 0.000 D_fake: 0.019 \n",
            "(epoch: 78, iters: 200, time: 0.638, data: 0.003) G_GAN: 7.948 G_L1: 141.539 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 78, iters: 300, time: 0.059, data: 0.003) G_GAN: 6.551 G_L1: 131.872 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 78, iters: 400, time: 0.057, data: 0.004) G_GAN: 0.764 G_L1: 0.000 D_real: 0.903 D_fake: 0.537 \n",
            "(epoch: 78, iters: 500, time: 0.059, data: 0.002) G_GAN: 0.664 G_L1: 0.000 D_real: 0.672 D_fake: 0.728 \n",
            "(epoch: 78, iters: 600, time: 0.173, data: 0.004) G_GAN: 0.670 G_L1: 0.000 D_real: 0.664 D_fake: 0.727 \n",
            "(epoch: 78, iters: 700, time: 0.056, data: 0.004) G_GAN: 7.543 G_L1: 121.735 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 78, iters: 800, time: 0.056, data: 0.002) G_GAN: 3.719 G_L1: 29.875 D_real: 0.000 D_fake: 0.036 \n",
            "(epoch: 78, iters: 900, time: 0.058, data: 0.003) G_GAN: 7.662 G_L1: 58.871 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 78, iters: 1000, time: 0.509, data: 0.003) G_GAN: 0.792 G_L1: 0.000 D_real: 0.780 D_fake: 0.620 \n",
            "End of epoch 78 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.057, data: 0.175) G_GAN: 0.842 G_L1: 0.000 D_real: 0.850 D_fake: 0.563 \n",
            "(epoch: 79, iters: 200, time: 0.055, data: 0.003) G_GAN: 0.798 G_L1: 0.000 D_real: 0.901 D_fake: 0.533 \n",
            "(epoch: 79, iters: 300, time: 0.052, data: 0.003) G_GAN: 0.640 G_L1: 0.000 D_real: 0.627 D_fake: 0.772 \n",
            "(epoch: 79, iters: 400, time: 0.607, data: 0.006) G_GAN: 1.059 G_L1: 0.000 D_real: 1.714 D_fake: 0.230 \n",
            "(epoch: 79, iters: 500, time: 0.059, data: 0.008) G_GAN: 4.972 G_L1: 92.165 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 79, iters: 600, time: 0.054, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 1.142 D_fake: 0.392 \n",
            "(epoch: 79, iters: 700, time: 0.057, data: 0.004) G_GAN: 6.342 G_L1: 101.482 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 79, iters: 800, time: 0.167, data: 0.003) G_GAN: 0.660 G_L1: 0.000 D_real: 0.643 D_fake: 0.760 \n",
            "(epoch: 79, iters: 900, time: 0.057, data: 0.003) G_GAN: 4.312 G_L1: 38.107 D_real: 0.000 D_fake: 0.018 \n",
            "(epoch: 79, iters: 1000, time: 0.058, data: 0.003) G_GAN: 0.669 G_L1: 0.000 D_real: 0.662 D_fake: 0.746 \n",
            "End of epoch 79 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.058, data: 0.194) G_GAN: 4.554 G_L1: 39.941 D_real: 0.000 D_fake: 0.014 \n",
            "(epoch: 80, iters: 200, time: 0.653, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.657 D_fake: 0.734 \n",
            "(epoch: 80, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.765 G_L1: 0.000 D_real: 0.777 D_fake: 0.624 \n",
            "(epoch: 80, iters: 400, time: 0.057, data: 0.004) G_GAN: 4.829 G_L1: 59.540 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 80, iters: 500, time: 0.058, data: 0.004) G_GAN: 1.253 G_L1: 5.224 D_real: 0.000 D_fake: 0.486 \n",
            "(epoch: 80, iters: 600, time: 0.182, data: 0.003) G_GAN: 0.684 G_L1: 0.000 D_real: 0.675 D_fake: 0.716 \n",
            "(epoch: 80, iters: 700, time: 0.057, data: 0.007) G_GAN: 0.714 G_L1: 0.000 D_real: 0.719 D_fake: 0.672 \n",
            "(epoch: 80, iters: 800, time: 0.057, data: 0.004) G_GAN: 0.647 G_L1: 0.000 D_real: 0.632 D_fake: 0.763 \n",
            "(epoch: 80, iters: 900, time: 0.056, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.738 D_fake: 0.658 \n",
            "(epoch: 80, iters: 1000, time: 0.674, data: 0.003) G_GAN: 3.062 G_L1: 34.647 D_real: 0.000 D_fake: 0.076 \n",
            "saving the latest model (epoch 80, total_iters 80000)\n",
            "saving the model at the end of epoch 80, iters 80000\n",
            "End of epoch 80 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.055, data: 0.198) G_GAN: 3.167 G_L1: 40.620 D_real: 0.000 D_fake: 0.052 \n",
            "(epoch: 81, iters: 200, time: 0.055, data: 0.003) G_GAN: 0.916 G_L1: 4.338 D_real: 0.000 D_fake: 0.672 \n",
            "(epoch: 81, iters: 300, time: 0.060, data: 0.003) G_GAN: 3.019 G_L1: 28.257 D_real: 0.000 D_fake: 0.067 \n",
            "(epoch: 81, iters: 400, time: 0.751, data: 0.004) G_GAN: 0.760 G_L1: 0.000 D_real: 0.797 D_fake: 0.606 \n",
            "(epoch: 81, iters: 500, time: 0.056, data: 0.004) G_GAN: 6.270 G_L1: 86.689 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 81, iters: 600, time: 0.056, data: 0.005) G_GAN: 6.131 G_L1: 37.370 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 81, iters: 700, time: 0.054, data: 0.003) G_GAN: 5.513 G_L1: 39.428 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 81, iters: 800, time: 0.170, data: 0.003) G_GAN: 0.749 G_L1: 0.000 D_real: 0.795 D_fake: 0.612 \n",
            "(epoch: 81, iters: 900, time: 0.055, data: 0.009) G_GAN: 4.416 G_L1: 78.054 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 81, iters: 1000, time: 0.057, data: 0.003) G_GAN: 8.443 G_L1: 82.536 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 81 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.055, data: 0.184) G_GAN: 0.757 G_L1: 0.000 D_real: 0.777 D_fake: 0.623 \n",
            "(epoch: 82, iters: 200, time: 0.645, data: 0.002) G_GAN: 4.569 G_L1: 100.206 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 82, iters: 300, time: 0.056, data: 0.005) G_GAN: 0.705 G_L1: 0.000 D_real: 0.716 D_fake: 0.684 \n",
            "(epoch: 82, iters: 400, time: 0.057, data: 0.003) G_GAN: 8.077 G_L1: 144.900 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 82, iters: 500, time: 0.059, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.710 D_fake: 0.679 \n",
            "(epoch: 82, iters: 600, time: 0.170, data: 0.003) G_GAN: 2.303 G_L1: 30.874 D_real: 0.000 D_fake: 0.178 \n",
            "(epoch: 82, iters: 700, time: 0.057, data: 0.010) G_GAN: 6.861 G_L1: 54.985 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 82, iters: 800, time: 0.047, data: 0.004) G_GAN: 0.691 G_L1: 0.000 D_real: 0.686 D_fake: 0.708 \n",
            "(epoch: 82, iters: 900, time: 0.055, data: 0.003) G_GAN: 4.983 G_L1: 25.193 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 82, iters: 1000, time: 0.516, data: 0.003) G_GAN: 3.666 G_L1: 23.114 D_real: 0.000 D_fake: 0.032 \n",
            "End of epoch 82 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.062, data: 0.210) G_GAN: 7.642 G_L1: 109.443 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 83, iters: 200, time: 0.055, data: 0.006) G_GAN: 5.244 G_L1: 60.584 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 83, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.684 G_L1: 0.000 D_real: 0.679 D_fake: 0.718 \n",
            "(epoch: 83, iters: 400, time: 0.642, data: 0.003) G_GAN: 0.765 G_L1: 0.000 D_real: 0.798 D_fake: 0.607 \n",
            "(epoch: 83, iters: 500, time: 0.059, data: 0.003) G_GAN: 1.298 G_L1: 5.175 D_real: 0.000 D_fake: 0.513 \n",
            "(epoch: 83, iters: 600, time: 0.055, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.668 \n",
            "(epoch: 83, iters: 700, time: 0.054, data: 0.004) G_GAN: 7.485 G_L1: 51.722 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 83, iters: 800, time: 0.166, data: 0.003) G_GAN: 6.606 G_L1: 149.255 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 83, iters: 900, time: 0.047, data: 0.003) G_GAN: 5.517 G_L1: 52.467 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 83, iters: 1000, time: 0.054, data: 0.005) G_GAN: 3.447 G_L1: 131.149 D_real: 0.000 D_fake: 0.046 \n",
            "End of epoch 83 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 0.056, data: 0.207) G_GAN: 0.709 G_L1: 0.000 D_real: 0.718 D_fake: 0.673 \n",
            "(epoch: 84, iters: 200, time: 0.794, data: 0.003) G_GAN: 0.686 G_L1: 0.000 D_real: 0.674 D_fake: 0.724 \n",
            "(epoch: 84, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
            "(epoch: 84, iters: 400, time: 0.056, data: 0.004) G_GAN: 0.669 G_L1: 0.000 D_real: 0.703 D_fake: 0.693 \n",
            "(epoch: 84, iters: 500, time: 0.055, data: 0.003) G_GAN: 0.784 G_L1: 0.000 D_real: 0.863 D_fake: 0.565 \n",
            "(epoch: 84, iters: 600, time: 0.166, data: 0.002) G_GAN: 3.968 G_L1: 119.753 D_real: 0.000 D_fake: 0.023 \n",
            "(epoch: 84, iters: 700, time: 0.056, data: 0.004) G_GAN: 4.862 G_L1: 23.204 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 84, iters: 800, time: 0.054, data: 0.003) G_GAN: 5.482 G_L1: 52.296 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 84, iters: 900, time: 0.058, data: 0.002) G_GAN: 0.596 G_L1: 0.000 D_real: 0.595 D_fake: 0.811 \n",
            "(epoch: 84, iters: 1000, time: 0.504, data: 0.003) G_GAN: 9.960 G_L1: 122.923 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 84 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.055, data: 0.182) G_GAN: 3.315 G_L1: 40.440 D_real: 0.000 D_fake: 0.053 \n",
            "(epoch: 85, iters: 200, time: 0.060, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 1.080 D_fake: 0.432 \n",
            "(epoch: 85, iters: 300, time: 0.055, data: 0.004) G_GAN: 1.652 G_L1: 11.266 D_real: 0.000 D_fake: 0.383 \n",
            "(epoch: 85, iters: 400, time: 0.669, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.733 D_fake: 0.663 \n",
            "(epoch: 85, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.754 G_L1: 0.000 D_real: 0.823 D_fake: 0.589 \n",
            "(epoch: 85, iters: 600, time: 0.057, data: 0.004) G_GAN: 6.480 G_L1: 133.029 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 85, iters: 700, time: 0.056, data: 0.004) G_GAN: 5.824 G_L1: 51.099 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 85, iters: 800, time: 0.167, data: 0.003) G_GAN: 5.829 G_L1: 200.000 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 85, iters: 900, time: 0.055, data: 0.004) G_GAN: 0.645 G_L1: 0.000 D_real: 0.622 D_fake: 0.785 \n",
            "(epoch: 85, iters: 1000, time: 0.058, data: 0.002) G_GAN: 1.038 G_L1: 0.105 D_real: 0.211 D_fake: 0.525 \n",
            "saving the latest model (epoch 85, total_iters 85000)\n",
            "saving the model at the end of epoch 85, iters 85000\n",
            "End of epoch 85 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.061, data: 0.245) G_GAN: 0.671 G_L1: 0.000 D_real: 0.673 D_fake: 0.717 \n",
            "(epoch: 86, iters: 200, time: 0.634, data: 0.003) G_GAN: 0.769 G_L1: 0.000 D_real: 0.822 D_fake: 0.585 \n",
            "(epoch: 86, iters: 300, time: 0.058, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.780 D_fake: 0.618 \n",
            "(epoch: 86, iters: 400, time: 0.059, data: 0.003) G_GAN: 0.707 G_L1: 0.000 D_real: 0.698 D_fake: 0.693 \n",
            "(epoch: 86, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.685 G_L1: 0.000 D_real: 0.690 D_fake: 0.700 \n",
            "(epoch: 86, iters: 600, time: 0.168, data: 0.007) G_GAN: 0.687 G_L1: 0.000 D_real: 0.710 D_fake: 0.680 \n",
            "(epoch: 86, iters: 700, time: 0.053, data: 0.006) G_GAN: 0.651 G_L1: 0.000 D_real: 0.630 D_fake: 0.776 \n",
            "(epoch: 86, iters: 800, time: 0.054, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.756 D_fake: 0.638 \n",
            "(epoch: 86, iters: 900, time: 0.057, data: 0.003) G_GAN: 2.970 G_L1: 22.592 D_real: 0.000 D_fake: 0.064 \n",
            "(epoch: 86, iters: 1000, time: 0.514, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.676 D_fake: 0.718 \n",
            "End of epoch 86 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.060, data: 0.225) G_GAN: 3.546 G_L1: 154.409 D_real: 0.000 D_fake: 0.047 \n",
            "(epoch: 87, iters: 200, time: 0.052, data: 0.003) G_GAN: 2.885 G_L1: 77.034 D_real: 0.000 D_fake: 0.084 \n",
            "(epoch: 87, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.698 G_L1: 0.000 D_real: 0.694 D_fake: 0.698 \n",
            "(epoch: 87, iters: 400, time: 0.673, data: 0.003) G_GAN: 0.778 G_L1: 0.000 D_real: 0.829 D_fake: 0.580 \n",
            "(epoch: 87, iters: 500, time: 0.056, data: 0.010) G_GAN: 0.754 G_L1: 0.000 D_real: 0.770 D_fake: 0.627 \n",
            "(epoch: 87, iters: 600, time: 0.056, data: 0.004) G_GAN: 7.644 G_L1: 76.228 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 87, iters: 700, time: 0.059, data: 0.003) G_GAN: 1.919 G_L1: 5.646 D_real: 0.000 D_fake: 0.234 \n",
            "(epoch: 87, iters: 800, time: 0.305, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.709 D_fake: 0.684 \n",
            "(epoch: 87, iters: 900, time: 0.056, data: 0.004) G_GAN: 7.405 G_L1: 96.191 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 87, iters: 1000, time: 0.063, data: 0.003) G_GAN: 0.650 G_L1: 0.000 D_real: 0.633 D_fake: 0.771 \n",
            "End of epoch 87 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 0.058, data: 0.200) G_GAN: 2.494 G_L1: 30.987 D_real: 0.001 D_fake: 0.123 \n",
            "(epoch: 88, iters: 200, time: 0.677, data: 0.004) G_GAN: 0.759 G_L1: 0.000 D_real: 0.794 D_fake: 0.611 \n",
            "(epoch: 88, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.676 G_L1: 0.000 D_real: 0.685 D_fake: 0.704 \n",
            "(epoch: 88, iters: 400, time: 0.057, data: 0.002) G_GAN: 7.584 G_L1: 61.435 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 88, iters: 500, time: 0.054, data: 0.003) G_GAN: 6.531 G_L1: 147.834 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 88, iters: 600, time: 0.169, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.674 D_fake: 0.718 \n",
            "(epoch: 88, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.782 G_L1: 0.000 D_real: 0.800 D_fake: 0.601 \n",
            "(epoch: 88, iters: 800, time: 0.051, data: 0.004) G_GAN: 0.740 G_L1: 0.000 D_real: 0.749 D_fake: 0.647 \n",
            "(epoch: 88, iters: 900, time: 0.061, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.734 D_fake: 0.658 \n",
            "(epoch: 88, iters: 1000, time: 0.527, data: 0.003) G_GAN: 0.582 G_L1: 0.000 D_real: 0.568 D_fake: 0.840 \n",
            "End of epoch 88 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.054, data: 0.214) G_GAN: 1.226 G_L1: 8.099 D_real: 0.001 D_fake: 0.476 \n",
            "(epoch: 89, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.671 G_L1: 0.000 D_real: 0.649 D_fake: 0.765 \n",
            "(epoch: 89, iters: 300, time: 0.058, data: 0.003) G_GAN: 6.953 G_L1: 71.101 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 89, iters: 400, time: 0.663, data: 0.002) G_GAN: 2.022 G_L1: 39.924 D_real: 0.000 D_fake: 0.273 \n",
            "(epoch: 89, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.773 G_L1: 0.000 D_real: 0.811 D_fake: 0.595 \n",
            "(epoch: 89, iters: 600, time: 0.061, data: 0.003) G_GAN: 3.651 G_L1: 26.044 D_real: 0.000 D_fake: 0.033 \n",
            "(epoch: 89, iters: 700, time: 0.056, data: 0.004) G_GAN: 5.933 G_L1: 167.516 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 89, iters: 800, time: 0.177, data: 0.003) G_GAN: 7.037 G_L1: 80.036 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 89, iters: 900, time: 0.057, data: 0.009) G_GAN: 0.609 G_L1: 0.000 D_real: 0.553 D_fake: 0.869 \n",
            "(epoch: 89, iters: 1000, time: 0.057, data: 0.003) G_GAN: 5.393 G_L1: 15.310 D_real: 0.002 D_fake: 0.007 \n",
            "End of epoch 89 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.057, data: 0.203) G_GAN: 0.678 G_L1: 0.000 D_real: 0.670 D_fake: 0.721 \n",
            "(epoch: 90, iters: 200, time: 0.649, data: 0.004) G_GAN: 4.099 G_L1: 19.527 D_real: 0.001 D_fake: 0.022 \n",
            "(epoch: 90, iters: 300, time: 0.056, data: 0.004) G_GAN: 0.693 G_L1: 0.000 D_real: 0.691 D_fake: 0.705 \n",
            "(epoch: 90, iters: 400, time: 0.058, data: 0.003) G_GAN: 2.649 G_L1: 15.000 D_real: 0.000 D_fake: 0.098 \n",
            "(epoch: 90, iters: 500, time: 0.056, data: 0.002) G_GAN: 8.097 G_L1: 78.587 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 90, iters: 600, time: 0.173, data: 0.003) G_GAN: 0.666 G_L1: 0.002 D_real: 0.609 D_fake: 0.803 \n",
            "(epoch: 90, iters: 700, time: 0.058, data: 0.005) G_GAN: 6.916 G_L1: 137.499 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 90, iters: 800, time: 0.056, data: 0.006) G_GAN: 0.747 G_L1: 0.000 D_real: 0.776 D_fake: 0.628 \n",
            "(epoch: 90, iters: 900, time: 0.059, data: 0.003) G_GAN: 7.475 G_L1: 92.350 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 90, iters: 1000, time: 0.533, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.688 D_fake: 0.701 \n",
            "saving the latest model (epoch 90, total_iters 90000)\n",
            "saving the model at the end of epoch 90, iters 90000\n",
            "End of epoch 90 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.056, data: 0.196) G_GAN: 4.169 G_L1: 32.330 D_real: 0.000 D_fake: 0.019 \n",
            "(epoch: 91, iters: 200, time: 0.056, data: 0.003) G_GAN: 6.736 G_L1: 88.777 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 91, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.915 D_fake: 0.526 \n",
            "(epoch: 91, iters: 400, time: 0.685, data: 0.002) G_GAN: 5.537 G_L1: 30.078 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 91, iters: 500, time: 0.057, data: 0.005) G_GAN: 2.295 G_L1: 9.618 D_real: 0.001 D_fake: 0.138 \n",
            "(epoch: 91, iters: 600, time: 0.057, data: 0.003) G_GAN: 2.226 G_L1: 5.840 D_real: 0.000 D_fake: 0.140 \n",
            "(epoch: 91, iters: 700, time: 0.052, data: 0.002) G_GAN: 1.911 G_L1: 61.252 D_real: 0.000 D_fake: 0.248 \n",
            "(epoch: 91, iters: 800, time: 0.165, data: 0.003) G_GAN: 0.705 G_L1: 0.000 D_real: 0.714 D_fake: 0.680 \n",
            "(epoch: 91, iters: 900, time: 0.052, data: 0.005) G_GAN: 0.761 G_L1: 0.000 D_real: 0.857 D_fake: 0.565 \n",
            "(epoch: 91, iters: 1000, time: 0.058, data: 0.005) G_GAN: 0.666 G_L1: 0.001 D_real: 0.564 D_fake: 0.861 \n",
            "End of epoch 91 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 0.057, data: 0.215) G_GAN: 5.239 G_L1: 36.016 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 92, iters: 200, time: 0.678, data: 0.005) G_GAN: 2.670 G_L1: 60.155 D_real: 0.000 D_fake: 0.098 \n",
            "(epoch: 92, iters: 300, time: 0.055, data: 0.007) G_GAN: 3.360 G_L1: 49.541 D_real: 0.000 D_fake: 0.044 \n",
            "(epoch: 92, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.694 D_fake: 0.717 \n",
            "(epoch: 92, iters: 500, time: 0.055, data: 0.002) G_GAN: 6.549 G_L1: 140.485 D_real: 0.022 D_fake: 0.002 \n",
            "(epoch: 92, iters: 600, time: 0.173, data: 0.003) G_GAN: 2.259 G_L1: 62.380 D_real: 0.000 D_fake: 0.136 \n",
            "(epoch: 92, iters: 700, time: 0.045, data: 0.006) G_GAN: 3.324 G_L1: 24.464 D_real: 0.000 D_fake: 0.046 \n",
            "(epoch: 92, iters: 800, time: 0.055, data: 0.009) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.708 \n",
            "(epoch: 92, iters: 900, time: 0.053, data: 0.004) G_GAN: 2.285 G_L1: 2.567 D_real: 0.005 D_fake: 0.240 \n",
            "(epoch: 92, iters: 1000, time: 0.528, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.682 D_fake: 0.715 \n",
            "End of epoch 92 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.056, data: 0.199) G_GAN: 0.673 G_L1: 0.000 D_real: 0.664 D_fake: 0.726 \n",
            "(epoch: 93, iters: 200, time: 0.056, data: 0.003) G_GAN: 4.269 G_L1: 16.746 D_real: 0.000 D_fake: 0.018 \n",
            "(epoch: 93, iters: 300, time: 0.057, data: 0.003) G_GAN: 4.466 G_L1: 91.064 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 93, iters: 400, time: 0.683, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.698 D_fake: 0.694 \n",
            "(epoch: 93, iters: 500, time: 0.056, data: 0.003) G_GAN: 2.022 G_L1: 12.081 D_real: 0.001 D_fake: 0.202 \n",
            "(epoch: 93, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.684 G_L1: 0.000 D_real: 0.682 D_fake: 0.712 \n",
            "(epoch: 93, iters: 700, time: 0.058, data: 0.003) G_GAN: 6.087 G_L1: 112.459 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 93, iters: 800, time: 0.165, data: 0.003) G_GAN: 0.683 G_L1: 0.000 D_real: 0.640 D_fake: 0.797 \n",
            "(epoch: 93, iters: 900, time: 0.055, data: 0.002) G_GAN: 2.459 G_L1: 54.670 D_real: 0.000 D_fake: 0.146 \n",
            "(epoch: 93, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.683 G_L1: 0.000 D_real: 0.680 D_fake: 0.711 \n",
            "End of epoch 93 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.060, data: 0.197) G_GAN: 4.942 G_L1: 165.847 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 94, iters: 200, time: 0.790, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.753 D_fake: 0.645 \n",
            "(epoch: 94, iters: 300, time: 0.063, data: 0.003) G_GAN: 6.948 G_L1: 66.061 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 94, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.666 D_fake: 0.730 \n",
            "(epoch: 94, iters: 500, time: 0.056, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.672 \n",
            "(epoch: 94, iters: 600, time: 0.167, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.806 D_fake: 0.611 \n",
            "(epoch: 94, iters: 700, time: 0.058, data: 0.004) G_GAN: 0.724 G_L1: 0.000 D_real: 0.774 D_fake: 0.632 \n",
            "(epoch: 94, iters: 800, time: 0.056, data: 0.003) G_GAN: 2.022 G_L1: 14.093 D_real: 0.000 D_fake: 0.211 \n",
            "(epoch: 94, iters: 900, time: 0.057, data: 0.002) G_GAN: 0.609 G_L1: 0.000 D_real: 0.595 D_fake: 0.810 \n",
            "(epoch: 94, iters: 1000, time: 0.548, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.762 D_fake: 0.641 \n",
            "End of epoch 94 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.056, data: 0.224) G_GAN: 0.675 G_L1: 0.000 D_real: 0.689 D_fake: 0.704 \n",
            "(epoch: 95, iters: 200, time: 0.057, data: 0.002) G_GAN: 0.527 G_L1: 0.000 D_real: 0.523 D_fake: 0.942 \n",
            "(epoch: 95, iters: 300, time: 0.058, data: 0.004) G_GAN: 6.961 G_L1: 114.115 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 95, iters: 400, time: 0.699, data: 0.003) G_GAN: 5.349 G_L1: 113.107 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 95, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.654 G_L1: 0.000 D_real: 0.620 D_fake: 0.782 \n",
            "(epoch: 95, iters: 600, time: 0.058, data: 0.003) G_GAN: 0.625 G_L1: 0.000 D_real: 0.643 D_fake: 0.794 \n",
            "(epoch: 95, iters: 700, time: 0.056, data: 0.003) G_GAN: 2.893 G_L1: 47.343 D_real: 0.000 D_fake: 0.070 \n",
            "(epoch: 95, iters: 800, time: 0.166, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.717 D_fake: 0.681 \n",
            "(epoch: 95, iters: 900, time: 0.055, data: 0.005) G_GAN: 0.655 G_L1: 0.000 D_real: 0.643 D_fake: 0.750 \n",
            "(epoch: 95, iters: 1000, time: 0.056, data: 0.005) G_GAN: 0.508 G_L1: 0.000 D_real: 0.441 D_fake: 1.114 \n",
            "saving the latest model (epoch 95, total_iters 95000)\n",
            "saving the model at the end of epoch 95, iters 95000\n",
            "End of epoch 95 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 0.059, data: 0.243) G_GAN: 4.986 G_L1: 25.068 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 96, iters: 200, time: 0.687, data: 0.004) G_GAN: 4.670 G_L1: 84.127 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 96, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.646 G_L1: 0.000 D_real: 0.627 D_fake: 0.768 \n",
            "(epoch: 96, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.725 D_fake: 0.672 \n",
            "(epoch: 96, iters: 500, time: 0.055, data: 0.003) G_GAN: 1.589 G_L1: 1.027 D_real: 0.017 D_fake: 0.346 \n",
            "(epoch: 96, iters: 600, time: 0.162, data: 0.003) G_GAN: 4.481 G_L1: 83.787 D_real: 0.003 D_fake: 0.015 \n",
            "(epoch: 96, iters: 700, time: 0.055, data: 0.004) G_GAN: 0.646 G_L1: 0.001 D_real: 0.666 D_fake: 0.728 \n",
            "(epoch: 96, iters: 800, time: 0.069, data: 0.007) G_GAN: 0.800 G_L1: 0.000 D_real: 0.842 D_fake: 0.571 \n",
            "(epoch: 96, iters: 900, time: 0.055, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.712 D_fake: 0.681 \n",
            "(epoch: 96, iters: 1000, time: 0.566, data: 0.003) G_GAN: 0.830 G_L1: 0.000 D_real: 0.913 D_fake: 0.520 \n",
            "End of epoch 96 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.061, data: 0.234) G_GAN: 0.802 G_L1: 0.000 D_real: 0.841 D_fake: 0.569 \n",
            "(epoch: 97, iters: 200, time: 0.059, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.729 D_fake: 0.662 \n",
            "(epoch: 97, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.686 G_L1: 0.000 D_real: 0.684 D_fake: 0.707 \n",
            "(epoch: 97, iters: 400, time: 0.812, data: 0.002) G_GAN: 7.271 G_L1: 29.067 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 97, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.704 D_fake: 0.685 \n",
            "(epoch: 97, iters: 600, time: 0.058, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.716 D_fake: 0.675 \n",
            "(epoch: 97, iters: 700, time: 0.056, data: 0.003) G_GAN: 1.391 G_L1: 1.589 D_real: 0.076 D_fake: 0.526 \n",
            "(epoch: 97, iters: 800, time: 0.168, data: 0.003) G_GAN: 0.840 G_L1: 0.000 D_real: 0.960 D_fake: 0.488 \n",
            "(epoch: 97, iters: 900, time: 0.054, data: 0.003) G_GAN: 1.726 G_L1: 1.428 D_real: 0.004 D_fake: 0.294 \n",
            "(epoch: 97, iters: 1000, time: 0.058, data: 0.002) G_GAN: 0.695 G_L1: 0.029 D_real: 0.690 D_fake: 0.712 \n",
            "End of epoch 97 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.060, data: 0.190) G_GAN: 5.513 G_L1: 200.000 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 98, iters: 200, time: 0.699, data: 0.004) G_GAN: 4.508 G_L1: 69.536 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 98, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.891 G_L1: 0.000 D_real: 1.179 D_fake: 0.381 \n",
            "(epoch: 98, iters: 400, time: 0.056, data: 0.003) G_GAN: 0.683 G_L1: 0.000 D_real: 0.661 D_fake: 0.738 \n",
            "(epoch: 98, iters: 500, time: 0.055, data: 0.003) G_GAN: 4.040 G_L1: 72.761 D_real: 0.000 D_fake: 0.022 \n",
            "(epoch: 98, iters: 600, time: 0.169, data: 0.004) G_GAN: 8.214 G_L1: 126.874 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 98, iters: 700, time: 0.059, data: 0.012) G_GAN: 0.654 G_L1: 0.000 D_real: 0.683 D_fake: 0.707 \n",
            "(epoch: 98, iters: 800, time: 0.056, data: 0.004) G_GAN: 4.648 G_L1: 132.971 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 98, iters: 900, time: 0.055, data: 0.003) G_GAN: 0.750 G_L1: 0.000 D_real: 0.794 D_fake: 0.606 \n",
            "(epoch: 98, iters: 1000, time: 0.524, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.711 D_fake: 0.690 \n",
            "End of epoch 98 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.057, data: 0.182) G_GAN: 4.133 G_L1: 5.937 D_real: 0.025 D_fake: 0.020 \n",
            "(epoch: 99, iters: 200, time: 0.056, data: 0.004) G_GAN: 7.194 G_L1: 85.975 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 99, iters: 300, time: 0.055, data: 0.002) G_GAN: 0.728 G_L1: 0.001 D_real: 0.739 D_fake: 0.656 \n",
            "(epoch: 99, iters: 400, time: 0.699, data: 0.002) G_GAN: 5.901 G_L1: 100.476 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 99, iters: 500, time: 0.055, data: 0.007) G_GAN: 0.747 G_L1: 0.000 D_real: 0.763 D_fake: 0.639 \n",
            "(epoch: 99, iters: 600, time: 0.056, data: 0.003) G_GAN: 4.660 G_L1: 35.745 D_real: 0.000 D_fake: 0.017 \n",
            "(epoch: 99, iters: 700, time: 0.059, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.668 D_fake: 0.725 \n",
            "(epoch: 99, iters: 800, time: 0.176, data: 0.003) G_GAN: 1.070 G_L1: 0.077 D_real: 2.016 D_fake: 0.157 \n",
            "(epoch: 99, iters: 900, time: 0.053, data: 0.004) G_GAN: 3.404 G_L1: 88.310 D_real: 0.000 D_fake: 0.047 \n",
            "(epoch: 99, iters: 1000, time: 0.057, data: 0.008) G_GAN: 2.320 G_L1: 16.005 D_real: 0.000 D_fake: 0.158 \n",
            "End of epoch 99 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 0.057, data: 0.199) G_GAN: 7.210 G_L1: 53.855 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 100, iters: 200, time: 0.716, data: 0.002) G_GAN: 0.806 G_L1: 0.000 D_real: 0.881 D_fake: 0.547 \n",
            "(epoch: 100, iters: 300, time: 0.051, data: 0.009) G_GAN: 0.703 G_L1: 0.000 D_real: 0.708 D_fake: 0.683 \n",
            "(epoch: 100, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.654 D_fake: 0.745 \n",
            "(epoch: 100, iters: 500, time: 0.055, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.680 D_fake: 0.713 \n",
            "(epoch: 100, iters: 600, time: 0.155, data: 0.003) G_GAN: 5.879 G_L1: 200.000 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 100, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.799 G_L1: 0.000 D_real: 0.837 D_fake: 0.582 \n",
            "(epoch: 100, iters: 800, time: 0.059, data: 0.003) G_GAN: 0.664 G_L1: 0.000 D_real: 0.648 D_fake: 0.751 \n",
            "(epoch: 100, iters: 900, time: 0.067, data: 0.004) G_GAN: 0.712 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
            "(epoch: 100, iters: 1000, time: 0.648, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.752 D_fake: 0.645 \n",
            "saving the latest model (epoch 100, total_iters 100000)\n",
            "saving the model at the end of epoch 100, iters 100000\n",
            "End of epoch 100 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.056, data: 0.245) G_GAN: 0.704 G_L1: 0.000 D_real: 0.698 D_fake: 0.702 \n",
            "(epoch: 101, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.824 G_L1: 0.008 D_real: 0.856 D_fake: 0.559 \n",
            "(epoch: 101, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.678 G_L1: 0.001 D_real: 0.673 D_fake: 0.723 \n",
            "(epoch: 101, iters: 400, time: 0.742, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.746 D_fake: 0.649 \n",
            "(epoch: 101, iters: 500, time: 0.059, data: 0.006) G_GAN: 0.850 G_L1: 0.000 D_real: 0.871 D_fake: 0.549 \n",
            "(epoch: 101, iters: 600, time: 0.054, data: 0.002) G_GAN: 3.277 G_L1: 28.787 D_real: 0.000 D_fake: 0.052 \n",
            "(epoch: 101, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.849 D_fake: 0.568 \n",
            "(epoch: 101, iters: 800, time: 0.154, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.753 D_fake: 0.649 \n",
            "(epoch: 101, iters: 900, time: 0.056, data: 0.014) G_GAN: 2.903 G_L1: 60.903 D_real: 0.000 D_fake: 0.122 \n",
            "(epoch: 101, iters: 1000, time: 0.054, data: 0.003) G_GAN: 0.652 G_L1: 0.000 D_real: 0.614 D_fake: 0.786 \n",
            "End of epoch 101 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.062, data: 0.224) G_GAN: 0.688 G_L1: 0.000 D_real: 0.675 D_fake: 0.721 \n",
            "(epoch: 102, iters: 200, time: 0.704, data: 0.003) G_GAN: 3.801 G_L1: 1.336 D_real: 0.229 D_fake: 0.051 \n",
            "(epoch: 102, iters: 300, time: 0.056, data: 0.005) G_GAN: 6.239 G_L1: 84.829 D_real: 0.028 D_fake: 0.009 \n",
            "(epoch: 102, iters: 400, time: 0.059, data: 0.002) G_GAN: 2.755 G_L1: 0.640 D_real: 0.503 D_fake: 0.081 \n",
            "(epoch: 102, iters: 500, time: 0.056, data: 0.003) G_GAN: 2.494 G_L1: 28.066 D_real: 0.479 D_fake: 0.224 \n",
            "(epoch: 102, iters: 600, time: 0.167, data: 0.002) G_GAN: 1.265 G_L1: 4.743 D_real: 0.060 D_fake: 1.434 \n",
            "(epoch: 102, iters: 700, time: 0.058, data: 0.006) G_GAN: 4.686 G_L1: 1.203 D_real: 0.188 D_fake: 0.024 \n",
            "(epoch: 102, iters: 800, time: 0.061, data: 0.003) G_GAN: 2.281 G_L1: 4.139 D_real: 0.005 D_fake: 1.819 \n",
            "(epoch: 102, iters: 900, time: 0.060, data: 0.003) G_GAN: 1.245 G_L1: 0.090 D_real: 0.290 D_fake: 0.382 \n",
            "(epoch: 102, iters: 1000, time: 0.526, data: 0.002) G_GAN: 1.698 G_L1: 0.157 D_real: 0.387 D_fake: 0.209 \n",
            "End of epoch 102 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.058, data: 0.198) G_GAN: 5.525 G_L1: 54.064 D_real: 0.001 D_fake: 0.016 \n",
            "(epoch: 103, iters: 200, time: 0.059, data: 0.003) G_GAN: 2.301 G_L1: 18.901 D_real: 0.087 D_fake: 0.286 \n",
            "(epoch: 103, iters: 300, time: 0.059, data: 0.005) G_GAN: 3.567 G_L1: 4.185 D_real: 0.013 D_fake: 0.073 \n",
            "(epoch: 103, iters: 400, time: 0.684, data: 0.002) G_GAN: 2.821 G_L1: 2.621 D_real: 0.170 D_fake: 0.099 \n",
            "(epoch: 103, iters: 500, time: 0.054, data: 0.004) G_GAN: 4.393 G_L1: 0.795 D_real: 0.211 D_fake: 0.021 \n",
            "(epoch: 103, iters: 600, time: 0.059, data: 0.003) G_GAN: 3.267 G_L1: 15.211 D_real: 0.120 D_fake: 0.067 \n",
            "(epoch: 103, iters: 700, time: 0.057, data: 0.002) G_GAN: 0.941 G_L1: 0.037 D_real: 0.331 D_fake: 0.453 \n",
            "(epoch: 103, iters: 800, time: 0.282, data: 0.002) G_GAN: 5.382 G_L1: 19.422 D_real: 0.066 D_fake: 0.008 \n",
            "(epoch: 103, iters: 900, time: 0.058, data: 0.006) G_GAN: 0.661 G_L1: 0.008 D_real: 0.750 D_fake: 0.647 \n",
            "(epoch: 103, iters: 1000, time: 0.058, data: 0.003) G_GAN: 4.843 G_L1: 9.774 D_real: 0.060 D_fake: 0.016 \n",
            "End of epoch 103 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 0.059, data: 0.214) G_GAN: 0.869 G_L1: 5.840 D_real: 0.015 D_fake: 2.161 \n",
            "(epoch: 104, iters: 200, time: 0.754, data: 0.007) G_GAN: 0.897 G_L1: 0.009 D_real: 0.408 D_fake: 0.596 \n",
            "(epoch: 104, iters: 300, time: 0.056, data: 0.005) G_GAN: 2.673 G_L1: 12.393 D_real: 0.267 D_fake: 0.294 \n",
            "(epoch: 104, iters: 400, time: 0.059, data: 0.003) G_GAN: 5.152 G_L1: 35.587 D_real: 0.023 D_fake: 0.009 \n",
            "(epoch: 104, iters: 500, time: 0.058, data: 0.003) G_GAN: 2.715 G_L1: 4.119 D_real: 0.098 D_fake: 0.096 \n",
            "(epoch: 104, iters: 600, time: 0.174, data: 0.003) G_GAN: 3.715 G_L1: 14.744 D_real: 0.474 D_fake: 0.069 \n",
            "(epoch: 104, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.630 G_L1: 0.000 D_real: 0.585 D_fake: 0.827 \n",
            "(epoch: 104, iters: 800, time: 0.058, data: 0.003) G_GAN: 5.478 G_L1: 18.059 D_real: 0.155 D_fake: 0.016 \n",
            "(epoch: 104, iters: 900, time: 0.053, data: 0.003) G_GAN: 0.781 G_L1: 0.000 D_real: 0.735 D_fake: 0.682 \n",
            "(epoch: 104, iters: 1000, time: 0.571, data: 0.002) G_GAN: 7.228 G_L1: 0.455 D_real: 0.414 D_fake: 0.002 \n",
            "End of epoch 104 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.055, data: 0.211) G_GAN: 0.700 G_L1: 0.000 D_real: 0.686 D_fake: 0.734 \n",
            "(epoch: 105, iters: 200, time: 0.056, data: 0.003) G_GAN: 0.579 G_L1: 0.005 D_real: 0.450 D_fake: 0.979 \n",
            "(epoch: 105, iters: 300, time: 0.056, data: 0.002) G_GAN: 5.014 G_L1: 20.503 D_real: 0.011 D_fake: 0.015 \n",
            "(epoch: 105, iters: 400, time: 0.710, data: 0.003) G_GAN: 0.503 G_L1: 0.000 D_real: 0.466 D_fake: 1.011 \n",
            "(epoch: 105, iters: 500, time: 0.060, data: 0.007) G_GAN: 2.673 G_L1: 0.032 D_real: 0.576 D_fake: 0.074 \n",
            "(epoch: 105, iters: 600, time: 0.057, data: 0.002) G_GAN: 1.673 G_L1: 27.413 D_real: 0.102 D_fake: 0.441 \n",
            "(epoch: 105, iters: 700, time: 0.056, data: 0.003) G_GAN: 4.404 G_L1: 57.536 D_real: 0.315 D_fake: 0.015 \n",
            "(epoch: 105, iters: 800, time: 0.169, data: 0.003) G_GAN: 2.096 G_L1: 25.290 D_real: 0.071 D_fake: 0.229 \n",
            "(epoch: 105, iters: 900, time: 0.059, data: 0.004) G_GAN: 1.354 G_L1: 18.147 D_real: 0.011 D_fake: 2.693 \n",
            "(epoch: 105, iters: 1000, time: 0.059, data: 0.006) G_GAN: 1.324 G_L1: 7.941 D_real: 0.248 D_fake: 1.274 \n",
            "saving the latest model (epoch 105, total_iters 105000)\n",
            "saving the model at the end of epoch 105, iters 105000\n",
            "End of epoch 105 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.058, data: 0.262) G_GAN: 0.506 G_L1: 0.000 D_real: 0.482 D_fake: 0.968 \n",
            "(epoch: 106, iters: 200, time: 0.738, data: 0.002) G_GAN: 0.548 G_L1: 0.000 D_real: 0.505 D_fake: 0.951 \n",
            "(epoch: 106, iters: 300, time: 0.058, data: 0.004) G_GAN: 0.745 G_L1: 0.000 D_real: 0.792 D_fake: 0.619 \n",
            "(epoch: 106, iters: 400, time: 0.059, data: 0.007) G_GAN: 6.679 G_L1: 7.519 D_real: 0.029 D_fake: 0.002 \n",
            "(epoch: 106, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.657 G_L1: 0.000 D_real: 0.626 D_fake: 0.766 \n",
            "(epoch: 106, iters: 600, time: 0.174, data: 0.003) G_GAN: 7.853 G_L1: 10.833 D_real: 0.334 D_fake: 0.001 \n",
            "(epoch: 106, iters: 700, time: 0.061, data: 0.011) G_GAN: 0.766 G_L1: 0.000 D_real: 0.891 D_fake: 0.548 \n",
            "(epoch: 106, iters: 800, time: 0.056, data: 0.005) G_GAN: 3.609 G_L1: 11.683 D_real: 0.115 D_fake: 0.036 \n",
            "(epoch: 106, iters: 900, time: 0.057, data: 0.003) G_GAN: 1.589 G_L1: 0.327 D_real: 1.513 D_fake: 0.252 \n",
            "(epoch: 106, iters: 1000, time: 0.640, data: 0.005) G_GAN: 3.512 G_L1: 0.173 D_real: 0.462 D_fake: 0.045 \n",
            "End of epoch 106 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.058, data: 0.207) G_GAN: 0.609 G_L1: 0.000 D_real: 0.618 D_fake: 0.782 \n",
            "(epoch: 107, iters: 200, time: 0.059, data: 0.002) G_GAN: 2.212 G_L1: 0.013 D_real: 0.482 D_fake: 0.124 \n",
            "(epoch: 107, iters: 300, time: 0.053, data: 0.003) G_GAN: 0.649 G_L1: 0.000 D_real: 0.670 D_fake: 0.731 \n",
            "(epoch: 107, iters: 400, time: 0.737, data: 0.003) G_GAN: 0.679 G_L1: 0.000 D_real: 0.629 D_fake: 0.811 \n",
            "(epoch: 107, iters: 500, time: 0.054, data: 0.003) G_GAN: 5.925 G_L1: 20.948 D_real: 0.587 D_fake: 0.005 \n",
            "(epoch: 107, iters: 600, time: 0.057, data: 0.004) G_GAN: 4.495 G_L1: 0.021 D_real: 0.614 D_fake: 0.015 \n",
            "(epoch: 107, iters: 700, time: 0.056, data: 0.002) G_GAN: 0.559 G_L1: 0.000 D_real: 0.528 D_fake: 0.896 \n",
            "(epoch: 107, iters: 800, time: 0.190, data: 0.003) G_GAN: 5.718 G_L1: 10.944 D_real: 0.226 D_fake: 0.004 \n",
            "(epoch: 107, iters: 900, time: 0.057, data: 0.011) G_GAN: 5.730 G_L1: 11.416 D_real: 0.510 D_fake: 0.007 \n",
            "(epoch: 107, iters: 1000, time: 0.059, data: 0.003) G_GAN: 0.630 G_L1: 0.000 D_real: 0.614 D_fake: 0.791 \n",
            "End of epoch 107 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 0.055, data: 0.219) G_GAN: 0.486 G_L1: 0.001 D_real: 0.472 D_fake: 0.977 \n",
            "(epoch: 108, iters: 200, time: 0.731, data: 0.007) G_GAN: 0.691 G_L1: 0.000 D_real: 0.823 D_fake: 0.599 \n",
            "(epoch: 108, iters: 300, time: 0.052, data: 0.009) G_GAN: 1.527 G_L1: 9.762 D_real: 0.482 D_fake: 0.183 \n",
            "(epoch: 108, iters: 400, time: 0.055, data: 0.004) G_GAN: 3.555 G_L1: 12.797 D_real: 0.087 D_fake: 0.050 \n",
            "(epoch: 108, iters: 500, time: 0.056, data: 0.003) G_GAN: 6.660 G_L1: 0.327 D_real: 0.436 D_fake: 0.003 \n",
            "(epoch: 108, iters: 600, time: 0.153, data: 0.003) G_GAN: 1.023 G_L1: 63.569 D_real: 0.118 D_fake: 0.552 \n",
            "(epoch: 108, iters: 700, time: 0.058, data: 0.003) G_GAN: 1.357 G_L1: 5.455 D_real: 0.082 D_fake: 0.590 \n",
            "(epoch: 108, iters: 800, time: 0.057, data: 0.003) G_GAN: 5.038 G_L1: 8.202 D_real: 0.029 D_fake: 0.010 \n",
            "(epoch: 108, iters: 900, time: 0.056, data: 0.003) G_GAN: 0.639 G_L1: 0.000 D_real: 0.625 D_fake: 0.771 \n",
            "(epoch: 108, iters: 1000, time: 0.596, data: 0.002) G_GAN: 4.224 G_L1: 8.254 D_real: 0.118 D_fake: 0.024 \n",
            "End of epoch 108 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.056, data: 0.211) G_GAN: 0.900 G_L1: 0.002 D_real: 0.789 D_fake: 0.540 \n",
            "(epoch: 109, iters: 200, time: 0.057, data: 0.004) G_GAN: 3.917 G_L1: 11.446 D_real: 0.130 D_fake: 0.044 \n",
            "(epoch: 109, iters: 300, time: 0.056, data: 0.003) G_GAN: 5.949 G_L1: 65.319 D_real: 0.035 D_fake: 0.005 \n",
            "(epoch: 109, iters: 400, time: 0.729, data: 0.002) G_GAN: 0.498 G_L1: 0.001 D_real: 0.429 D_fake: 1.074 \n",
            "(epoch: 109, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.346 G_L1: 1.204 D_real: 0.065 D_fake: 3.127 \n",
            "(epoch: 109, iters: 600, time: 0.058, data: 0.004) G_GAN: 6.779 G_L1: 23.737 D_real: 1.248 D_fake: 0.002 \n",
            "(epoch: 109, iters: 700, time: 0.058, data: 0.004) G_GAN: 0.771 G_L1: 0.000 D_real: 0.788 D_fake: 0.610 \n",
            "(epoch: 109, iters: 800, time: 0.275, data: 0.002) G_GAN: 0.489 G_L1: 0.000 D_real: 0.455 D_fake: 1.019 \n",
            "(epoch: 109, iters: 900, time: 0.058, data: 0.010) G_GAN: 6.061 G_L1: 4.412 D_real: 0.022 D_fake: 0.005 \n",
            "(epoch: 109, iters: 1000, time: 0.058, data: 0.003) G_GAN: 0.594 G_L1: 0.000 D_real: 0.594 D_fake: 0.811 \n",
            "End of epoch 109 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.056, data: 0.177) G_GAN: 0.572 G_L1: 0.000 D_real: 0.576 D_fake: 0.846 \n",
            "(epoch: 110, iters: 200, time: 0.736, data: 0.003) G_GAN: 6.188 G_L1: 21.200 D_real: 0.280 D_fake: 0.004 \n",
            "(epoch: 110, iters: 300, time: 0.054, data: 0.003) G_GAN: 2.867 G_L1: 14.310 D_real: 0.166 D_fake: 0.066 \n",
            "(epoch: 110, iters: 400, time: 0.049, data: 0.004) G_GAN: 3.087 G_L1: 0.045 D_real: 0.570 D_fake: 0.049 \n",
            "(epoch: 110, iters: 500, time: 0.059, data: 0.002) G_GAN: 0.500 G_L1: 0.000 D_real: 0.495 D_fake: 0.944 \n",
            "(epoch: 110, iters: 600, time: 0.185, data: 0.003) G_GAN: 6.206 G_L1: 17.838 D_real: 0.400 D_fake: 0.003 \n",
            "(epoch: 110, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.636 G_L1: 0.000 D_real: 0.622 D_fake: 0.772 \n",
            "(epoch: 110, iters: 800, time: 0.057, data: 0.002) G_GAN: 4.429 G_L1: 0.246 D_real: 0.538 D_fake: 0.016 \n",
            "(epoch: 110, iters: 900, time: 0.057, data: 0.004) G_GAN: 0.594 G_L1: 2.821 D_real: 0.582 D_fake: 1.083 \n",
            "(epoch: 110, iters: 1000, time: 0.615, data: 0.003) G_GAN: 0.650 G_L1: 0.000 D_real: 0.590 D_fake: 0.819 \n",
            "saving the latest model (epoch 110, total_iters 110000)\n",
            "saving the model at the end of epoch 110, iters 110000\n",
            "End of epoch 110 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.058, data: 0.194) G_GAN: 0.484 G_L1: 2.676 D_real: 0.169 D_fake: 2.276 \n",
            "(epoch: 111, iters: 200, time: 0.058, data: 0.005) G_GAN: 0.712 G_L1: 0.000 D_real: 1.023 D_fake: 0.460 \n",
            "(epoch: 111, iters: 300, time: 0.056, data: 0.003) G_GAN: 2.477 G_L1: 35.554 D_real: 0.141 D_fake: 0.125 \n",
            "(epoch: 111, iters: 400, time: 0.809, data: 0.004) G_GAN: 0.178 G_L1: 3.984 D_real: 0.050 D_fake: 2.925 \n",
            "(epoch: 111, iters: 500, time: 0.056, data: 0.003) G_GAN: 1.788 G_L1: 15.181 D_real: 0.146 D_fake: 0.229 \n",
            "(epoch: 111, iters: 600, time: 0.056, data: 0.004) G_GAN: 0.566 G_L1: 0.000 D_real: 0.545 D_fake: 0.869 \n",
            "(epoch: 111, iters: 700, time: 0.060, data: 0.003) G_GAN: 0.778 G_L1: 0.000 D_real: 0.794 D_fake: 0.605 \n",
            "(epoch: 111, iters: 800, time: 0.171, data: 0.003) G_GAN: 0.562 G_L1: 0.000 D_real: 0.563 D_fake: 0.863 \n",
            "(epoch: 111, iters: 900, time: 0.061, data: 0.003) G_GAN: 6.599 G_L1: 109.440 D_real: 0.129 D_fake: 0.003 \n",
            "(epoch: 111, iters: 1000, time: 0.053, data: 0.003) G_GAN: 2.781 G_L1: 11.504 D_real: 0.389 D_fake: 0.069 \n",
            "End of epoch 111 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 0.055, data: 0.186) G_GAN: 0.654 G_L1: 0.000 D_real: 0.645 D_fake: 0.750 \n",
            "(epoch: 112, iters: 200, time: 0.737, data: 0.002) G_GAN: 2.562 G_L1: 13.832 D_real: 0.163 D_fake: 0.098 \n",
            "(epoch: 112, iters: 300, time: 0.055, data: 0.003) G_GAN: 2.702 G_L1: 6.749 D_real: 0.473 D_fake: 0.060 \n",
            "(epoch: 112, iters: 400, time: 0.055, data: 0.003) G_GAN: 0.497 G_L1: 0.000 D_real: 0.456 D_fake: 1.017 \n",
            "(epoch: 112, iters: 500, time: 0.052, data: 0.002) G_GAN: 0.424 G_L1: 2.793 D_real: 0.548 D_fake: 1.445 \n",
            "(epoch: 112, iters: 600, time: 0.166, data: 0.003) G_GAN: 0.681 G_L1: 0.000 D_real: 0.663 D_fake: 0.730 \n",
            "(epoch: 112, iters: 700, time: 0.064, data: 0.005) G_GAN: 0.639 G_L1: 0.000 D_real: 0.632 D_fake: 0.763 \n",
            "(epoch: 112, iters: 800, time: 0.056, data: 0.003) G_GAN: 0.673 G_L1: 0.000 D_real: 0.671 D_fake: 0.731 \n",
            "(epoch: 112, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.650 G_L1: 0.000 D_real: 0.641 D_fake: 0.757 \n",
            "(epoch: 112, iters: 1000, time: 0.707, data: 0.002) G_GAN: 7.384 G_L1: 4.181 D_real: 0.501 D_fake: 0.002 \n",
            "End of epoch 112 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.065, data: 0.238) G_GAN: 0.772 G_L1: 0.939 D_real: 0.195 D_fake: 1.194 \n",
            "(epoch: 113, iters: 200, time: 0.056, data: 0.004) G_GAN: 0.634 G_L1: 0.000 D_real: 0.617 D_fake: 0.780 \n",
            "(epoch: 113, iters: 300, time: 0.058, data: 0.003) G_GAN: 0.610 G_L1: 0.000 D_real: 0.591 D_fake: 0.814 \n",
            "(epoch: 113, iters: 400, time: 0.739, data: 0.003) G_GAN: 0.682 G_L1: 0.000 D_real: 0.680 D_fake: 0.718 \n",
            "(epoch: 113, iters: 500, time: 0.055, data: 0.003) G_GAN: 1.977 G_L1: 10.006 D_real: 0.296 D_fake: 0.204 \n",
            "(epoch: 113, iters: 600, time: 0.059, data: 0.004) G_GAN: 0.388 G_L1: 28.029 D_real: 0.100 D_fake: 2.011 \n",
            "(epoch: 113, iters: 700, time: 0.057, data: 0.003) G_GAN: 1.217 G_L1: 9.081 D_real: 0.297 D_fake: 1.123 \n",
            "(epoch: 113, iters: 800, time: 0.186, data: 0.003) G_GAN: 8.776 G_L1: 21.231 D_real: 0.578 D_fake: 0.000 \n",
            "(epoch: 113, iters: 900, time: 0.058, data: 0.004) G_GAN: 0.623 G_L1: 0.000 D_real: 0.602 D_fake: 0.800 \n",
            "(epoch: 113, iters: 1000, time: 0.062, data: 0.002) G_GAN: 1.841 G_L1: 18.342 D_real: 0.291 D_fake: 0.544 \n",
            "End of epoch 113 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.055, data: 0.172) G_GAN: 0.692 G_L1: 0.001 D_real: 0.659 D_fake: 0.737 \n",
            "(epoch: 114, iters: 200, time: 0.760, data: 0.003) G_GAN: 0.635 G_L1: 0.000 D_real: 0.623 D_fake: 0.774 \n",
            "(epoch: 114, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.661 G_L1: 0.000 D_real: 0.618 D_fake: 0.782 \n",
            "(epoch: 114, iters: 400, time: 0.057, data: 0.004) G_GAN: 0.741 G_L1: 0.000 D_real: 0.722 D_fake: 0.671 \n",
            "(epoch: 114, iters: 500, time: 0.059, data: 0.004) G_GAN: 0.573 G_L1: 0.000 D_real: 0.560 D_fake: 0.854 \n",
            "(epoch: 114, iters: 600, time: 0.155, data: 0.003) G_GAN: 8.395 G_L1: 117.238 D_real: 0.290 D_fake: 0.001 \n",
            "(epoch: 114, iters: 700, time: 0.055, data: 0.004) G_GAN: 0.757 G_L1: 0.000 D_real: 0.774 D_fake: 0.621 \n",
            "(epoch: 114, iters: 800, time: 0.056, data: 0.008) G_GAN: 0.972 G_L1: 7.268 D_real: 0.118 D_fake: 0.878 \n",
            "(epoch: 114, iters: 900, time: 0.057, data: 0.002) G_GAN: 7.679 G_L1: 20.537 D_real: 0.401 D_fake: 0.001 \n",
            "(epoch: 114, iters: 1000, time: 0.606, data: 0.003) G_GAN: 8.333 G_L1: 18.180 D_real: 0.365 D_fake: 0.001 \n",
            "End of epoch 114 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.059, data: 0.226) G_GAN: 0.710 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
            "(epoch: 115, iters: 200, time: 0.056, data: 0.005) G_GAN: 5.315 G_L1: 0.089 D_real: 0.633 D_fake: 0.008 \n",
            "(epoch: 115, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.665 G_L1: 0.000 D_real: 0.658 D_fake: 0.733 \n",
            "(epoch: 115, iters: 400, time: 0.851, data: 0.003) G_GAN: 1.606 G_L1: 14.207 D_real: 0.362 D_fake: 0.297 \n",
            "(epoch: 115, iters: 500, time: 0.053, data: 0.007) G_GAN: 0.701 G_L1: 0.000 D_real: 0.703 D_fake: 0.689 \n",
            "(epoch: 115, iters: 600, time: 0.058, data: 0.003) G_GAN: 0.566 G_L1: 0.000 D_real: 0.589 D_fake: 0.893 \n",
            "(epoch: 115, iters: 700, time: 0.058, data: 0.003) G_GAN: 5.764 G_L1: 12.896 D_real: 0.126 D_fake: 0.006 \n",
            "(epoch: 115, iters: 800, time: 0.162, data: 0.003) G_GAN: 1.094 G_L1: 8.179 D_real: 0.063 D_fake: 0.551 \n",
            "(epoch: 115, iters: 900, time: 0.053, data: 0.006) G_GAN: 3.370 G_L1: 8.247 D_real: 0.116 D_fake: 0.050 \n",
            "(epoch: 115, iters: 1000, time: 0.061, data: 0.003) G_GAN: 0.482 G_L1: 0.000 D_real: 0.426 D_fake: 1.069 \n",
            "saving the latest model (epoch 115, total_iters 115000)\n",
            "saving the model at the end of epoch 115, iters 115000\n",
            "End of epoch 115 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 0.059, data: 0.171) G_GAN: 2.006 G_L1: 2.544 D_real: 0.663 D_fake: 0.175 \n",
            "(epoch: 116, iters: 200, time: 0.754, data: 0.002) G_GAN: 1.003 G_L1: 6.971 D_real: 0.068 D_fake: 0.636 \n",
            "(epoch: 116, iters: 300, time: 0.058, data: 0.002) G_GAN: 1.018 G_L1: 4.128 D_real: 0.347 D_fake: 0.958 \n",
            "(epoch: 116, iters: 400, time: 0.056, data: 0.003) G_GAN: 4.470 G_L1: 43.502 D_real: 0.157 D_fake: 0.015 \n",
            "(epoch: 116, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.616 G_L1: 0.000 D_real: 0.593 D_fake: 0.809 \n",
            "(epoch: 116, iters: 600, time: 0.173, data: 0.002) G_GAN: 0.644 G_L1: 0.000 D_real: 0.653 D_fake: 0.739 \n",
            "(epoch: 116, iters: 700, time: 0.058, data: 0.007) G_GAN: 0.608 G_L1: 0.000 D_real: 0.600 D_fake: 0.813 \n",
            "(epoch: 116, iters: 800, time: 0.058, data: 0.004) G_GAN: 0.704 G_L1: 1.846 D_real: 0.341 D_fake: 1.189 \n",
            "(epoch: 116, iters: 900, time: 0.059, data: 0.002) G_GAN: 4.285 G_L1: 2.310 D_real: 0.634 D_fake: 0.020 \n",
            "(epoch: 116, iters: 1000, time: 0.611, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.737 D_fake: 0.661 \n",
            "End of epoch 116 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.059, data: 0.197) G_GAN: 4.489 G_L1: 34.899 D_real: 0.005 D_fake: 0.022 \n",
            "(epoch: 117, iters: 200, time: 0.057, data: 0.002) G_GAN: 0.658 G_L1: 0.000 D_real: 0.659 D_fake: 0.740 \n",
            "(epoch: 117, iters: 300, time: 0.057, data: 0.003) G_GAN: 1.300 G_L1: 10.761 D_real: 0.134 D_fake: 0.740 \n",
            "(epoch: 117, iters: 400, time: 0.775, data: 0.004) G_GAN: 0.492 G_L1: 0.000 D_real: 0.455 D_fake: 1.021 \n",
            "(epoch: 117, iters: 500, time: 0.055, data: 0.002) G_GAN: 0.474 G_L1: 0.000 D_real: 0.421 D_fake: 1.080 \n",
            "(epoch: 117, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.612 G_L1: 0.000 D_real: 0.608 D_fake: 0.790 \n",
            "(epoch: 117, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.601 G_L1: 0.000 D_real: 0.583 D_fake: 0.822 \n",
            "(epoch: 117, iters: 800, time: 0.154, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.662 D_fake: 0.729 \n",
            "(epoch: 117, iters: 900, time: 0.055, data: 0.005) G_GAN: 0.599 G_L1: 0.000 D_real: 0.590 D_fake: 0.818 \n",
            "(epoch: 117, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.566 G_L1: 0.000 D_real: 0.571 D_fake: 0.837 \n",
            "End of epoch 117 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.059, data: 0.231) G_GAN: 0.733 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
            "(epoch: 118, iters: 200, time: 0.879, data: 0.002) G_GAN: 0.859 G_L1: 19.559 D_real: 0.246 D_fake: 0.612 \n",
            "(epoch: 118, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.582 G_L1: 0.000 D_real: 0.566 D_fake: 0.842 \n",
            "(epoch: 118, iters: 400, time: 0.059, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.671 D_fake: 0.722 \n",
            "(epoch: 118, iters: 500, time: 0.058, data: 0.002) G_GAN: 3.184 G_L1: 24.677 D_real: 0.550 D_fake: 0.057 \n",
            "(epoch: 118, iters: 600, time: 0.170, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.737 D_fake: 0.656 \n",
            "(epoch: 118, iters: 700, time: 0.055, data: 0.003) G_GAN: 4.241 G_L1: 9.435 D_real: 0.083 D_fake: 0.019 \n",
            "(epoch: 118, iters: 800, time: 0.057, data: 0.003) G_GAN: 4.912 G_L1: 18.823 D_real: 0.284 D_fake: 0.009 \n",
            "(epoch: 118, iters: 900, time: 0.057, data: 0.002) G_GAN: 0.633 G_L1: 0.000 D_real: 0.614 D_fake: 0.785 \n",
            "(epoch: 118, iters: 1000, time: 0.606, data: 0.003) G_GAN: 0.783 G_L1: 12.418 D_real: 0.120 D_fake: 1.084 \n",
            "End of epoch 118 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.059, data: 0.228) G_GAN: 0.627 G_L1: 0.000 D_real: 0.622 D_fake: 0.771 \n",
            "(epoch: 119, iters: 200, time: 0.057, data: 0.002) G_GAN: 0.599 G_L1: 0.000 D_real: 0.597 D_fake: 0.806 \n",
            "(epoch: 119, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.595 G_L1: 0.768 D_real: 0.317 D_fake: 1.309 \n",
            "(epoch: 119, iters: 400, time: 0.766, data: 0.003) G_GAN: 0.668 G_L1: 0.000 D_real: 0.666 D_fake: 0.724 \n",
            "(epoch: 119, iters: 500, time: 0.055, data: 0.003) G_GAN: 2.890 G_L1: 12.164 D_real: 0.158 D_fake: 0.085 \n",
            "(epoch: 119, iters: 600, time: 0.054, data: 0.003) G_GAN: 0.652 G_L1: 0.000 D_real: 0.646 D_fake: 0.747 \n",
            "(epoch: 119, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.711 D_fake: 0.678 \n",
            "(epoch: 119, iters: 800, time: 0.170, data: 0.002) G_GAN: 0.634 G_L1: 0.000 D_real: 0.614 D_fake: 0.781 \n",
            "(epoch: 119, iters: 900, time: 0.059, data: 0.004) G_GAN: 0.608 G_L1: 0.000 D_real: 0.611 D_fake: 0.792 \n",
            "(epoch: 119, iters: 1000, time: 0.053, data: 0.003) G_GAN: 0.987 G_L1: 5.099 D_real: 0.239 D_fake: 1.074 \n",
            "End of epoch 119 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 0.058, data: 0.189) G_GAN: 3.919 G_L1: 16.666 D_real: 0.746 D_fake: 0.024 \n",
            "(epoch: 120, iters: 200, time: 0.745, data: 0.002) G_GAN: 0.803 G_L1: 4.900 D_real: 0.242 D_fake: 0.701 \n",
            "(epoch: 120, iters: 300, time: 0.053, data: 0.003) G_GAN: 5.211 G_L1: 19.563 D_real: 0.589 D_fake: 0.007 \n",
            "(epoch: 120, iters: 400, time: 0.056, data: 0.003) G_GAN: 2.616 G_L1: 25.362 D_real: 0.007 D_fake: 0.139 \n",
            "(epoch: 120, iters: 500, time: 0.056, data: 0.004) G_GAN: 2.521 G_L1: 132.920 D_real: 0.407 D_fake: 0.145 \n",
            "(epoch: 120, iters: 600, time: 0.149, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.635 D_fake: 0.763 \n",
            "(epoch: 120, iters: 700, time: 0.059, data: 0.010) G_GAN: 5.567 G_L1: 4.638 D_real: 0.681 D_fake: 0.006 \n",
            "(epoch: 120, iters: 800, time: 0.056, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.713 D_fake: 0.678 \n",
            "(epoch: 120, iters: 900, time: 0.057, data: 0.002) G_GAN: 6.651 G_L1: 0.198 D_real: 0.520 D_fake: 0.003 \n",
            "(epoch: 120, iters: 1000, time: 0.617, data: 0.003) G_GAN: 2.668 G_L1: 14.626 D_real: 0.029 D_fake: 0.107 \n",
            "saving the latest model (epoch 120, total_iters 120000)\n",
            "saving the model at the end of epoch 120, iters 120000\n",
            "End of epoch 120 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.055, data: 0.211) G_GAN: 0.770 G_L1: 4.305 D_real: 0.510 D_fake: 0.989 \n",
            "(epoch: 121, iters: 200, time: 0.055, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.682 D_fake: 0.709 \n",
            "(epoch: 121, iters: 300, time: 0.053, data: 0.003) G_GAN: 0.735 G_L1: 0.000 D_real: 0.746 D_fake: 0.651 \n",
            "(epoch: 121, iters: 400, time: 0.875, data: 0.004) G_GAN: 1.266 G_L1: 5.487 D_real: 0.435 D_fake: 0.357 \n",
            "(epoch: 121, iters: 500, time: 0.054, data: 0.003) G_GAN: 3.614 G_L1: 0.157 D_real: 0.428 D_fake: 0.032 \n",
            "(epoch: 121, iters: 600, time: 0.056, data: 0.003) G_GAN: 4.924 G_L1: 25.905 D_real: 1.416 D_fake: 0.010 \n",
            "(epoch: 121, iters: 700, time: 0.054, data: 0.003) G_GAN: 3.817 G_L1: 0.317 D_real: 0.696 D_fake: 0.028 \n",
            "(epoch: 121, iters: 800, time: 0.161, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.781 D_fake: 0.615 \n",
            "(epoch: 121, iters: 900, time: 0.053, data: 0.004) G_GAN: 0.808 G_L1: 0.000 D_real: 0.843 D_fake: 0.578 \n",
            "(epoch: 121, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.698 G_L1: 0.000 D_real: 0.693 D_fake: 0.699 \n",
            "End of epoch 121 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.056, data: 0.214) G_GAN: 0.589 G_L1: 0.000 D_real: 0.576 D_fake: 0.836 \n",
            "(epoch: 122, iters: 200, time: 0.763, data: 0.002) G_GAN: 0.506 G_L1: 0.000 D_real: 0.451 D_fake: 1.045 \n",
            "(epoch: 122, iters: 300, time: 0.058, data: 0.003) G_GAN: 1.161 G_L1: 16.664 D_real: 0.147 D_fake: 0.691 \n",
            "(epoch: 122, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.621 G_L1: 0.000 D_real: 0.617 D_fake: 0.780 \n",
            "(epoch: 122, iters: 500, time: 0.057, data: 0.003) G_GAN: 5.130 G_L1: 1.488 D_real: 0.466 D_fake: 0.011 \n",
            "(epoch: 122, iters: 600, time: 0.174, data: 0.002) G_GAN: 0.639 G_L1: 0.000 D_real: 0.640 D_fake: 0.753 \n",
            "(epoch: 122, iters: 700, time: 0.057, data: 0.009) G_GAN: 0.875 G_L1: 0.000 D_real: 0.888 D_fake: 0.533 \n",
            "(epoch: 122, iters: 800, time: 0.055, data: 0.004) G_GAN: 2.806 G_L1: 5.184 D_real: 0.601 D_fake: 0.084 \n",
            "(epoch: 122, iters: 900, time: 0.054, data: 0.002) G_GAN: 0.580 G_L1: 0.000 D_real: 0.576 D_fake: 0.841 \n",
            "(epoch: 122, iters: 1000, time: 0.614, data: 0.004) G_GAN: 0.812 G_L1: 0.000 D_real: 0.840 D_fake: 0.573 \n",
            "End of epoch 122 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.056, data: 0.174) G_GAN: 0.463 G_L1: 7.047 D_real: 0.225 D_fake: 1.551 \n",
            "(epoch: 123, iters: 200, time: 0.057, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.706 D_fake: 0.683 \n",
            "(epoch: 123, iters: 300, time: 0.053, data: 0.005) G_GAN: 0.607 G_L1: 0.000 D_real: 0.599 D_fake: 0.800 \n",
            "(epoch: 123, iters: 400, time: 0.803, data: 0.003) G_GAN: 0.595 G_L1: 16.886 D_real: 0.118 D_fake: 1.459 \n",
            "(epoch: 123, iters: 500, time: 0.054, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.679 \n",
            "(epoch: 123, iters: 600, time: 0.058, data: 0.003) G_GAN: 5.175 G_L1: 0.144 D_real: 0.366 D_fake: 0.010 \n",
            "(epoch: 123, iters: 700, time: 0.059, data: 0.003) G_GAN: 4.595 G_L1: 0.420 D_real: 0.605 D_fake: 0.014 \n",
            "(epoch: 123, iters: 800, time: 0.169, data: 0.005) G_GAN: 0.646 G_L1: 0.000 D_real: 0.647 D_fake: 0.749 \n",
            "(epoch: 123, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.638 G_L1: 0.000 D_real: 0.626 D_fake: 0.769 \n",
            "(epoch: 123, iters: 1000, time: 0.058, data: 0.002) G_GAN: 2.972 G_L1: 0.294 D_real: 0.668 D_fake: 0.055 \n",
            "End of epoch 123 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 0.058, data: 0.214) G_GAN: 0.894 G_L1: 12.270 D_real: 0.174 D_fake: 0.859 \n",
            "(epoch: 124, iters: 200, time: 0.891, data: 0.004) G_GAN: 1.936 G_L1: 2.658 D_real: 0.149 D_fake: 0.191 \n",
            "(epoch: 124, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.690 D_fake: 0.701 \n",
            "(epoch: 124, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.655 G_L1: 0.000 D_real: 0.642 D_fake: 0.749 \n",
            "(epoch: 124, iters: 500, time: 0.059, data: 0.004) G_GAN: 0.680 G_L1: 0.001 D_real: 0.647 D_fake: 0.719 \n",
            "(epoch: 124, iters: 600, time: 0.160, data: 0.003) G_GAN: 1.664 G_L1: 14.863 D_real: 0.052 D_fake: 0.440 \n",
            "(epoch: 124, iters: 700, time: 0.059, data: 0.003) G_GAN: 1.015 G_L1: 5.358 D_real: 0.610 D_fake: 0.481 \n",
            "(epoch: 124, iters: 800, time: 0.059, data: 0.010) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.657 \n",
            "(epoch: 124, iters: 900, time: 0.056, data: 0.003) G_GAN: 0.705 G_L1: 0.000 D_real: 0.698 D_fake: 0.694 \n",
            "(epoch: 124, iters: 1000, time: 0.645, data: 0.002) G_GAN: 4.423 G_L1: 22.472 D_real: 0.173 D_fake: 0.014 \n",
            "End of epoch 124 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.055, data: 0.199) G_GAN: 0.644 G_L1: 0.000 D_real: 0.629 D_fake: 0.774 \n",
            "(epoch: 125, iters: 200, time: 0.062, data: 0.003) G_GAN: 1.361 G_L1: 4.056 D_real: 0.440 D_fake: 0.312 \n",
            "(epoch: 125, iters: 300, time: 0.057, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
            "(epoch: 125, iters: 400, time: 0.799, data: 0.003) G_GAN: 0.692 G_L1: 0.000 D_real: 0.702 D_fake: 0.686 \n",
            "(epoch: 125, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.574 G_L1: 0.000 D_real: 0.579 D_fake: 0.824 \n",
            "(epoch: 125, iters: 600, time: 0.055, data: 0.002) G_GAN: 0.600 G_L1: 0.000 D_real: 0.597 D_fake: 0.802 \n",
            "(epoch: 125, iters: 700, time: 0.057, data: 0.003) G_GAN: 3.640 G_L1: 4.124 D_real: 0.128 D_fake: 0.034 \n",
            "(epoch: 125, iters: 800, time: 0.173, data: 0.002) G_GAN: 0.784 G_L1: 0.007 D_real: 1.244 D_fake: 0.638 \n",
            "(epoch: 125, iters: 900, time: 0.059, data: 0.009) G_GAN: 6.126 G_L1: 0.531 D_real: 0.372 D_fake: 0.004 \n",
            "(epoch: 125, iters: 1000, time: 0.058, data: 0.003) G_GAN: 8.503 G_L1: 14.027 D_real: 0.069 D_fake: 0.001 \n",
            "saving the latest model (epoch 125, total_iters 125000)\n",
            "saving the model at the end of epoch 125, iters 125000\n",
            "End of epoch 125 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.055, data: 0.223) G_GAN: 0.686 G_L1: 0.000 D_real: 0.681 D_fake: 0.708 \n",
            "(epoch: 126, iters: 200, time: 0.776, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
            "(epoch: 126, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.643 G_L1: 0.000 D_real: 0.620 D_fake: 0.778 \n",
            "(epoch: 126, iters: 400, time: 0.059, data: 0.003) G_GAN: 0.616 G_L1: 0.000 D_real: 0.617 D_fake: 0.779 \n",
            "(epoch: 126, iters: 500, time: 0.055, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.646 D_fake: 0.747 \n",
            "(epoch: 126, iters: 600, time: 0.154, data: 0.003) G_GAN: 0.801 G_L1: 0.000 D_real: 0.828 D_fake: 0.577 \n",
            "(epoch: 126, iters: 700, time: 0.057, data: 0.004) G_GAN: 0.656 G_L1: 0.000 D_real: 0.646 D_fake: 0.747 \n",
            "(epoch: 126, iters: 800, time: 0.055, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.732 D_fake: 0.661 \n",
            "(epoch: 126, iters: 900, time: 0.056, data: 0.003) G_GAN: 0.611 G_L1: 0.000 D_real: 0.610 D_fake: 0.786 \n",
            "(epoch: 126, iters: 1000, time: 0.748, data: 0.004) G_GAN: 0.520 G_L1: 0.000 D_real: 0.499 D_fake: 0.938 \n",
            "End of epoch 126 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.056, data: 0.219) G_GAN: 0.708 G_L1: 0.000 D_real: 0.693 D_fake: 0.697 \n",
            "(epoch: 127, iters: 200, time: 0.057, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.677 \n",
            "(epoch: 127, iters: 300, time: 0.053, data: 0.004) G_GAN: 0.623 G_L1: 0.000 D_real: 0.615 D_fake: 0.783 \n",
            "(epoch: 127, iters: 400, time: 0.799, data: 0.003) G_GAN: 2.106 G_L1: 0.104 D_real: 0.637 D_fake: 0.143 \n",
            "(epoch: 127, iters: 500, time: 0.057, data: 0.017) G_GAN: 0.674 G_L1: 0.000 D_real: 0.679 D_fake: 0.709 \n",
            "(epoch: 127, iters: 600, time: 0.055, data: 0.008) G_GAN: 0.823 G_L1: 0.000 D_real: 0.861 D_fake: 0.555 \n",
            "(epoch: 127, iters: 700, time: 0.055, data: 0.003) G_GAN: 0.564 G_L1: 0.000 D_real: 0.555 D_fake: 0.856 \n",
            "(epoch: 127, iters: 800, time: 0.182, data: 0.002) G_GAN: 1.338 G_L1: 2.232 D_real: 0.280 D_fake: 0.576 \n",
            "(epoch: 127, iters: 900, time: 0.060, data: 0.004) G_GAN: 4.437 G_L1: 17.358 D_real: 0.279 D_fake: 0.015 \n",
            "(epoch: 127, iters: 1000, time: 0.059, data: 0.005) G_GAN: 5.579 G_L1: 15.305 D_real: 0.064 D_fake: 0.006 \n",
            "End of epoch 127 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 0.058, data: 0.210) G_GAN: 0.636 G_L1: 0.000 D_real: 0.633 D_fake: 0.759 \n",
            "(epoch: 128, iters: 200, time: 0.838, data: 0.003) G_GAN: 3.328 G_L1: 8.827 D_real: 0.274 D_fake: 0.033 \n",
            "(epoch: 128, iters: 300, time: 0.060, data: 0.003) G_GAN: 0.646 G_L1: 0.000 D_real: 0.638 D_fake: 0.757 \n",
            "(epoch: 128, iters: 400, time: 0.062, data: 0.002) G_GAN: 0.628 G_L1: 0.000 D_real: 0.620 D_fake: 0.783 \n",
            "(epoch: 128, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.716 D_fake: 0.674 \n",
            "(epoch: 128, iters: 600, time: 0.175, data: 0.003) G_GAN: 0.667 G_L1: 0.000 D_real: 0.662 D_fake: 0.730 \n",
            "(epoch: 128, iters: 700, time: 0.058, data: 0.005) G_GAN: 0.800 G_L1: 0.000 D_real: 0.808 D_fake: 0.592 \n",
            "(epoch: 128, iters: 800, time: 0.058, data: 0.002) G_GAN: 2.525 G_L1: 3.650 D_real: 0.511 D_fake: 0.065 \n",
            "(epoch: 128, iters: 900, time: 0.057, data: 0.003) G_GAN: 1.523 G_L1: 6.049 D_real: 0.059 D_fake: 0.644 \n",
            "(epoch: 128, iters: 1000, time: 0.633, data: 0.003) G_GAN: 6.262 G_L1: 7.755 D_real: 0.603 D_fake: 0.003 \n",
            "End of epoch 128 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.058, data: 0.213) G_GAN: 0.605 G_L1: 0.000 D_real: 0.608 D_fake: 0.791 \n",
            "(epoch: 129, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.773 G_L1: 0.000 D_real: 0.784 D_fake: 0.611 \n",
            "(epoch: 129, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.736 D_fake: 0.664 \n",
            "(epoch: 129, iters: 400, time: 0.904, data: 0.002) G_GAN: 1.745 G_L1: 6.105 D_real: 0.128 D_fake: 0.240 \n",
            "(epoch: 129, iters: 500, time: 0.057, data: 0.006) G_GAN: 2.604 G_L1: 7.500 D_real: 0.106 D_fake: 0.138 \n",
            "(epoch: 129, iters: 600, time: 0.059, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.690 D_fake: 0.698 \n",
            "(epoch: 129, iters: 700, time: 0.058, data: 0.002) G_GAN: 0.582 G_L1: 0.000 D_real: 0.577 D_fake: 0.831 \n",
            "(epoch: 129, iters: 800, time: 0.171, data: 0.003) G_GAN: 2.394 G_L1: 7.456 D_real: 0.842 D_fake: 0.033 \n",
            "(epoch: 129, iters: 900, time: 0.059, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.679 D_fake: 0.714 \n",
            "(epoch: 129, iters: 1000, time: 0.056, data: 0.003) G_GAN: 3.747 G_L1: 9.128 D_real: 0.070 D_fake: 0.032 \n",
            "End of epoch 129 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.059, data: 0.179) G_GAN: 4.454 G_L1: 17.421 D_real: 0.028 D_fake: 0.018 \n",
            "(epoch: 130, iters: 200, time: 0.784, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.641 D_fake: 0.756 \n",
            "(epoch: 130, iters: 300, time: 0.053, data: 0.004) G_GAN: 0.636 G_L1: 0.000 D_real: 0.624 D_fake: 0.772 \n",
            "(epoch: 130, iters: 400, time: 0.056, data: 0.004) G_GAN: 0.646 G_L1: 0.000 D_real: 0.643 D_fake: 0.751 \n",
            "(epoch: 130, iters: 500, time: 0.054, data: 0.003) G_GAN: 0.634 G_L1: 0.000 D_real: 0.614 D_fake: 0.806 \n",
            "(epoch: 130, iters: 600, time: 0.167, data: 0.002) G_GAN: 0.747 G_L1: 0.790 D_real: 0.441 D_fake: 0.664 \n",
            "(epoch: 130, iters: 700, time: 0.062, data: 0.005) G_GAN: 0.740 G_L1: 0.000 D_real: 0.744 D_fake: 0.646 \n",
            "(epoch: 130, iters: 800, time: 0.058, data: 0.005) G_GAN: 0.520 G_L1: 0.000 D_real: 0.517 D_fake: 0.915 \n",
            "(epoch: 130, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.616 G_L1: 0.000 D_real: 0.621 D_fake: 0.775 \n",
            "(epoch: 130, iters: 1000, time: 0.645, data: 0.003) G_GAN: 1.723 G_L1: 8.780 D_real: 0.280 D_fake: 0.245 \n",
            "saving the latest model (epoch 130, total_iters 130000)\n",
            "saving the model at the end of epoch 130, iters 130000\n",
            "End of epoch 130 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.056, data: 0.228) G_GAN: 6.779 G_L1: 21.182 D_real: 0.095 D_fake: 0.002 \n",
            "(epoch: 131, iters: 200, time: 0.059, data: 0.003) G_GAN: 1.692 G_L1: 6.529 D_real: 0.078 D_fake: 0.257 \n",
            "(epoch: 131, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.731 D_fake: 0.663 \n",
            "(epoch: 131, iters: 400, time: 0.804, data: 0.003) G_GAN: 0.697 G_L1: 1.910 D_real: 0.087 D_fake: 1.771 \n",
            "(epoch: 131, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.631 G_L1: 0.000 D_real: 0.612 D_fake: 0.796 \n",
            "(epoch: 131, iters: 600, time: 0.059, data: 0.003) G_GAN: 0.666 G_L1: 0.000 D_real: 0.679 D_fake: 0.711 \n",
            "(epoch: 131, iters: 700, time: 0.055, data: 0.003) G_GAN: 4.617 G_L1: 8.969 D_real: 0.027 D_fake: 0.013 \n",
            "(epoch: 131, iters: 800, time: 0.152, data: 0.003) G_GAN: 0.626 G_L1: 0.000 D_real: 0.632 D_fake: 0.766 \n",
            "(epoch: 131, iters: 900, time: 0.057, data: 0.004) G_GAN: 1.734 G_L1: 8.951 D_real: 0.654 D_fake: 0.145 \n",
            "(epoch: 131, iters: 1000, time: 0.056, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.708 \n",
            "End of epoch 131 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 0.062, data: 0.202) G_GAN: 0.788 G_L1: 0.000 D_real: 0.789 D_fake: 0.615 \n",
            "(epoch: 132, iters: 200, time: 0.908, data: 0.007) G_GAN: 3.863 G_L1: 6.608 D_real: 0.080 D_fake: 0.028 \n",
            "(epoch: 132, iters: 300, time: 0.054, data: 0.003) G_GAN: 2.843 G_L1: 3.103 D_real: 0.373 D_fake: 0.058 \n",
            "(epoch: 132, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.592 G_L1: 0.000 D_real: 0.580 D_fake: 0.823 \n",
            "(epoch: 132, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.665 G_L1: 0.000 D_real: 0.673 D_fake: 0.715 \n",
            "(epoch: 132, iters: 600, time: 0.170, data: 0.002) G_GAN: 5.017 G_L1: 1.755 D_real: 0.148 D_fake: 0.011 \n",
            "(epoch: 132, iters: 700, time: 0.057, data: 0.003) G_GAN: 3.379 G_L1: 15.905 D_real: 0.304 D_fake: 0.041 \n",
            "(epoch: 132, iters: 800, time: 0.055, data: 0.003) G_GAN: 0.558 G_L1: 0.000 D_real: 0.523 D_fake: 0.920 \n",
            "(epoch: 132, iters: 900, time: 0.058, data: 0.002) G_GAN: 3.806 G_L1: 13.886 D_real: 0.130 D_fake: 0.026 \n",
            "(epoch: 132, iters: 1000, time: 0.654, data: 0.003) G_GAN: 0.776 G_L1: 0.000 D_real: 0.798 D_fake: 0.604 \n",
            "End of epoch 132 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.056, data: 0.189) G_GAN: 0.751 G_L1: 0.000 D_real: 0.761 D_fake: 0.634 \n",
            "(epoch: 133, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.755 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
            "(epoch: 133, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.677 G_L1: 3.205 D_real: 0.035 D_fake: 0.784 \n",
            "(epoch: 133, iters: 400, time: 0.806, data: 0.004) G_GAN: 0.657 G_L1: 0.000 D_real: 0.660 D_fake: 0.728 \n",
            "(epoch: 133, iters: 500, time: 0.057, data: 0.003) G_GAN: 2.328 G_L1: 2.924 D_real: 0.550 D_fake: 0.114 \n",
            "(epoch: 133, iters: 600, time: 0.056, data: 0.003) G_GAN: 6.447 G_L1: 25.482 D_real: 0.459 D_fake: 0.002 \n",
            "(epoch: 133, iters: 700, time: 0.053, data: 0.002) G_GAN: 0.663 G_L1: 0.000 D_real: 0.657 D_fake: 0.737 \n",
            "(epoch: 133, iters: 800, time: 0.170, data: 0.003) G_GAN: 1.720 G_L1: 13.176 D_real: 0.620 D_fake: 0.266 \n",
            "(epoch: 133, iters: 900, time: 0.058, data: 0.005) G_GAN: 0.781 G_L1: 0.000 D_real: 0.842 D_fake: 0.578 \n",
            "(epoch: 133, iters: 1000, time: 0.058, data: 0.002) G_GAN: 5.189 G_L1: 13.647 D_real: 0.017 D_fake: 0.008 \n",
            "End of epoch 133 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.063, data: 0.223) G_GAN: 0.735 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
            "(epoch: 134, iters: 200, time: 0.951, data: 0.003) G_GAN: 3.343 G_L1: 5.903 D_real: 0.080 D_fake: 0.057 \n",
            "(epoch: 134, iters: 300, time: 0.056, data: 0.003) G_GAN: 2.561 G_L1: 11.945 D_real: 0.035 D_fake: 0.109 \n",
            "(epoch: 134, iters: 400, time: 0.055, data: 0.004) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
            "(epoch: 134, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.803 G_L1: 2.248 D_real: 0.877 D_fake: 0.516 \n",
            "(epoch: 134, iters: 600, time: 0.169, data: 0.003) G_GAN: 1.623 G_L1: 43.402 D_real: 0.072 D_fake: 0.348 \n",
            "(epoch: 134, iters: 700, time: 0.054, data: 0.003) G_GAN: 4.316 G_L1: 6.375 D_real: 0.265 D_fake: 0.016 \n",
            "(epoch: 134, iters: 800, time: 0.058, data: 0.004) G_GAN: 2.036 G_L1: 9.771 D_real: 0.042 D_fake: 0.659 \n",
            "(epoch: 134, iters: 900, time: 0.054, data: 0.003) G_GAN: 1.014 G_L1: 6.595 D_real: 0.031 D_fake: 0.519 \n",
            "(epoch: 134, iters: 1000, time: 0.658, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.708 D_fake: 0.681 \n",
            "End of epoch 134 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.057, data: 0.222) G_GAN: 0.670 G_L1: 0.000 D_real: 0.668 D_fake: 0.720 \n",
            "(epoch: 135, iters: 200, time: 0.057, data: 0.003) G_GAN: 2.321 G_L1: 9.748 D_real: 0.089 D_fake: 0.132 \n",
            "(epoch: 135, iters: 300, time: 0.059, data: 0.002) G_GAN: 2.397 G_L1: 0.302 D_real: 0.809 D_fake: 0.121 \n",
            "(epoch: 135, iters: 400, time: 0.822, data: 0.003) G_GAN: 4.148 G_L1: 7.643 D_real: 0.563 D_fake: 0.015 \n",
            "(epoch: 135, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.630 G_L1: 0.000 D_real: 0.634 D_fake: 0.765 \n",
            "(epoch: 135, iters: 600, time: 0.057, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.687 D_fake: 0.701 \n",
            "(epoch: 135, iters: 700, time: 0.059, data: 0.003) G_GAN: 5.789 G_L1: 17.479 D_real: 0.077 D_fake: 0.004 \n",
            "(epoch: 135, iters: 800, time: 0.170, data: 0.004) G_GAN: 0.774 G_L1: 0.000 D_real: 0.812 D_fake: 0.593 \n",
            "(epoch: 135, iters: 900, time: 0.057, data: 0.008) G_GAN: 0.713 G_L1: 0.000 D_real: 0.720 D_fake: 0.668 \n",
            "(epoch: 135, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.744 D_fake: 0.651 \n",
            "saving the latest model (epoch 135, total_iters 135000)\n",
            "saving the model at the end of epoch 135, iters 135000\n",
            "End of epoch 135 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 0.055, data: 0.180) G_GAN: 3.634 G_L1: 6.754 D_real: 0.039 D_fake: 0.034 \n",
            "(epoch: 136, iters: 200, time: 0.832, data: 0.002) G_GAN: 3.329 G_L1: 4.453 D_real: 0.027 D_fake: 0.048 \n",
            "(epoch: 136, iters: 300, time: 0.059, data: 0.007) G_GAN: 2.349 G_L1: 13.494 D_real: 0.001 D_fake: 0.168 \n",
            "(epoch: 136, iters: 400, time: 0.059, data: 0.004) G_GAN: 4.750 G_L1: 9.438 D_real: 0.146 D_fake: 0.014 \n",
            "(epoch: 136, iters: 500, time: 0.059, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.680 D_fake: 0.718 \n",
            "(epoch: 136, iters: 600, time: 0.183, data: 0.003) G_GAN: 0.574 G_L1: 0.000 D_real: 0.559 D_fake: 0.859 \n",
            "(epoch: 136, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.767 G_L1: 3.589 D_real: 0.329 D_fake: 1.046 \n",
            "(epoch: 136, iters: 800, time: 0.057, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.739 D_fake: 0.669 \n",
            "(epoch: 136, iters: 900, time: 0.068, data: 0.003) G_GAN: 0.752 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
            "(epoch: 136, iters: 1000, time: 0.741, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.686 \n",
            "End of epoch 136 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.070, data: 0.211) G_GAN: 2.755 G_L1: 21.400 D_real: 0.063 D_fake: 0.091 \n",
            "(epoch: 137, iters: 200, time: 0.055, data: 0.004) G_GAN: 1.406 G_L1: 5.871 D_real: 0.454 D_fake: 0.322 \n",
            "(epoch: 137, iters: 300, time: 0.055, data: 0.002) G_GAN: 3.760 G_L1: 6.839 D_real: 0.324 D_fake: 0.092 \n",
            "(epoch: 137, iters: 400, time: 0.779, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.675 D_fake: 0.714 \n",
            "(epoch: 137, iters: 500, time: 0.056, data: 0.003) G_GAN: 5.921 G_L1: 0.125 D_real: 0.581 D_fake: 0.006 \n",
            "(epoch: 137, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.647 G_L1: 0.000 D_real: 0.650 D_fake: 0.742 \n",
            "(epoch: 137, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.664 G_L1: 0.000 D_real: 0.681 D_fake: 0.732 \n",
            "(epoch: 137, iters: 800, time: 0.170, data: 0.002) G_GAN: 1.084 G_L1: 4.140 D_real: 0.031 D_fake: 0.986 \n",
            "(epoch: 137, iters: 900, time: 0.056, data: 0.004) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.673 \n",
            "(epoch: 137, iters: 1000, time: 0.058, data: 0.004) G_GAN: 0.768 G_L1: 0.000 D_real: 0.776 D_fake: 0.618 \n",
            "End of epoch 137 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.070, data: 0.175) G_GAN: 4.189 G_L1: 6.075 D_real: 0.032 D_fake: 0.020 \n",
            "(epoch: 138, iters: 200, time: 0.792, data: 0.004) G_GAN: 1.863 G_L1: 13.388 D_real: 0.232 D_fake: 0.195 \n",
            "(epoch: 138, iters: 300, time: 0.058, data: 0.003) G_GAN: 2.931 G_L1: 6.899 D_real: 0.041 D_fake: 0.063 \n",
            "(epoch: 138, iters: 400, time: 0.059, data: 0.002) G_GAN: 0.977 G_L1: 5.866 D_real: 0.076 D_fake: 1.216 \n",
            "(epoch: 138, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.663 G_L1: 0.000 D_real: 0.652 D_fake: 0.738 \n",
            "(epoch: 138, iters: 600, time: 0.167, data: 0.009) G_GAN: 5.082 G_L1: 11.896 D_real: 0.023 D_fake: 0.010 \n",
            "(epoch: 138, iters: 700, time: 0.054, data: 0.003) G_GAN: 2.928 G_L1: 2.928 D_real: 0.065 D_fake: 0.069 \n",
            "(epoch: 138, iters: 800, time: 0.053, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.739 D_fake: 0.653 \n",
            "(epoch: 138, iters: 900, time: 0.057, data: 0.003) G_GAN: 5.809 G_L1: 7.553 D_real: 0.056 D_fake: 0.005 \n",
            "(epoch: 138, iters: 1000, time: 0.682, data: 0.003) G_GAN: 2.249 G_L1: 8.849 D_real: 1.760 D_fake: 0.039 \n",
            "End of epoch 138 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.058, data: 0.203) G_GAN: 2.918 G_L1: 12.338 D_real: 0.241 D_fake: 0.058 \n",
            "(epoch: 139, iters: 200, time: 0.058, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.667 D_fake: 0.721 \n",
            "(epoch: 139, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.604 G_L1: 0.000 D_real: 0.606 D_fake: 0.799 \n",
            "(epoch: 139, iters: 400, time: 0.946, data: 0.003) G_GAN: 1.198 G_L1: 0.406 D_real: 0.839 D_fake: 0.409 \n",
            "(epoch: 139, iters: 500, time: 0.058, data: 0.003) G_GAN: 3.642 G_L1: 3.124 D_real: 0.023 D_fake: 0.068 \n",
            "(epoch: 139, iters: 600, time: 0.054, data: 0.003) G_GAN: 3.978 G_L1: 16.443 D_real: 0.018 D_fake: 0.025 \n",
            "(epoch: 139, iters: 700, time: 0.055, data: 0.002) G_GAN: 1.484 G_L1: 11.142 D_real: 0.212 D_fake: 0.339 \n",
            "(epoch: 139, iters: 800, time: 0.167, data: 0.002) G_GAN: 0.444 G_L1: 0.593 D_real: 0.499 D_fake: 1.510 \n",
            "(epoch: 139, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.625 G_L1: 0.000 D_real: 0.618 D_fake: 0.778 \n",
            "(epoch: 139, iters: 1000, time: 0.059, data: 0.003) G_GAN: 0.488 G_L1: 0.000 D_real: 0.462 D_fake: 0.998 \n",
            "End of epoch 139 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 0.059, data: 0.181) G_GAN: 0.734 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
            "(epoch: 140, iters: 200, time: 0.790, data: 0.002) G_GAN: 6.064 G_L1: 20.654 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 140, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.697 D_fake: 0.692 \n",
            "(epoch: 140, iters: 400, time: 0.056, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.682 D_fake: 0.707 \n",
            "(epoch: 140, iters: 500, time: 0.059, data: 0.003) G_GAN: 5.393 G_L1: 23.550 D_real: 0.048 D_fake: 0.006 \n",
            "(epoch: 140, iters: 600, time: 0.163, data: 0.003) G_GAN: 0.684 G_L1: 0.000 D_real: 0.683 D_fake: 0.704 \n",
            "(epoch: 140, iters: 700, time: 0.060, data: 0.009) G_GAN: 0.553 G_L1: 5.794 D_real: 1.803 D_fake: 0.864 \n",
            "(epoch: 140, iters: 800, time: 0.058, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.726 D_fake: 0.667 \n",
            "(epoch: 140, iters: 900, time: 0.057, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
            "(epoch: 140, iters: 1000, time: 0.645, data: 0.004) G_GAN: 2.661 G_L1: 2.151 D_real: 0.638 D_fake: 0.049 \n",
            "saving the latest model (epoch 140, total_iters 140000)\n",
            "saving the model at the end of epoch 140, iters 140000\n",
            "End of epoch 140 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.058, data: 0.248) G_GAN: 6.083 G_L1: 7.967 D_real: 0.531 D_fake: 0.004 \n",
            "(epoch: 141, iters: 200, time: 0.058, data: 0.003) G_GAN: 0.662 G_L1: 0.000 D_real: 0.672 D_fake: 0.719 \n",
            "(epoch: 141, iters: 300, time: 0.059, data: 0.002) G_GAN: 0.794 G_L1: 0.000 D_real: 0.839 D_fake: 0.579 \n",
            "(epoch: 141, iters: 400, time: 0.791, data: 0.003) G_GAN: 6.413 G_L1: 7.638 D_real: 0.610 D_fake: 0.002 \n",
            "(epoch: 141, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.989 G_L1: 3.345 D_real: 0.209 D_fake: 0.805 \n",
            "(epoch: 141, iters: 600, time: 0.057, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.675 D_fake: 0.713 \n",
            "(epoch: 141, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
            "(epoch: 141, iters: 800, time: 0.169, data: 0.003) G_GAN: 5.675 G_L1: 30.623 D_real: 0.017 D_fake: 0.006 \n",
            "(epoch: 141, iters: 900, time: 0.055, data: 0.006) G_GAN: 0.718 G_L1: 0.000 D_real: 0.725 D_fake: 0.669 \n",
            "(epoch: 141, iters: 1000, time: 0.058, data: 0.003) G_GAN: 0.692 G_L1: 0.000 D_real: 0.668 D_fake: 0.723 \n",
            "End of epoch 141 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.058, data: 0.215) G_GAN: 0.750 G_L1: 0.000 D_real: 0.767 D_fake: 0.632 \n",
            "(epoch: 142, iters: 200, time: 1.015, data: 0.005) G_GAN: 5.943 G_L1: 58.703 D_real: 0.076 D_fake: 0.005 \n",
            "(epoch: 142, iters: 300, time: 0.058, data: 0.003) G_GAN: 5.058 G_L1: 8.426 D_real: 0.109 D_fake: 0.011 \n",
            "(epoch: 142, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.684 G_L1: 0.000 D_real: 0.686 D_fake: 0.702 \n",
            "(epoch: 142, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.550 G_L1: 0.000 D_real: 0.523 D_fake: 0.910 \n",
            "(epoch: 142, iters: 600, time: 0.174, data: 0.003) G_GAN: 4.324 G_L1: 8.979 D_real: 0.035 D_fake: 0.015 \n",
            "(epoch: 142, iters: 700, time: 0.057, data: 0.010) G_GAN: 1.167 G_L1: 2.937 D_real: 0.073 D_fake: 0.791 \n",
            "(epoch: 142, iters: 800, time: 0.059, data: 0.003) G_GAN: 0.641 G_L1: 0.000 D_real: 0.635 D_fake: 0.760 \n",
            "(epoch: 142, iters: 900, time: 0.054, data: 0.003) G_GAN: 4.969 G_L1: 29.669 D_real: 0.887 D_fake: 0.006 \n",
            "(epoch: 142, iters: 1000, time: 0.664, data: 0.002) G_GAN: 0.633 G_L1: 0.000 D_real: 0.625 D_fake: 0.767 \n",
            "End of epoch 142 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.058, data: 0.235) G_GAN: 1.589 G_L1: 17.222 D_real: 0.033 D_fake: 0.301 \n",
            "(epoch: 143, iters: 200, time: 0.056, data: 0.003) G_GAN: 0.648 G_L1: 46.005 D_real: 0.765 D_fake: 0.774 \n",
            "(epoch: 143, iters: 300, time: 0.059, data: 0.002) G_GAN: 6.072 G_L1: 6.161 D_real: 0.127 D_fake: 0.003 \n",
            "(epoch: 143, iters: 400, time: 0.817, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.694 D_fake: 0.696 \n",
            "(epoch: 143, iters: 500, time: 0.061, data: 0.003) G_GAN: 0.611 G_L1: 0.000 D_real: 0.602 D_fake: 0.795 \n",
            "(epoch: 143, iters: 600, time: 0.055, data: 0.003) G_GAN: 1.704 G_L1: 6.975 D_real: 0.188 D_fake: 0.313 \n",
            "(epoch: 143, iters: 700, time: 0.063, data: 0.003) G_GAN: 0.593 G_L1: 0.000 D_real: 0.579 D_fake: 0.843 \n",
            "(epoch: 143, iters: 800, time: 0.170, data: 0.002) G_GAN: 3.995 G_L1: 13.844 D_real: 0.073 D_fake: 0.026 \n",
            "(epoch: 143, iters: 900, time: 0.061, data: 0.003) G_GAN: 0.516 G_L1: 0.000 D_real: 0.518 D_fake: 0.923 \n",
            "(epoch: 143, iters: 1000, time: 0.051, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
            "End of epoch 143 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 0.059, data: 0.175) G_GAN: 0.631 G_L1: 0.000 D_real: 0.635 D_fake: 0.757 \n",
            "(epoch: 144, iters: 200, time: 0.814, data: 0.004) G_GAN: 7.049 G_L1: 5.711 D_real: 0.063 D_fake: 0.002 \n",
            "(epoch: 144, iters: 300, time: 0.059, data: 0.003) G_GAN: 2.817 G_L1: 11.282 D_real: 0.185 D_fake: 0.053 \n",
            "(epoch: 144, iters: 400, time: 0.054, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.667 D_fake: 0.724 \n",
            "(epoch: 144, iters: 500, time: 0.057, data: 0.003) G_GAN: 4.713 G_L1: 17.007 D_real: 0.026 D_fake: 0.012 \n",
            "(epoch: 144, iters: 600, time: 0.286, data: 0.003) G_GAN: 1.475 G_L1: 3.556 D_real: 0.085 D_fake: 0.558 \n",
            "(epoch: 144, iters: 700, time: 0.057, data: 0.004) G_GAN: 1.068 G_L1: 0.674 D_real: 0.551 D_fake: 1.179 \n",
            "(epoch: 144, iters: 800, time: 0.054, data: 0.002) G_GAN: 0.804 G_L1: 0.000 D_real: 0.796 D_fake: 0.602 \n",
            "(epoch: 144, iters: 900, time: 0.059, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
            "(epoch: 144, iters: 1000, time: 0.682, data: 0.003) G_GAN: 0.669 G_L1: 0.000 D_real: 0.669 D_fake: 0.720 \n",
            "End of epoch 144 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.058, data: 0.195) G_GAN: 1.502 G_L1: 3.119 D_real: 0.153 D_fake: 0.401 \n",
            "(epoch: 145, iters: 200, time: 0.058, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.682 D_fake: 0.706 \n",
            "(epoch: 145, iters: 300, time: 0.047, data: 0.003) G_GAN: 1.932 G_L1: 8.439 D_real: 0.075 D_fake: 0.223 \n",
            "(epoch: 145, iters: 400, time: 0.818, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.651 D_fake: 0.741 \n",
            "(epoch: 145, iters: 500, time: 0.057, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.666 D_fake: 0.724 \n",
            "(epoch: 145, iters: 600, time: 0.063, data: 0.003) G_GAN: 0.689 G_L1: 0.000 D_real: 0.702 D_fake: 0.688 \n",
            "(epoch: 145, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.653 G_L1: 0.000 D_real: 0.652 D_fake: 0.738 \n",
            "(epoch: 145, iters: 800, time: 0.167, data: 0.002) G_GAN: 0.637 G_L1: 0.000 D_real: 0.644 D_fake: 0.757 \n",
            "(epoch: 145, iters: 900, time: 0.060, data: 0.004) G_GAN: 1.860 G_L1: 6.867 D_real: 0.115 D_fake: 0.316 \n",
            "(epoch: 145, iters: 1000, time: 0.056, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.742 D_fake: 0.651 \n",
            "saving the latest model (epoch 145, total_iters 145000)\n",
            "saving the model at the end of epoch 145, iters 145000\n",
            "End of epoch 145 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.055, data: 0.216) G_GAN: 4.778 G_L1: 3.243 D_real: 0.362 D_fake: 0.007 \n",
            "(epoch: 146, iters: 200, time: 0.833, data: 0.005) G_GAN: 3.007 G_L1: 32.178 D_real: 0.062 D_fake: 0.099 \n",
            "(epoch: 146, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.604 G_L1: 0.000 D_real: 1.433 D_fake: 0.290 \n",
            "(epoch: 146, iters: 400, time: 0.057, data: 0.003) G_GAN: 1.868 G_L1: 3.096 D_real: 0.023 D_fake: 0.354 \n",
            "(epoch: 146, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.804 G_L1: 0.000 D_real: 0.823 D_fake: 0.586 \n",
            "(epoch: 146, iters: 600, time: 0.167, data: 0.002) G_GAN: 0.645 G_L1: 0.000 D_real: 0.634 D_fake: 0.761 \n",
            "(epoch: 146, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.658 G_L1: 0.000 D_real: 0.649 D_fake: 0.744 \n",
            "(epoch: 146, iters: 800, time: 0.055, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.679 \n",
            "(epoch: 146, iters: 900, time: 0.059, data: 0.004) G_GAN: 0.671 G_L1: 0.000 D_real: 0.681 D_fake: 0.710 \n",
            "(epoch: 146, iters: 1000, time: 0.809, data: 0.002) G_GAN: 1.030 G_L1: 4.154 D_real: 0.416 D_fake: 0.603 \n",
            "End of epoch 146 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.056, data: 0.243) G_GAN: 0.748 G_L1: 0.000 D_real: 0.755 D_fake: 0.636 \n",
            "(epoch: 147, iters: 200, time: 0.058, data: 0.003) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
            "(epoch: 147, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.910 G_L1: 0.000 D_real: 1.183 D_fake: 0.386 \n",
            "(epoch: 147, iters: 400, time: 0.842, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.719 D_fake: 0.675 \n",
            "(epoch: 147, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.613 G_L1: 0.000 D_real: 0.603 D_fake: 0.796 \n",
            "(epoch: 147, iters: 600, time: 0.053, data: 0.003) G_GAN: 0.688 G_L1: 0.000 D_real: 0.687 D_fake: 0.701 \n",
            "(epoch: 147, iters: 700, time: 0.057, data: 0.004) G_GAN: 0.702 G_L1: 0.000 D_real: 0.697 D_fake: 0.691 \n",
            "(epoch: 147, iters: 800, time: 0.163, data: 0.003) G_GAN: 0.598 G_L1: 0.000 D_real: 0.594 D_fake: 0.810 \n",
            "(epoch: 147, iters: 900, time: 0.056, data: 0.004) G_GAN: 0.774 G_L1: 0.002 D_real: 0.746 D_fake: 0.621 \n",
            "(epoch: 147, iters: 1000, time: 0.057, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.676 D_fake: 0.715 \n",
            "End of epoch 147 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 0.056, data: 0.214) G_GAN: 0.783 G_L1: 0.000 D_real: 0.795 D_fake: 0.602 \n",
            "(epoch: 148, iters: 200, time: 0.848, data: 0.010) G_GAN: 0.786 G_L1: 0.000 D_real: 0.984 D_fake: 0.475 \n",
            "(epoch: 148, iters: 300, time: 0.053, data: 0.006) G_GAN: 1.442 G_L1: 13.908 D_real: 0.026 D_fake: 0.460 \n",
            "(epoch: 148, iters: 400, time: 0.056, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
            "(epoch: 148, iters: 500, time: 0.054, data: 0.003) G_GAN: 0.692 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
            "(epoch: 148, iters: 600, time: 0.168, data: 0.003) G_GAN: 0.792 G_L1: 0.000 D_real: 0.814 D_fake: 0.587 \n",
            "(epoch: 148, iters: 700, time: 0.056, data: 0.004) G_GAN: 0.735 G_L1: 0.000 D_real: 0.760 D_fake: 0.639 \n",
            "(epoch: 148, iters: 800, time: 0.059, data: 0.003) G_GAN: 3.597 G_L1: 8.551 D_real: 0.140 D_fake: 0.045 \n",
            "(epoch: 148, iters: 900, time: 0.059, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.724 D_fake: 0.673 \n",
            "(epoch: 148, iters: 1000, time: 0.716, data: 0.002) G_GAN: 2.575 G_L1: 5.433 D_real: 5.836 D_fake: 0.032 \n",
            "End of epoch 148 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.060, data: 0.190) G_GAN: 5.337 G_L1: 1.305 D_real: 0.522 D_fake: 0.006 \n",
            "(epoch: 149, iters: 200, time: 0.056, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
            "(epoch: 149, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.741 D_fake: 0.651 \n",
            "(epoch: 149, iters: 400, time: 0.942, data: 0.002) G_GAN: 0.585 G_L1: 0.000 D_real: 0.583 D_fake: 0.828 \n",
            "(epoch: 149, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.699 D_fake: 0.691 \n",
            "(epoch: 149, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.705 \n",
            "(epoch: 149, iters: 700, time: 0.057, data: 0.004) G_GAN: 1.286 G_L1: 7.038 D_real: 0.009 D_fake: 1.032 \n",
            "(epoch: 149, iters: 800, time: 0.161, data: 0.003) G_GAN: 0.796 G_L1: 11.447 D_real: 0.003 D_fake: 0.645 \n",
            "(epoch: 149, iters: 900, time: 0.059, data: 0.004) G_GAN: 0.814 G_L1: 0.597 D_real: 0.192 D_fake: 0.625 \n",
            "(epoch: 149, iters: 1000, time: 0.061, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.762 D_fake: 0.640 \n",
            "End of epoch 149 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.056, data: 0.244) G_GAN: 0.635 G_L1: 0.000 D_real: 0.647 D_fake: 0.746 \n",
            "(epoch: 150, iters: 200, time: 0.926, data: 0.005) G_GAN: 4.732 G_L1: 10.714 D_real: 0.035 D_fake: 0.014 \n",
            "(epoch: 150, iters: 300, time: 0.058, data: 0.004) G_GAN: 0.718 G_L1: 0.000 D_real: 0.730 D_fake: 0.672 \n",
            "(epoch: 150, iters: 400, time: 0.056, data: 0.004) G_GAN: 0.734 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
            "(epoch: 150, iters: 500, time: 0.057, data: 0.002) G_GAN: 4.311 G_L1: 4.662 D_real: 0.231 D_fake: 0.011 \n",
            "(epoch: 150, iters: 600, time: 0.161, data: 0.003) G_GAN: 0.596 G_L1: 0.000 D_real: 0.585 D_fake: 0.817 \n",
            "(epoch: 150, iters: 700, time: 0.057, data: 0.004) G_GAN: 1.667 G_L1: 8.123 D_real: 0.699 D_fake: 0.144 \n",
            "(epoch: 150, iters: 800, time: 0.060, data: 0.003) G_GAN: 1.066 G_L1: 0.408 D_real: 0.694 D_fake: 0.500 \n",
            "(epoch: 150, iters: 900, time: 0.053, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.726 D_fake: 0.668 \n",
            "(epoch: 150, iters: 1000, time: 0.719, data: 0.006) G_GAN: 0.664 G_L1: 0.000 D_real: 0.651 D_fake: 0.739 \n",
            "saving the latest model (epoch 150, total_iters 150000)\n",
            "saving the model at the end of epoch 150, iters 150000\n",
            "End of epoch 150 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.057, data: 0.239) G_GAN: 0.639 G_L1: 0.000 D_real: 0.633 D_fake: 0.762 \n",
            "(epoch: 151, iters: 200, time: 0.059, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.752 D_fake: 0.642 \n",
            "(epoch: 151, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.684 \n",
            "(epoch: 151, iters: 400, time: 0.977, data: 0.002) G_GAN: 3.620 G_L1: 7.709 D_real: 0.011 D_fake: 0.039 \n",
            "(epoch: 151, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.699 D_fake: 0.689 \n",
            "(epoch: 151, iters: 600, time: 0.058, data: 0.008) G_GAN: 0.677 G_L1: 0.000 D_real: 0.662 D_fake: 0.727 \n",
            "(epoch: 151, iters: 700, time: 0.058, data: 0.003) G_GAN: 3.277 G_L1: 11.704 D_real: 0.007 D_fake: 0.064 \n",
            "(epoch: 151, iters: 800, time: 0.169, data: 0.002) G_GAN: 0.787 G_L1: 0.001 D_real: 0.802 D_fake: 0.601 \n",
            "(epoch: 151, iters: 900, time: 0.057, data: 0.004) G_GAN: 0.664 G_L1: 0.000 D_real: 0.663 D_fake: 0.727 \n",
            "(epoch: 151, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.681 G_L1: 0.000 D_real: 0.677 D_fake: 0.710 \n",
            "End of epoch 151 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 0.055, data: 0.192) G_GAN: 6.508 G_L1: 5.493 D_real: 0.012 D_fake: 0.003 \n",
            "(epoch: 152, iters: 200, time: 0.854, data: 0.003) G_GAN: 2.246 G_L1: 4.096 D_real: 0.038 D_fake: 0.160 \n",
            "(epoch: 152, iters: 300, time: 0.056, data: 0.006) G_GAN: 0.717 G_L1: 0.000 D_real: 0.723 D_fake: 0.665 \n",
            "(epoch: 152, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.670 G_L1: 0.000 D_real: 0.680 D_fake: 0.711 \n",
            "(epoch: 152, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.698 G_L1: 0.000 D_real: 0.709 D_fake: 0.682 \n",
            "(epoch: 152, iters: 600, time: 0.165, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
            "(epoch: 152, iters: 700, time: 0.059, data: 0.004) G_GAN: 3.027 G_L1: 3.810 D_real: 0.020 D_fake: 0.100 \n",
            "(epoch: 152, iters: 800, time: 0.058, data: 0.003) G_GAN: 0.603 G_L1: 0.000 D_real: 0.604 D_fake: 0.794 \n",
            "(epoch: 152, iters: 900, time: 0.058, data: 0.003) G_GAN: 3.009 G_L1: 3.641 D_real: 0.514 D_fake: 0.042 \n",
            "(epoch: 152, iters: 1000, time: 0.715, data: 0.004) G_GAN: 4.391 G_L1: 25.115 D_real: 0.156 D_fake: 0.019 \n",
            "End of epoch 152 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.059, data: 0.219) G_GAN: 0.651 G_L1: 0.000 D_real: 0.655 D_fake: 0.741 \n",
            "(epoch: 153, iters: 200, time: 0.053, data: 0.004) G_GAN: 0.686 G_L1: 0.000 D_real: 0.689 D_fake: 0.699 \n",
            "(epoch: 153, iters: 300, time: 0.057, data: 0.004) G_GAN: 2.270 G_L1: 12.844 D_real: 0.111 D_fake: 0.130 \n",
            "(epoch: 153, iters: 400, time: 0.860, data: 0.003) G_GAN: 0.670 G_L1: 0.000 D_real: 0.668 D_fake: 0.720 \n",
            "(epoch: 153, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.812 G_L1: 0.001 D_real: 0.861 D_fake: 0.583 \n",
            "(epoch: 153, iters: 600, time: 0.059, data: 0.003) G_GAN: 0.665 G_L1: 0.000 D_real: 0.662 D_fake: 0.730 \n",
            "(epoch: 153, iters: 700, time: 0.054, data: 0.002) G_GAN: 0.650 G_L1: 0.000 D_real: 0.648 D_fake: 0.744 \n",
            "(epoch: 153, iters: 800, time: 0.163, data: 0.004) G_GAN: 1.849 G_L1: 2.820 D_real: 0.108 D_fake: 0.458 \n",
            "(epoch: 153, iters: 900, time: 0.059, data: 0.004) G_GAN: 3.982 G_L1: 23.364 D_real: 0.040 D_fake: 0.024 \n",
            "(epoch: 153, iters: 1000, time: 0.058, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.699 D_fake: 0.689 \n",
            "End of epoch 153 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.054, data: 0.197) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.642 \n",
            "(epoch: 154, iters: 200, time: 1.052, data: 0.004) G_GAN: 2.147 G_L1: 4.567 D_real: 0.004 D_fake: 0.200 \n",
            "(epoch: 154, iters: 300, time: 0.058, data: 0.003) G_GAN: 4.392 G_L1: 8.830 D_real: 0.089 D_fake: 0.018 \n",
            "(epoch: 154, iters: 400, time: 0.056, data: 0.003) G_GAN: 1.115 G_L1: 8.302 D_real: 0.011 D_fake: 0.470 \n",
            "(epoch: 154, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.681 G_L1: 0.000 D_real: 0.673 D_fake: 0.715 \n",
            "(epoch: 154, iters: 600, time: 0.163, data: 0.004) G_GAN: 5.022 G_L1: 20.067 D_real: 0.037 D_fake: 0.010 \n",
            "(epoch: 154, iters: 700, time: 0.056, data: 0.004) G_GAN: 0.733 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
            "(epoch: 154, iters: 800, time: 0.058, data: 0.003) G_GAN: 0.658 G_L1: 0.000 D_real: 0.649 D_fake: 0.744 \n",
            "(epoch: 154, iters: 900, time: 0.056, data: 0.004) G_GAN: 0.885 G_L1: 0.000 D_real: 1.036 D_fake: 0.455 \n",
            "(epoch: 154, iters: 1000, time: 0.731, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.669 D_fake: 0.719 \n",
            "End of epoch 154 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.057, data: 0.189) G_GAN: 0.689 G_L1: 0.000 D_real: 0.687 D_fake: 0.701 \n",
            "(epoch: 155, iters: 200, time: 0.059, data: 0.003) G_GAN: 5.033 G_L1: 8.564 D_real: 0.039 D_fake: 0.008 \n",
            "(epoch: 155, iters: 300, time: 0.055, data: 0.002) G_GAN: 0.595 G_L1: 0.000 D_real: 0.571 D_fake: 0.841 \n",
            "(epoch: 155, iters: 400, time: 0.903, data: 0.004) G_GAN: 4.508 G_L1: 20.687 D_real: 0.003 D_fake: 0.020 \n",
            "(epoch: 155, iters: 500, time: 0.056, data: 0.012) G_GAN: 5.002 G_L1: 29.307 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 155, iters: 600, time: 0.058, data: 0.003) G_GAN: 2.637 G_L1: 6.890 D_real: 0.043 D_fake: 0.085 \n",
            "(epoch: 155, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.740 D_fake: 0.655 \n",
            "(epoch: 155, iters: 800, time: 0.166, data: 0.003) G_GAN: 4.858 G_L1: 11.566 D_real: 0.066 D_fake: 0.011 \n",
            "(epoch: 155, iters: 900, time: 0.056, data: 0.010) G_GAN: 5.798 G_L1: 8.141 D_real: 1.054 D_fake: 0.003 \n",
            "(epoch: 155, iters: 1000, time: 0.058, data: 0.003) G_GAN: 6.628 G_L1: 16.434 D_real: 0.046 D_fake: 0.002 \n",
            "saving the latest model (epoch 155, total_iters 155000)\n",
            "saving the model at the end of epoch 155, iters 155000\n",
            "End of epoch 155 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 0.059, data: 0.206) G_GAN: 0.657 G_L1: 2.180 D_real: 0.007 D_fake: 2.335 \n",
            "(epoch: 156, iters: 200, time: 1.030, data: 0.002) G_GAN: 2.459 G_L1: 8.066 D_real: 0.185 D_fake: 0.108 \n",
            "(epoch: 156, iters: 300, time: 0.059, data: 0.003) G_GAN: 6.387 G_L1: 7.991 D_real: 0.149 D_fake: 0.002 \n",
            "(epoch: 156, iters: 400, time: 0.058, data: 0.003) G_GAN: 1.480 G_L1: 1.468 D_real: 0.052 D_fake: 1.385 \n",
            "(epoch: 156, iters: 500, time: 0.056, data: 0.003) G_GAN: 5.843 G_L1: 8.515 D_real: 0.178 D_fake: 0.005 \n",
            "(epoch: 156, iters: 600, time: 0.173, data: 0.003) G_GAN: 4.364 G_L1: 33.206 D_real: 0.005 D_fake: 0.018 \n",
            "(epoch: 156, iters: 700, time: 0.054, data: 0.003) G_GAN: 2.960 G_L1: 19.708 D_real: 0.000 D_fake: 0.079 \n",
            "(epoch: 156, iters: 800, time: 0.057, data: 0.002) G_GAN: 1.719 G_L1: 12.595 D_real: 0.040 D_fake: 0.578 \n",
            "(epoch: 156, iters: 900, time: 0.057, data: 0.003) G_GAN: 5.035 G_L1: 10.262 D_real: 0.024 D_fake: 0.013 \n",
            "(epoch: 156, iters: 1000, time: 0.730, data: 0.003) G_GAN: 7.073 G_L1: 11.852 D_real: 0.063 D_fake: 0.002 \n",
            "End of epoch 156 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.059, data: 0.176) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.688 \n",
            "(epoch: 157, iters: 200, time: 0.062, data: 0.004) G_GAN: 0.744 G_L1: 0.000 D_real: 0.773 D_fake: 0.624 \n",
            "(epoch: 157, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.856 G_L1: 4.433 D_real: 0.838 D_fake: 0.910 \n",
            "(epoch: 157, iters: 400, time: 0.969, data: 0.003) G_GAN: 5.507 G_L1: 7.808 D_real: 0.052 D_fake: 0.006 \n",
            "(epoch: 157, iters: 500, time: 0.054, data: 0.003) G_GAN: 3.761 G_L1: 5.146 D_real: 0.304 D_fake: 0.031 \n",
            "(epoch: 157, iters: 600, time: 0.057, data: 0.003) G_GAN: 3.102 G_L1: 5.955 D_real: 0.116 D_fake: 0.049 \n",
            "(epoch: 157, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.657 G_L1: 0.000 D_real: 0.645 D_fake: 0.748 \n",
            "(epoch: 157, iters: 800, time: 0.176, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.673 \n",
            "(epoch: 157, iters: 900, time: 0.059, data: 0.005) G_GAN: 0.659 G_L1: 0.000 D_real: 0.654 D_fake: 0.738 \n",
            "(epoch: 157, iters: 1000, time: 0.058, data: 0.005) G_GAN: 0.663 G_L1: 0.000 D_real: 0.670 D_fake: 0.724 \n",
            "End of epoch 157 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.063, data: 0.217) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
            "(epoch: 158, iters: 200, time: 0.876, data: 0.004) G_GAN: 1.195 G_L1: 4.859 D_real: 0.138 D_fake: 0.417 \n",
            "(epoch: 158, iters: 300, time: 0.056, data: 0.010) G_GAN: 0.720 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
            "(epoch: 158, iters: 400, time: 0.056, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.676 D_fake: 0.712 \n",
            "(epoch: 158, iters: 500, time: 0.060, data: 0.003) G_GAN: 0.600 G_L1: 0.000 D_real: 0.584 D_fake: 0.829 \n",
            "(epoch: 158, iters: 600, time: 0.185, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.742 D_fake: 0.651 \n",
            "(epoch: 158, iters: 700, time: 0.059, data: 0.004) G_GAN: 1.485 G_L1: 4.936 D_real: 0.063 D_fake: 0.505 \n",
            "(epoch: 158, iters: 800, time: 0.055, data: 0.004) G_GAN: 0.607 G_L1: 0.000 D_real: 0.598 D_fake: 0.804 \n",
            "(epoch: 158, iters: 900, time: 0.057, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
            "(epoch: 158, iters: 1000, time: 0.849, data: 0.004) G_GAN: 0.674 G_L1: 0.000 D_real: 0.674 D_fake: 0.717 \n",
            "End of epoch 158 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.057, data: 0.209) G_GAN: 0.700 G_L1: 0.000 D_real: 0.698 D_fake: 0.693 \n",
            "(epoch: 159, iters: 200, time: 0.056, data: 0.003) G_GAN: 0.745 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
            "(epoch: 159, iters: 300, time: 0.056, data: 0.004) G_GAN: 0.798 G_L1: 0.000 D_real: 0.807 D_fake: 0.593 \n",
            "(epoch: 159, iters: 400, time: 0.913, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.716 D_fake: 0.676 \n",
            "(epoch: 159, iters: 500, time: 0.054, data: 0.003) G_GAN: 7.053 G_L1: 4.547 D_real: 0.035 D_fake: 0.002 \n",
            "(epoch: 159, iters: 600, time: 0.067, data: 0.003) G_GAN: 0.677 G_L1: 0.000 D_real: 0.668 D_fake: 0.721 \n",
            "(epoch: 159, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.664 G_L1: 0.000 D_real: 0.661 D_fake: 0.732 \n",
            "(epoch: 159, iters: 800, time: 0.176, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.676 D_fake: 0.714 \n",
            "(epoch: 159, iters: 900, time: 0.055, data: 0.004) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.690 \n",
            "(epoch: 159, iters: 1000, time: 0.057, data: 0.003) G_GAN: 2.651 G_L1: 9.408 D_real: 0.356 D_fake: 0.067 \n",
            "End of epoch 159 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 0.059, data: 0.202) G_GAN: 0.686 G_L1: 0.000 D_real: 0.689 D_fake: 0.701 \n",
            "(epoch: 160, iters: 200, time: 0.904, data: 0.005) G_GAN: 0.650 G_L1: 0.000 D_real: 0.645 D_fake: 0.744 \n",
            "(epoch: 160, iters: 300, time: 0.056, data: 0.003) G_GAN: 1.910 G_L1: 5.277 D_real: 0.663 D_fake: 0.437 \n",
            "(epoch: 160, iters: 400, time: 0.059, data: 0.004) G_GAN: 4.993 G_L1: 4.919 D_real: 0.006 D_fake: 0.011 \n",
            "(epoch: 160, iters: 500, time: 0.058, data: 0.003) G_GAN: 1.027 G_L1: 1.002 D_real: 0.075 D_fake: 2.033 \n",
            "(epoch: 160, iters: 600, time: 0.165, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.701 D_fake: 0.688 \n",
            "(epoch: 160, iters: 700, time: 0.056, data: 0.005) G_GAN: 0.698 G_L1: 0.000 D_real: 0.700 D_fake: 0.697 \n",
            "(epoch: 160, iters: 800, time: 0.058, data: 0.003) G_GAN: 0.666 G_L1: 0.000 D_real: 0.664 D_fake: 0.728 \n",
            "(epoch: 160, iters: 900, time: 0.056, data: 0.005) G_GAN: 0.704 G_L1: 0.000 D_real: 0.704 D_fake: 0.688 \n",
            "(epoch: 160, iters: 1000, time: 0.810, data: 0.003) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.686 \n",
            "saving the latest model (epoch 160, total_iters 160000)\n",
            "saving the model at the end of epoch 160, iters 160000\n",
            "End of epoch 160 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.055, data: 0.201) G_GAN: 1.892 G_L1: 19.276 D_real: 0.722 D_fake: 0.189 \n",
            "(epoch: 161, iters: 200, time: 0.057, data: 0.003) G_GAN: 3.862 G_L1: 20.893 D_real: 0.041 D_fake: 0.041 \n",
            "(epoch: 161, iters: 300, time: 0.055, data: 0.002) G_GAN: 0.643 G_L1: 0.000 D_real: 0.645 D_fake: 0.747 \n",
            "(epoch: 161, iters: 400, time: 0.879, data: 0.002) G_GAN: 4.399 G_L1: 6.844 D_real: 0.014 D_fake: 0.015 \n",
            "(epoch: 161, iters: 500, time: 0.059, data: 0.016) G_GAN: 0.700 G_L1: 0.000 D_real: 0.699 D_fake: 0.690 \n",
            "(epoch: 161, iters: 600, time: 0.057, data: 0.003) G_GAN: 4.242 G_L1: 11.591 D_real: 0.021 D_fake: 0.035 \n",
            "(epoch: 161, iters: 700, time: 0.055, data: 0.003) G_GAN: 0.675 G_L1: 0.000 D_real: 0.672 D_fake: 0.717 \n",
            "(epoch: 161, iters: 800, time: 0.163, data: 0.002) G_GAN: 0.839 G_L1: 0.000 D_real: 0.868 D_fake: 0.550 \n",
            "(epoch: 161, iters: 900, time: 0.058, data: 0.004) G_GAN: 2.040 G_L1: 6.845 D_real: 0.015 D_fake: 0.258 \n",
            "(epoch: 161, iters: 1000, time: 0.044, data: 0.003) G_GAN: 9.199 G_L1: 15.302 D_real: 0.357 D_fake: 0.000 \n",
            "End of epoch 161 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.058, data: 0.232) G_GAN: 0.227 G_L1: 3.382 D_real: 0.068 D_fake: 3.220 \n",
            "(epoch: 162, iters: 200, time: 0.917, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
            "(epoch: 162, iters: 300, time: 0.053, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.676 D_fake: 0.713 \n",
            "(epoch: 162, iters: 400, time: 0.060, data: 0.003) G_GAN: 2.613 G_L1: 14.394 D_real: 1.893 D_fake: 0.073 \n",
            "(epoch: 162, iters: 500, time: 0.057, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.665 D_fake: 0.724 \n",
            "(epoch: 162, iters: 600, time: 0.169, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.708 D_fake: 0.687 \n",
            "(epoch: 162, iters: 700, time: 0.055, data: 0.004) G_GAN: 0.679 G_L1: 0.000 D_real: 0.676 D_fake: 0.711 \n",
            "(epoch: 162, iters: 800, time: 0.054, data: 0.004) G_GAN: 3.124 G_L1: 6.888 D_real: 0.006 D_fake: 0.058 \n",
            "(epoch: 162, iters: 900, time: 0.050, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.676 D_fake: 0.713 \n",
            "(epoch: 162, iters: 1000, time: 0.752, data: 0.010) G_GAN: 0.677 G_L1: 0.000 D_real: 0.678 D_fake: 0.709 \n",
            "End of epoch 162 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.054, data: 0.201) G_GAN: 3.465 G_L1: 6.693 D_real: 1.130 D_fake: 0.029 \n",
            "(epoch: 163, iters: 200, time: 0.057, data: 0.005) G_GAN: 0.814 G_L1: 5.417 D_real: 0.251 D_fake: 0.983 \n",
            "(epoch: 163, iters: 300, time: 0.058, data: 0.005) G_GAN: 0.738 G_L1: 3.367 D_real: 0.070 D_fake: 0.687 \n",
            "(epoch: 163, iters: 400, time: 0.970, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
            "(epoch: 163, iters: 500, time: 0.054, data: 0.008) G_GAN: 0.670 G_L1: 0.000 D_real: 0.669 D_fake: 0.719 \n",
            "(epoch: 163, iters: 600, time: 0.058, data: 0.003) G_GAN: 1.798 G_L1: 13.362 D_real: 0.007 D_fake: 0.309 \n",
            "(epoch: 163, iters: 700, time: 0.060, data: 0.003) G_GAN: 5.242 G_L1: 6.333 D_real: 0.024 D_fake: 0.009 \n",
            "(epoch: 163, iters: 800, time: 0.172, data: 0.003) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.677 \n",
            "(epoch: 163, iters: 900, time: 0.059, data: 0.013) G_GAN: 6.418 G_L1: 10.923 D_real: 0.023 D_fake: 0.003 \n",
            "(epoch: 163, iters: 1000, time: 0.057, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.691 \n",
            "End of epoch 163 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 0.058, data: 0.202) G_GAN: 0.725 G_L1: 0.000 D_real: 0.721 D_fake: 0.669 \n",
            "(epoch: 164, iters: 200, time: 0.897, data: 0.003) G_GAN: 0.975 G_L1: 10.605 D_real: 0.012 D_fake: 1.386 \n",
            "(epoch: 164, iters: 300, time: 0.051, data: 0.007) G_GAN: 3.491 G_L1: 3.667 D_real: 0.058 D_fake: 0.045 \n",
            "(epoch: 164, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.672 D_fake: 0.718 \n",
            "(epoch: 164, iters: 500, time: 0.056, data: 0.002) G_GAN: 6.809 G_L1: 10.764 D_real: 0.018 D_fake: 0.002 \n",
            "(epoch: 164, iters: 600, time: 0.180, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
            "(epoch: 164, iters: 700, time: 0.055, data: 0.004) G_GAN: 0.673 G_L1: 0.000 D_real: 0.671 D_fake: 0.719 \n",
            "(epoch: 164, iters: 800, time: 0.058, data: 0.005) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.684 \n",
            "(epoch: 164, iters: 900, time: 0.057, data: 0.002) G_GAN: 0.673 G_L1: 0.000 D_real: 0.671 D_fake: 0.720 \n",
            "(epoch: 164, iters: 1000, time: 0.744, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.701 D_fake: 0.688 \n",
            "End of epoch 164 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.059, data: 0.187) G_GAN: 1.339 G_L1: 1.023 D_real: 0.061 D_fake: 0.774 \n",
            "(epoch: 165, iters: 200, time: 0.058, data: 0.003) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.709 \n",
            "(epoch: 165, iters: 300, time: 0.059, data: 0.003) G_GAN: 1.084 G_L1: 0.000 D_real: 1.218 D_fake: 0.357 \n",
            "(epoch: 165, iters: 400, time: 1.038, data: 0.003) G_GAN: 6.436 G_L1: 7.264 D_real: 0.013 D_fake: 0.003 \n",
            "(epoch: 165, iters: 500, time: 0.063, data: 0.003) G_GAN: 0.724 G_L1: 0.000 D_real: 0.792 D_fake: 0.615 \n",
            "(epoch: 165, iters: 600, time: 0.055, data: 0.003) G_GAN: 2.423 G_L1: 10.553 D_real: 0.137 D_fake: 0.117 \n",
            "(epoch: 165, iters: 700, time: 0.055, data: 0.003) G_GAN: 2.586 G_L1: 0.010 D_real: 0.724 D_fake: 0.081 \n",
            "(epoch: 165, iters: 800, time: 0.166, data: 0.002) G_GAN: 2.728 G_L1: 59.841 D_real: 0.006 D_fake: 0.093 \n",
            "(epoch: 165, iters: 900, time: 0.055, data: 0.005) G_GAN: 0.750 G_L1: 0.000 D_real: 0.768 D_fake: 0.638 \n",
            "(epoch: 165, iters: 1000, time: 0.055, data: 0.003) G_GAN: 4.833 G_L1: 4.989 D_real: 0.083 D_fake: 0.009 \n",
            "saving the latest model (epoch 165, total_iters 165000)\n",
            "saving the model at the end of epoch 165, iters 165000\n",
            "End of epoch 165 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.058, data: 0.203) G_GAN: 7.548 G_L1: 10.740 D_real: 0.549 D_fake: 0.001 \n",
            "(epoch: 166, iters: 200, time: 1.087, data: 0.003) G_GAN: 0.666 G_L1: 0.000 D_real: 0.664 D_fake: 0.724 \n",
            "(epoch: 166, iters: 300, time: 0.058, data: 0.004) G_GAN: 1.085 G_L1: 5.456 D_real: 0.009 D_fake: 1.052 \n",
            "(epoch: 166, iters: 400, time: 0.056, data: 0.002) G_GAN: 4.136 G_L1: 7.425 D_real: 0.004 D_fake: 0.029 \n",
            "(epoch: 166, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.753 D_fake: 0.643 \n",
            "(epoch: 166, iters: 600, time: 0.167, data: 0.003) G_GAN: 0.657 G_L1: 0.000 D_real: 0.654 D_fake: 0.739 \n",
            "(epoch: 166, iters: 700, time: 0.057, data: 0.005) G_GAN: 2.418 G_L1: 1.680 D_real: 0.808 D_fake: 0.053 \n",
            "(epoch: 166, iters: 800, time: 0.058, data: 0.003) G_GAN: 0.769 G_L1: 0.000 D_real: 0.776 D_fake: 0.621 \n",
            "(epoch: 166, iters: 900, time: 0.062, data: 0.003) G_GAN: 5.465 G_L1: 8.784 D_real: 0.019 D_fake: 0.006 \n",
            "(epoch: 166, iters: 1000, time: 0.762, data: 0.002) G_GAN: 2.916 G_L1: 0.993 D_real: 0.112 D_fake: 0.069 \n",
            "End of epoch 166 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.057, data: 0.199) G_GAN: 0.606 G_L1: 0.000 D_real: 0.596 D_fake: 0.806 \n",
            "(epoch: 167, iters: 200, time: 0.054, data: 0.003) G_GAN: 5.692 G_L1: 10.807 D_real: 0.102 D_fake: 0.006 \n",
            "(epoch: 167, iters: 300, time: 0.058, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.654 \n",
            "(epoch: 167, iters: 400, time: 1.124, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.681 \n",
            "(epoch: 167, iters: 500, time: 0.058, data: 0.010) G_GAN: 1.623 G_L1: 5.415 D_real: 0.008 D_fake: 0.520 \n",
            "(epoch: 167, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.672 G_L1: 0.000 D_real: 0.668 D_fake: 0.720 \n",
            "(epoch: 167, iters: 700, time: 0.058, data: 0.004) G_GAN: 0.734 G_L1: 0.000 D_real: 0.740 D_fake: 0.653 \n",
            "(epoch: 167, iters: 800, time: 0.167, data: 0.002) G_GAN: 0.636 G_L1: 0.000 D_real: 0.626 D_fake: 0.767 \n",
            "(epoch: 167, iters: 900, time: 0.057, data: 0.006) G_GAN: 4.435 G_L1: 3.236 D_real: 0.012 D_fake: 0.020 \n",
            "(epoch: 167, iters: 1000, time: 0.057, data: 0.003) G_GAN: 1.617 G_L1: 1.595 D_real: 0.009 D_fake: 0.425 \n",
            "End of epoch 167 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 0.054, data: 0.193) G_GAN: 6.333 G_L1: 1.527 D_real: 0.686 D_fake: 0.003 \n",
            "(epoch: 168, iters: 200, time: 0.944, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
            "(epoch: 168, iters: 300, time: 0.054, data: 0.004) G_GAN: 3.630 G_L1: 3.036 D_real: 0.045 D_fake: 0.041 \n",
            "(epoch: 168, iters: 400, time: 0.057, data: 0.002) G_GAN: 4.710 G_L1: 5.472 D_real: 0.065 D_fake: 0.018 \n",
            "(epoch: 168, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.871 G_L1: 0.286 D_real: 0.214 D_fake: 0.583 \n",
            "(epoch: 168, iters: 600, time: 0.167, data: 0.003) G_GAN: 0.669 G_L1: 0.000 D_real: 0.674 D_fake: 0.716 \n",
            "(epoch: 168, iters: 700, time: 0.057, data: 0.007) G_GAN: 1.011 G_L1: 5.176 D_real: 0.084 D_fake: 1.357 \n",
            "(epoch: 168, iters: 800, time: 0.057, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.702 D_fake: 0.686 \n",
            "(epoch: 168, iters: 900, time: 0.055, data: 0.003) G_GAN: 0.649 G_L1: 0.000 D_real: 0.650 D_fake: 0.740 \n",
            "(epoch: 168, iters: 1000, time: 0.777, data: 0.004) G_GAN: 2.320 G_L1: 1.243 D_real: 0.935 D_fake: 0.048 \n",
            "End of epoch 168 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.059, data: 0.214) G_GAN: 5.433 G_L1: 18.468 D_real: 0.008 D_fake: 0.008 \n",
            "(epoch: 169, iters: 200, time: 0.058, data: 0.005) G_GAN: 4.144 G_L1: 4.430 D_real: 0.013 D_fake: 0.023 \n",
            "(epoch: 169, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.819 G_L1: 0.000 D_real: 0.854 D_fake: 0.569 \n",
            "(epoch: 169, iters: 400, time: 0.905, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
            "(epoch: 169, iters: 500, time: 0.058, data: 0.007) G_GAN: 6.745 G_L1: 23.072 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 169, iters: 600, time: 0.058, data: 0.013) G_GAN: 0.665 G_L1: 0.000 D_real: 0.665 D_fake: 0.724 \n",
            "(epoch: 169, iters: 700, time: 0.047, data: 0.002) G_GAN: 1.636 G_L1: 3.038 D_real: 0.096 D_fake: 0.305 \n",
            "(epoch: 169, iters: 800, time: 0.284, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.702 D_fake: 0.686 \n",
            "(epoch: 169, iters: 900, time: 0.058, data: 0.003) G_GAN: 2.600 G_L1: 7.590 D_real: 0.010 D_fake: 0.121 \n",
            "(epoch: 169, iters: 1000, time: 0.057, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.706 D_fake: 0.712 \n",
            "End of epoch 169 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.062, data: 0.181) G_GAN: 0.769 G_L1: 0.000 D_real: 0.776 D_fake: 0.619 \n",
            "(epoch: 170, iters: 200, time: 0.912, data: 0.004) G_GAN: 0.753 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
            "(epoch: 170, iters: 300, time: 0.053, data: 0.009) G_GAN: 0.891 G_L1: 0.000 D_real: 0.978 D_fake: 0.511 \n",
            "(epoch: 170, iters: 400, time: 0.055, data: 0.005) G_GAN: 5.038 G_L1: 3.105 D_real: 0.026 D_fake: 0.012 \n",
            "(epoch: 170, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.681 G_L1: 0.000 D_real: 0.677 D_fake: 0.714 \n",
            "(epoch: 170, iters: 600, time: 0.164, data: 0.003) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
            "(epoch: 170, iters: 700, time: 0.058, data: 0.004) G_GAN: 0.593 G_L1: 0.000 D_real: 0.593 D_fake: 0.809 \n",
            "(epoch: 170, iters: 800, time: 0.059, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.676 \n",
            "(epoch: 170, iters: 900, time: 0.055, data: 0.005) G_GAN: 4.127 G_L1: 5.610 D_real: 0.753 D_fake: 0.008 \n",
            "(epoch: 170, iters: 1000, time: 0.769, data: 0.003) G_GAN: 0.710 G_L1: 0.000 D_real: 0.725 D_fake: 0.664 \n",
            "saving the latest model (epoch 170, total_iters 170000)\n",
            "saving the model at the end of epoch 170, iters 170000\n",
            "End of epoch 170 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.058, data: 0.238) G_GAN: 0.575 G_L1: 0.000 D_real: 0.573 D_fake: 0.831 \n",
            "(epoch: 171, iters: 200, time: 0.059, data: 0.004) G_GAN: 0.708 G_L1: 0.000 D_real: 0.702 D_fake: 0.688 \n",
            "(epoch: 171, iters: 300, time: 0.058, data: 0.007) G_GAN: 2.254 G_L1: 11.839 D_real: 0.300 D_fake: 0.164 \n",
            "(epoch: 171, iters: 400, time: 0.906, data: 0.004) G_GAN: 0.653 G_L1: 0.000 D_real: 0.651 D_fake: 0.744 \n",
            "(epoch: 171, iters: 500, time: 0.056, data: 0.003) G_GAN: 1.172 G_L1: 2.478 D_real: 0.691 D_fake: 0.290 \n",
            "(epoch: 171, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.922 G_L1: 0.632 D_real: 0.129 D_fake: 1.296 \n",
            "(epoch: 171, iters: 700, time: 0.059, data: 0.006) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.679 \n",
            "(epoch: 171, iters: 800, time: 0.164, data: 0.003) G_GAN: 0.664 G_L1: 0.000 D_real: 0.666 D_fake: 0.723 \n",
            "(epoch: 171, iters: 900, time: 0.058, data: 0.009) G_GAN: 0.647 G_L1: 0.000 D_real: 0.642 D_fake: 0.749 \n",
            "(epoch: 171, iters: 1000, time: 0.056, data: 0.003) G_GAN: 0.661 G_L1: 0.000 D_real: 0.659 D_fake: 0.729 \n",
            "End of epoch 171 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 0.056, data: 0.172) G_GAN: 4.603 G_L1: 6.193 D_real: 0.338 D_fake: 0.010 \n",
            "(epoch: 172, iters: 200, time: 1.037, data: 0.003) G_GAN: 0.599 G_L1: 0.000 D_real: 0.593 D_fake: 0.807 \n",
            "(epoch: 172, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.679 G_L1: 0.000 D_real: 0.677 D_fake: 0.711 \n",
            "(epoch: 172, iters: 400, time: 0.056, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
            "(epoch: 172, iters: 500, time: 0.058, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.689 \n",
            "(epoch: 172, iters: 600, time: 0.168, data: 0.003) G_GAN: 0.682 G_L1: 0.000 D_real: 0.686 D_fake: 0.702 \n",
            "(epoch: 172, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.646 G_L1: 0.000 D_real: 0.639 D_fake: 0.752 \n",
            "(epoch: 172, iters: 800, time: 0.058, data: 0.003) G_GAN: 2.189 G_L1: 9.171 D_real: 0.144 D_fake: 0.174 \n",
            "(epoch: 172, iters: 900, time: 0.059, data: 0.003) G_GAN: 0.577 G_L1: 0.000 D_real: 0.569 D_fake: 0.841 \n",
            "(epoch: 172, iters: 1000, time: 0.777, data: 0.003) G_GAN: 0.651 G_L1: 0.000 D_real: 0.648 D_fake: 0.743 \n",
            "End of epoch 172 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.058, data: 0.244) G_GAN: 0.659 G_L1: 0.000 D_real: 0.653 D_fake: 0.737 \n",
            "(epoch: 173, iters: 200, time: 0.059, data: 0.003) G_GAN: 0.688 G_L1: 0.000 D_real: 0.687 D_fake: 0.702 \n",
            "(epoch: 173, iters: 300, time: 0.060, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
            "(epoch: 173, iters: 400, time: 0.967, data: 0.004) G_GAN: 5.301 G_L1: 17.661 D_real: 4.767 D_fake: 0.003 \n",
            "(epoch: 173, iters: 500, time: 0.056, data: 0.004) G_GAN: 3.945 G_L1: 30.361 D_real: 0.002 D_fake: 0.033 \n",
            "(epoch: 173, iters: 600, time: 0.058, data: 0.003) G_GAN: 5.720 G_L1: 5.661 D_real: 0.059 D_fake: 0.006 \n",
            "(epoch: 173, iters: 700, time: 0.058, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.725 D_fake: 0.666 \n",
            "(epoch: 173, iters: 800, time: 0.155, data: 0.002) G_GAN: 2.263 G_L1: 4.164 D_real: 0.039 D_fake: 0.194 \n",
            "(epoch: 173, iters: 900, time: 0.058, data: 0.003) G_GAN: 0.771 G_L1: 2.948 D_real: 0.003 D_fake: 0.647 \n",
            "(epoch: 173, iters: 1000, time: 0.058, data: 0.003) G_GAN: 0.707 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
            "End of epoch 173 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.059, data: 0.195) G_GAN: 1.106 G_L1: 5.750 D_real: 0.092 D_fake: 1.125 \n",
            "(epoch: 174, iters: 200, time: 1.056, data: 0.003) G_GAN: 0.701 G_L1: 0.000 D_real: 0.700 D_fake: 0.690 \n",
            "(epoch: 174, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.736 D_fake: 0.653 \n",
            "(epoch: 174, iters: 400, time: 0.058, data: 0.002) G_GAN: 0.882 G_L1: 0.000 D_real: 0.980 D_fake: 0.490 \n",
            "(epoch: 174, iters: 500, time: 0.057, data: 0.004) G_GAN: 0.737 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
            "(epoch: 174, iters: 600, time: 0.178, data: 0.003) G_GAN: 1.652 G_L1: 14.679 D_real: 0.076 D_fake: 0.378 \n",
            "(epoch: 174, iters: 700, time: 0.058, data: 0.005) G_GAN: 5.331 G_L1: 7.553 D_real: 0.006 D_fake: 0.008 \n",
            "(epoch: 174, iters: 800, time: 0.059, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.683 D_fake: 0.705 \n",
            "(epoch: 174, iters: 900, time: 0.059, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
            "(epoch: 174, iters: 1000, time: 0.781, data: 0.003) G_GAN: 5.225 G_L1: 16.382 D_real: 0.009 D_fake: 0.008 \n",
            "End of epoch 174 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.060, data: 0.195) G_GAN: 4.247 G_L1: 11.119 D_real: 0.046 D_fake: 0.018 \n",
            "(epoch: 175, iters: 200, time: 0.058, data: 0.003) G_GAN: 0.682 G_L1: 0.000 D_real: 0.681 D_fake: 0.714 \n",
            "(epoch: 175, iters: 300, time: 0.054, data: 0.003) G_GAN: 5.490 G_L1: 8.620 D_real: 0.010 D_fake: 0.006 \n",
            "(epoch: 175, iters: 400, time: 0.941, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.713 D_fake: 0.676 \n",
            "(epoch: 175, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.729 D_fake: 0.663 \n",
            "(epoch: 175, iters: 600, time: 0.059, data: 0.003) G_GAN: 1.801 G_L1: 2.924 D_real: 0.490 D_fake: 0.126 \n",
            "(epoch: 175, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.733 G_L1: 0.000 D_real: 0.736 D_fake: 0.653 \n",
            "(epoch: 175, iters: 800, time: 0.180, data: 0.002) G_GAN: 4.120 G_L1: 7.626 D_real: 0.025 D_fake: 0.024 \n",
            "(epoch: 175, iters: 900, time: 0.059, data: 0.003) G_GAN: 2.601 G_L1: 1.410 D_real: 0.689 D_fake: 0.042 \n",
            "(epoch: 175, iters: 1000, time: 0.061, data: 0.003) G_GAN: 0.622 G_L1: 0.000 D_real: 0.616 D_fake: 0.783 \n",
            "saving the latest model (epoch 175, total_iters 175000)\n",
            "saving the model at the end of epoch 175, iters 175000\n",
            "End of epoch 175 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 0.057, data: 0.273) G_GAN: 0.645 G_L1: 0.000 D_real: 0.640 D_fake: 0.764 \n",
            "(epoch: 176, iters: 200, time: 1.101, data: 0.003) G_GAN: 4.144 G_L1: 5.988 D_real: 0.032 D_fake: 0.031 \n",
            "(epoch: 176, iters: 300, time: 0.056, data: 0.003) G_GAN: 2.372 G_L1: 4.701 D_real: 0.002 D_fake: 0.139 \n",
            "(epoch: 176, iters: 400, time: 0.056, data: 0.003) G_GAN: 0.682 G_L1: 0.000 D_real: 0.681 D_fake: 0.706 \n",
            "(epoch: 176, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.705 D_fake: 0.685 \n",
            "(epoch: 176, iters: 600, time: 0.166, data: 0.003) G_GAN: 1.810 G_L1: 0.165 D_real: 0.705 D_fake: 0.201 \n",
            "(epoch: 176, iters: 700, time: 0.054, data: 0.009) G_GAN: 0.719 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
            "(epoch: 176, iters: 800, time: 0.057, data: 0.003) G_GAN: 0.749 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
            "(epoch: 176, iters: 900, time: 0.057, data: 0.004) G_GAN: 0.659 G_L1: 0.000 D_real: 0.657 D_fake: 0.732 \n",
            "(epoch: 176, iters: 1000, time: 0.789, data: 0.004) G_GAN: 0.754 G_L1: 0.000 D_real: 0.759 D_fake: 0.633 \n",
            "End of epoch 176 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.050, data: 0.214) G_GAN: 5.801 G_L1: 9.567 D_real: 0.073 D_fake: 0.004 \n",
            "(epoch: 177, iters: 200, time: 0.056, data: 0.004) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
            "(epoch: 177, iters: 300, time: 0.056, data: 0.002) G_GAN: 3.626 G_L1: 59.430 D_real: 0.011 D_fake: 0.039 \n",
            "(epoch: 177, iters: 400, time: 0.962, data: 0.004) G_GAN: 0.639 G_L1: 0.000 D_real: 0.638 D_fake: 0.756 \n",
            "(epoch: 177, iters: 500, time: 0.051, data: 0.003) G_GAN: 0.677 G_L1: 0.000 D_real: 0.682 D_fake: 0.708 \n",
            "(epoch: 177, iters: 600, time: 0.058, data: 0.004) G_GAN: 2.254 G_L1: 8.311 D_real: 0.254 D_fake: 0.156 \n",
            "(epoch: 177, iters: 700, time: 0.057, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
            "(epoch: 177, iters: 800, time: 0.168, data: 0.003) G_GAN: 4.606 G_L1: 7.108 D_real: 0.210 D_fake: 0.013 \n",
            "(epoch: 177, iters: 900, time: 0.055, data: 0.003) G_GAN: 0.657 G_L1: 0.000 D_real: 0.654 D_fake: 0.736 \n",
            "(epoch: 177, iters: 1000, time: 0.059, data: 0.004) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.670 \n",
            "End of epoch 177 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.056, data: 0.213) G_GAN: 3.032 G_L1: 3.348 D_real: 0.137 D_fake: 0.055 \n",
            "(epoch: 178, iters: 200, time: 1.108, data: 0.003) G_GAN: 0.649 G_L1: 0.000 D_real: 0.645 D_fake: 0.751 \n",
            "(epoch: 178, iters: 300, time: 0.057, data: 0.003) G_GAN: 0.766 G_L1: 0.000 D_real: 0.772 D_fake: 0.625 \n",
            "(epoch: 178, iters: 400, time: 0.057, data: 0.003) G_GAN: 6.717 G_L1: 6.634 D_real: 0.019 D_fake: 0.002 \n",
            "(epoch: 178, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.675 \n",
            "(epoch: 178, iters: 600, time: 0.172, data: 0.003) G_GAN: 0.701 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
            "(epoch: 178, iters: 700, time: 0.058, data: 0.005) G_GAN: 0.756 G_L1: 0.000 D_real: 0.762 D_fake: 0.632 \n",
            "(epoch: 178, iters: 800, time: 0.057, data: 0.003) G_GAN: 4.708 G_L1: 6.063 D_real: 1.323 D_fake: 0.007 \n",
            "(epoch: 178, iters: 900, time: 0.056, data: 0.004) G_GAN: 3.651 G_L1: 3.887 D_real: 0.013 D_fake: 0.034 \n",
            "(epoch: 178, iters: 1000, time: 0.789, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
            "End of epoch 178 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.056, data: 0.211) G_GAN: 5.111 G_L1: 15.413 D_real: 0.613 D_fake: 0.010 \n",
            "(epoch: 179, iters: 200, time: 0.063, data: 0.003) G_GAN: 1.070 G_L1: 0.676 D_real: 0.218 D_fake: 0.872 \n",
            "(epoch: 179, iters: 300, time: 0.057, data: 0.005) G_GAN: 1.013 G_L1: 0.000 D_real: 1.110 D_fake: 0.417 \n",
            "(epoch: 179, iters: 400, time: 0.968, data: 0.003) G_GAN: 3.686 G_L1: 22.328 D_real: 0.004 D_fake: 0.040 \n",
            "(epoch: 179, iters: 500, time: 0.057, data: 0.003) G_GAN: 0.662 G_L1: 0.000 D_real: 0.662 D_fake: 0.727 \n",
            "(epoch: 179, iters: 600, time: 0.056, data: 0.003) G_GAN: 0.644 G_L1: 0.000 D_real: 0.643 D_fake: 0.753 \n",
            "(epoch: 179, iters: 700, time: 0.054, data: 0.004) G_GAN: 0.683 G_L1: 0.000 D_real: 0.684 D_fake: 0.705 \n",
            "(epoch: 179, iters: 800, time: 0.172, data: 0.003) G_GAN: 0.842 G_L1: 2.925 D_real: 0.007 D_fake: 0.586 \n",
            "(epoch: 179, iters: 900, time: 0.051, data: 0.005) G_GAN: 0.667 G_L1: 0.000 D_real: 0.664 D_fake: 0.727 \n",
            "(epoch: 179, iters: 1000, time: 0.058, data: 0.004) G_GAN: 4.008 G_L1: 4.700 D_real: 0.063 D_fake: 0.025 \n",
            "End of epoch 179 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 0.057, data: 0.232) G_GAN: 5.639 G_L1: 6.188 D_real: 0.005 D_fake: 0.006 \n",
            "(epoch: 180, iters: 200, time: 1.080, data: 0.004) G_GAN: 0.729 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
            "(epoch: 180, iters: 300, time: 0.054, data: 0.003) G_GAN: 2.261 G_L1: 1.707 D_real: 0.049 D_fake: 0.165 \n",
            "(epoch: 180, iters: 400, time: 0.059, data: 0.003) G_GAN: 0.779 G_L1: 0.000 D_real: 0.786 D_fake: 0.611 \n",
            "(epoch: 180, iters: 500, time: 0.056, data: 0.003) G_GAN: 4.403 G_L1: 7.184 D_real: 0.154 D_fake: 0.015 \n",
            "(epoch: 180, iters: 600, time: 0.167, data: 0.002) G_GAN: 0.816 G_L1: 0.000 D_real: 0.827 D_fake: 0.589 \n",
            "(epoch: 180, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.877 G_L1: 5.201 D_real: 0.037 D_fake: 0.982 \n",
            "(epoch: 180, iters: 800, time: 0.057, data: 0.003) G_GAN: 0.659 G_L1: 0.000 D_real: 0.659 D_fake: 0.730 \n",
            "(epoch: 180, iters: 900, time: 0.059, data: 0.003) G_GAN: 1.102 G_L1: 0.275 D_real: 0.819 D_fake: 0.365 \n",
            "(epoch: 180, iters: 1000, time: 0.785, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.697 D_fake: 0.693 \n",
            "saving the latest model (epoch 180, total_iters 180000)\n",
            "saving the model at the end of epoch 180, iters 180000\n",
            "End of epoch 180 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.065, data: 0.179) G_GAN: 2.726 G_L1: 5.742 D_real: 0.094 D_fake: 0.076 \n",
            "(epoch: 181, iters: 200, time: 0.050, data: 0.004) G_GAN: 2.317 G_L1: 3.002 D_real: 0.103 D_fake: 0.104 \n",
            "(epoch: 181, iters: 300, time: 0.055, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.695 \n",
            "(epoch: 181, iters: 400, time: 0.968, data: 0.003) G_GAN: 0.640 G_L1: 0.000 D_real: 0.638 D_fake: 0.756 \n",
            "(epoch: 181, iters: 500, time: 0.050, data: 0.003) G_GAN: 4.168 G_L1: 11.173 D_real: 0.025 D_fake: 0.025 \n",
            "(epoch: 181, iters: 600, time: 0.059, data: 0.003) G_GAN: 3.760 G_L1: 10.534 D_real: 0.072 D_fake: 0.029 \n",
            "(epoch: 181, iters: 700, time: 0.055, data: 0.004) G_GAN: 2.187 G_L1: 9.046 D_real: 0.069 D_fake: 0.151 \n",
            "(epoch: 181, iters: 800, time: 0.165, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.723 D_fake: 0.664 \n",
            "(epoch: 181, iters: 900, time: 0.058, data: 0.003) G_GAN: 6.786 G_L1: 9.492 D_real: 0.025 D_fake: 0.002 \n",
            "(epoch: 181, iters: 1000, time: 0.051, data: 0.002) G_GAN: 1.656 G_L1: 19.127 D_real: 0.010 D_fake: 0.351 \n",
            "End of epoch 181 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.055, data: 0.253) G_GAN: 1.380 G_L1: 7.407 D_real: 0.642 D_fake: 0.234 \n",
            "(epoch: 182, iters: 200, time: 1.001, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.706 \n",
            "(epoch: 182, iters: 300, time: 0.058, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.775 D_fake: 0.628 \n",
            "(epoch: 182, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.689 G_L1: 0.000 D_real: 0.687 D_fake: 0.703 \n",
            "(epoch: 182, iters: 500, time: 0.051, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
            "(epoch: 182, iters: 600, time: 0.302, data: 0.002) G_GAN: 3.491 G_L1: 14.737 D_real: 0.009 D_fake: 0.043 \n",
            "(epoch: 182, iters: 700, time: 0.057, data: 0.003) G_GAN: 1.481 G_L1: 3.733 D_real: 0.005 D_fake: 0.610 \n",
            "(epoch: 182, iters: 800, time: 0.054, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.765 D_fake: 0.631 \n",
            "(epoch: 182, iters: 900, time: 0.055, data: 0.002) G_GAN: 2.350 G_L1: 3.434 D_real: 0.094 D_fake: 0.120 \n",
            "(epoch: 182, iters: 1000, time: 0.801, data: 0.005) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
            "End of epoch 182 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.059, data: 0.185) G_GAN: 2.044 G_L1: 3.015 D_real: 0.527 D_fake: 0.128 \n",
            "(epoch: 183, iters: 200, time: 0.057, data: 0.004) G_GAN: 0.675 G_L1: 0.000 D_real: 0.675 D_fake: 0.713 \n",
            "(epoch: 183, iters: 300, time: 0.058, data: 0.003) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.701 \n",
            "(epoch: 183, iters: 400, time: 0.990, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
            "(epoch: 183, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.829 G_L1: 0.000 D_real: 0.844 D_fake: 0.570 \n",
            "(epoch: 183, iters: 600, time: 0.057, data: 0.003) G_GAN: 0.706 G_L1: 0.002 D_real: 0.710 D_fake: 0.678 \n",
            "(epoch: 183, iters: 700, time: 0.056, data: 0.003) G_GAN: 0.672 G_L1: 0.000 D_real: 0.673 D_fake: 0.716 \n",
            "(epoch: 183, iters: 800, time: 0.175, data: 0.003) G_GAN: 3.432 G_L1: 5.203 D_real: 0.020 D_fake: 0.053 \n",
            "(epoch: 183, iters: 900, time: 0.056, data: 0.010) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
            "(epoch: 183, iters: 1000, time: 0.053, data: 0.003) G_GAN: 6.225 G_L1: 6.062 D_real: 0.061 D_fake: 0.003 \n",
            "End of epoch 183 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 0.054, data: 0.234) G_GAN: 0.702 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
            "(epoch: 184, iters: 200, time: 1.009, data: 0.003) G_GAN: 0.683 G_L1: 0.000 D_real: 0.679 D_fake: 0.712 \n",
            "(epoch: 184, iters: 300, time: 0.058, data: 0.003) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.707 \n",
            "(epoch: 184, iters: 400, time: 0.058, data: 0.003) G_GAN: 1.149 G_L1: 2.829 D_real: 0.165 D_fake: 1.480 \n",
            "(epoch: 184, iters: 500, time: 0.058, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.643 \n",
            "(epoch: 184, iters: 600, time: 0.305, data: 0.003) G_GAN: 0.670 G_L1: 0.000 D_real: 0.669 D_fake: 0.719 \n",
            "(epoch: 184, iters: 700, time: 0.058, data: 0.005) G_GAN: 2.674 G_L1: 1.891 D_real: 0.035 D_fake: 0.088 \n",
            "(epoch: 184, iters: 800, time: 0.058, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
            "(epoch: 184, iters: 900, time: 0.057, data: 0.003) G_GAN: 0.646 G_L1: 0.000 D_real: 0.646 D_fake: 0.747 \n",
            "(epoch: 184, iters: 1000, time: 0.792, data: 0.003) G_GAN: 0.661 G_L1: 0.000 D_real: 0.660 D_fake: 0.730 \n",
            "End of epoch 184 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.058, data: 0.216) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.661 \n",
            "(epoch: 185, iters: 200, time: 0.053, data: 0.003) G_GAN: 5.555 G_L1: 9.049 D_real: 0.224 D_fake: 0.008 \n",
            "(epoch: 185, iters: 300, time: 0.054, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.669 \n",
            "(epoch: 185, iters: 400, time: 1.001, data: 0.003) G_GAN: 1.242 G_L1: 1.969 D_real: 0.334 D_fake: 0.452 \n",
            "(epoch: 185, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
            "(epoch: 185, iters: 600, time: 0.059, data: 0.008) G_GAN: 0.687 G_L1: 0.000 D_real: 0.689 D_fake: 0.700 \n",
            "(epoch: 185, iters: 700, time: 0.055, data: 0.004) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.652 \n",
            "(epoch: 185, iters: 800, time: 0.166, data: 0.003) G_GAN: 1.487 G_L1: 2.391 D_real: 0.345 D_fake: 0.223 \n",
            "(epoch: 185, iters: 900, time: 0.050, data: 0.003) G_GAN: 0.686 G_L1: 0.000 D_real: 0.684 D_fake: 0.704 \n",
            "(epoch: 185, iters: 1000, time: 0.057, data: 0.003) G_GAN: 1.240 G_L1: 2.242 D_real: 0.087 D_fake: 0.802 \n",
            "saving the latest model (epoch 185, total_iters 185000)\n",
            "saving the model at the end of epoch 185, iters 185000\n",
            "End of epoch 185 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.059, data: 0.177) G_GAN: 0.671 G_L1: 0.000 D_real: 0.670 D_fake: 0.720 \n",
            "(epoch: 186, iters: 200, time: 1.000, data: 0.003) G_GAN: 6.197 G_L1: 16.982 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 186, iters: 300, time: 0.059, data: 0.002) G_GAN: 0.905 G_L1: 0.006 D_real: 0.639 D_fake: 0.550 \n",
            "(epoch: 186, iters: 400, time: 0.057, data: 0.004) G_GAN: 0.717 G_L1: 0.000 D_real: 0.723 D_fake: 0.670 \n",
            "(epoch: 186, iters: 500, time: 0.057, data: 0.004) G_GAN: 2.446 G_L1: 5.603 D_real: 0.014 D_fake: 0.146 \n",
            "(epoch: 186, iters: 600, time: 0.170, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.690 \n",
            "(epoch: 186, iters: 700, time: 0.056, data: 0.003) G_GAN: 3.812 G_L1: 3.623 D_real: 0.060 D_fake: 0.032 \n",
            "(epoch: 186, iters: 800, time: 0.056, data: 0.003) G_GAN: 6.247 G_L1: 7.084 D_real: 0.023 D_fake: 0.003 \n",
            "(epoch: 186, iters: 900, time: 0.058, data: 0.004) G_GAN: 0.679 G_L1: 0.000 D_real: 0.680 D_fake: 0.711 \n",
            "(epoch: 186, iters: 1000, time: 0.929, data: 0.003) G_GAN: 0.769 G_L1: 0.000 D_real: 0.777 D_fake: 0.622 \n",
            "End of epoch 186 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.059, data: 0.200) G_GAN: 0.746 G_L1: 6.121 D_real: 0.575 D_fake: 0.658 \n",
            "(epoch: 187, iters: 200, time: 0.056, data: 0.003) G_GAN: 0.652 G_L1: 0.000 D_real: 0.650 D_fake: 0.744 \n",
            "(epoch: 187, iters: 300, time: 0.056, data: 0.003) G_GAN: 2.671 G_L1: 14.113 D_real: 0.056 D_fake: 0.104 \n",
            "(epoch: 187, iters: 400, time: 0.969, data: 0.003) G_GAN: 0.679 G_L1: 0.000 D_real: 0.679 D_fake: 0.709 \n",
            "(epoch: 187, iters: 500, time: 0.059, data: 0.007) G_GAN: 3.747 G_L1: 2.106 D_real: 0.315 D_fake: 0.033 \n",
            "(epoch: 187, iters: 600, time: 0.059, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.672 D_fake: 0.721 \n",
            "(epoch: 187, iters: 700, time: 0.055, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.655 \n",
            "(epoch: 187, iters: 800, time: 0.160, data: 0.003) G_GAN: 0.645 G_L1: 0.000 D_real: 0.644 D_fake: 0.747 \n",
            "(epoch: 187, iters: 900, time: 0.060, data: 0.003) G_GAN: 2.199 G_L1: 0.584 D_real: 0.424 D_fake: 0.095 \n",
            "(epoch: 187, iters: 1000, time: 0.055, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
            "End of epoch 187 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 0.058, data: 0.215) G_GAN: 0.712 G_L1: 0.000 D_real: 0.713 D_fake: 0.674 \n",
            "(epoch: 188, iters: 200, time: 0.969, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.651 \n",
            "(epoch: 188, iters: 300, time: 0.060, data: 0.005) G_GAN: 2.401 G_L1: 2.695 D_real: 0.274 D_fake: 0.096 \n",
            "(epoch: 188, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.657 \n",
            "(epoch: 188, iters: 500, time: 0.058, data: 0.010) G_GAN: 3.420 G_L1: 4.639 D_real: 0.021 D_fake: 0.046 \n",
            "(epoch: 188, iters: 600, time: 0.169, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.760 D_fake: 0.634 \n",
            "(epoch: 188, iters: 700, time: 0.059, data: 0.003) G_GAN: 6.143 G_L1: 11.154 D_real: 0.019 D_fake: 0.004 \n",
            "(epoch: 188, iters: 800, time: 0.061, data: 0.008) G_GAN: 0.677 G_L1: 0.000 D_real: 0.676 D_fake: 0.711 \n",
            "(epoch: 188, iters: 900, time: 0.056, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
            "(epoch: 188, iters: 1000, time: 0.944, data: 0.005) G_GAN: 0.698 G_L1: 0.000 D_real: 0.697 D_fake: 0.692 \n",
            "End of epoch 188 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.054, data: 0.177) G_GAN: 0.564 G_L1: 3.746 D_real: 0.396 D_fake: 1.478 \n",
            "(epoch: 189, iters: 200, time: 0.055, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.697 \n",
            "(epoch: 189, iters: 300, time: 0.057, data: 0.003) G_GAN: 3.293 G_L1: 6.430 D_real: 0.013 D_fake: 0.052 \n",
            "(epoch: 189, iters: 400, time: 1.016, data: 0.003) G_GAN: 4.323 G_L1: 4.572 D_real: 0.019 D_fake: 0.026 \n",
            "(epoch: 189, iters: 500, time: 0.058, data: 0.005) G_GAN: 2.767 G_L1: 11.858 D_real: 0.451 D_fake: 0.105 \n",
            "(epoch: 189, iters: 600, time: 0.059, data: 0.003) G_GAN: 0.638 G_L1: 0.000 D_real: 0.637 D_fake: 0.754 \n",
            "(epoch: 189, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.658 \n",
            "(epoch: 189, iters: 800, time: 0.170, data: 0.003) G_GAN: 2.344 G_L1: 3.891 D_real: 0.015 D_fake: 0.130 \n",
            "(epoch: 189, iters: 900, time: 0.058, data: 0.010) G_GAN: 0.835 G_L1: 0.000 D_real: 0.848 D_fake: 0.567 \n",
            "(epoch: 189, iters: 1000, time: 0.046, data: 0.003) G_GAN: 0.672 G_L1: 0.000 D_real: 0.675 D_fake: 0.713 \n",
            "End of epoch 189 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.059, data: 0.259) G_GAN: 0.549 G_L1: 1.286 D_real: 0.002 D_fake: 1.444 \n",
            "(epoch: 190, iters: 200, time: 0.982, data: 0.003) G_GAN: 0.856 G_L1: 0.000 D_real: 0.871 D_fake: 0.548 \n",
            "(epoch: 190, iters: 300, time: 0.057, data: 0.003) G_GAN: 6.735 G_L1: 9.134 D_real: 0.021 D_fake: 0.003 \n",
            "(epoch: 190, iters: 400, time: 0.058, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.720 D_fake: 0.669 \n",
            "(epoch: 190, iters: 500, time: 0.054, data: 0.002) G_GAN: 5.418 G_L1: 2.253 D_real: 0.004 D_fake: 0.007 \n",
            "(epoch: 190, iters: 600, time: 0.173, data: 0.003) G_GAN: 6.933 G_L1: 22.511 D_real: 0.007 D_fake: 0.002 \n",
            "(epoch: 190, iters: 700, time: 0.055, data: 0.003) G_GAN: 0.665 G_L1: 0.000 D_real: 0.665 D_fake: 0.724 \n",
            "(epoch: 190, iters: 800, time: 0.060, data: 0.003) G_GAN: 0.660 G_L1: 0.000 D_real: 0.660 D_fake: 0.728 \n",
            "(epoch: 190, iters: 900, time: 0.057, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.681 D_fake: 0.707 \n",
            "(epoch: 190, iters: 1000, time: 0.930, data: 0.005) G_GAN: 5.719 G_L1: 14.254 D_real: 0.000 D_fake: 0.006 \n",
            "saving the latest model (epoch 190, total_iters 190000)\n",
            "saving the model at the end of epoch 190, iters 190000\n",
            "End of epoch 190 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.054, data: 0.274) G_GAN: 2.866 G_L1: 5.327 D_real: 0.046 D_fake: 0.068 \n",
            "(epoch: 191, iters: 200, time: 0.058, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
            "(epoch: 191, iters: 300, time: 0.056, data: 0.003) G_GAN: 0.684 G_L1: 3.447 D_real: 0.445 D_fake: 0.866 \n",
            "(epoch: 191, iters: 400, time: 1.001, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.680 D_fake: 0.709 \n",
            "(epoch: 191, iters: 500, time: 0.058, data: 0.003) G_GAN: 0.659 G_L1: 0.000 D_real: 0.660 D_fake: 0.728 \n",
            "(epoch: 191, iters: 600, time: 0.054, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.677 D_fake: 0.712 \n",
            "(epoch: 191, iters: 700, time: 0.059, data: 0.002) G_GAN: 4.726 G_L1: 21.438 D_real: 0.003 D_fake: 0.012 \n",
            "(epoch: 191, iters: 800, time: 0.168, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.724 D_fake: 0.665 \n",
            "(epoch: 191, iters: 900, time: 0.059, data: 0.004) G_GAN: 0.687 G_L1: 0.000 D_real: 0.684 D_fake: 0.705 \n",
            "(epoch: 191, iters: 1000, time: 0.059, data: 0.003) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
            "End of epoch 191 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 0.054, data: 0.218) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.696 \n",
            "(epoch: 192, iters: 200, time: 0.990, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
            "(epoch: 192, iters: 300, time: 0.059, data: 0.006) G_GAN: 0.686 G_L1: 0.000 D_real: 0.684 D_fake: 0.704 \n",
            "(epoch: 192, iters: 400, time: 0.057, data: 0.004) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
            "(epoch: 192, iters: 500, time: 0.057, data: 0.002) G_GAN: 0.642 G_L1: 0.000 D_real: 0.639 D_fake: 0.764 \n",
            "(epoch: 192, iters: 600, time: 0.174, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.700 D_fake: 0.690 \n",
            "(epoch: 192, iters: 700, time: 0.054, data: 0.004) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.679 \n",
            "(epoch: 192, iters: 800, time: 0.054, data: 0.003) G_GAN: 4.974 G_L1: 8.078 D_real: 0.002 D_fake: 0.015 \n",
            "(epoch: 192, iters: 900, time: 0.058, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.706 \n",
            "(epoch: 192, iters: 1000, time: 0.954, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
            "End of epoch 192 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.055, data: 0.179) G_GAN: 4.932 G_L1: 4.580 D_real: 0.025 D_fake: 0.010 \n",
            "(epoch: 193, iters: 200, time: 0.059, data: 0.009) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.691 \n",
            "(epoch: 193, iters: 300, time: 0.055, data: 0.003) G_GAN: 0.120 G_L1: 2.649 D_real: 0.090 D_fake: 3.133 \n",
            "(epoch: 193, iters: 400, time: 1.012, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.660 \n",
            "(epoch: 193, iters: 500, time: 0.056, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.674 D_fake: 0.714 \n",
            "(epoch: 193, iters: 600, time: 0.054, data: 0.004) G_GAN: 2.187 G_L1: 3.007 D_real: 0.440 D_fake: 0.149 \n",
            "(epoch: 193, iters: 700, time: 0.059, data: 0.003) G_GAN: 0.675 G_L1: 0.000 D_real: 0.674 D_fake: 0.714 \n",
            "(epoch: 193, iters: 800, time: 0.159, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
            "(epoch: 193, iters: 900, time: 0.053, data: 0.006) G_GAN: 0.665 G_L1: 0.000 D_real: 0.665 D_fake: 0.723 \n",
            "(epoch: 193, iters: 1000, time: 0.059, data: 0.003) G_GAN: 6.162 G_L1: 51.356 D_real: 0.018 D_fake: 0.003 \n",
            "End of epoch 193 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.059, data: 0.243) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.706 \n",
            "(epoch: 194, iters: 200, time: 1.181, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.658 \n",
            "(epoch: 194, iters: 300, time: 0.058, data: 0.008) G_GAN: 2.722 G_L1: 0.005 D_real: 0.883 D_fake: 0.074 \n",
            "(epoch: 194, iters: 400, time: 0.057, data: 0.003) G_GAN: 0.750 G_L1: 2.650 D_real: 0.012 D_fake: 0.903 \n",
            "(epoch: 194, iters: 500, time: 0.055, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
            "(epoch: 194, iters: 600, time: 0.171, data: 0.003) G_GAN: 0.673 G_L1: 0.000 D_real: 0.673 D_fake: 0.716 \n",
            "(epoch: 194, iters: 700, time: 0.057, data: 0.004) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
            "(epoch: 194, iters: 800, time: 0.057, data: 0.003) G_GAN: 0.648 G_L1: 0.000 D_real: 0.647 D_fake: 0.745 \n",
            "(epoch: 194, iters: 900, time: 0.057, data: 0.003) G_GAN: 0.803 G_L1: 0.000 D_real: 0.816 D_fake: 0.598 \n",
            "(epoch: 194, iters: 1000, time: 0.961, data: 0.003) G_GAN: 2.397 G_L1: 4.121 D_real: 3.811 D_fake: 0.092 \n",
            "End of epoch 194 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.068, data: 0.209) G_GAN: 4.123 G_L1: 2.198 D_real: 0.110 D_fake: 0.020 \n",
            "(epoch: 195, iters: 200, time: 0.049, data: 0.004) G_GAN: 0.730 G_L1: 1.358 D_real: 0.072 D_fake: 0.939 \n",
            "(epoch: 195, iters: 300, time: 0.054, data: 0.004) G_GAN: 0.684 G_L1: 0.000 D_real: 0.686 D_fake: 0.710 \n",
            "(epoch: 195, iters: 400, time: 1.008, data: 0.005) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
            "(epoch: 195, iters: 500, time: 0.056, data: 0.004) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.713 \n",
            "(epoch: 195, iters: 600, time: 0.056, data: 0.005) G_GAN: 0.621 G_L1: 4.287 D_real: 0.017 D_fake: 1.238 \n",
            "(epoch: 195, iters: 700, time: 0.060, data: 0.003) G_GAN: 6.084 G_L1: 15.588 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 195, iters: 800, time: 0.171, data: 0.004) G_GAN: 4.154 G_L1: 3.116 D_real: 0.014 D_fake: 0.024 \n",
            "(epoch: 195, iters: 900, time: 0.059, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.677 \n",
            "(epoch: 195, iters: 1000, time: 0.057, data: 0.003) G_GAN: 4.438 G_L1: 5.178 D_real: 0.092 D_fake: 0.018 \n",
            "saving the latest model (epoch 195, total_iters 195000)\n",
            "saving the model at the end of epoch 195, iters 195000\n",
            "End of epoch 195 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 0.058, data: 0.255) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
            "(epoch: 196, iters: 200, time: 1.058, data: 0.003) G_GAN: 0.966 G_L1: 3.797 D_real: 0.020 D_fake: 0.614 \n",
            "(epoch: 196, iters: 300, time: 0.058, data: 0.004) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.685 \n",
            "(epoch: 196, iters: 400, time: 0.058, data: 0.003) G_GAN: 0.846 G_L1: 0.000 D_real: 0.848 D_fake: 0.562 \n",
            "(epoch: 196, iters: 500, time: 0.060, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
            "(epoch: 196, iters: 600, time: 0.326, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
            "(epoch: 196, iters: 700, time: 0.061, data: 0.003) G_GAN: 0.675 G_L1: 0.000 D_real: 0.675 D_fake: 0.713 \n",
            "(epoch: 196, iters: 800, time: 0.059, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.718 D_fake: 0.670 \n",
            "(epoch: 196, iters: 900, time: 0.057, data: 0.004) G_GAN: 5.095 G_L1: 26.017 D_real: 0.005 D_fake: 0.012 \n",
            "(epoch: 196, iters: 1000, time: 0.861, data: 0.003) G_GAN: 6.147 G_L1: 9.610 D_real: 0.033 D_fake: 0.003 \n",
            "End of epoch 196 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.058, data: 0.245) G_GAN: 6.836 G_L1: 22.878 D_real: 0.026 D_fake: 0.002 \n",
            "(epoch: 197, iters: 200, time: 0.057, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.681 \n",
            "(epoch: 197, iters: 300, time: 0.063, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.685 \n",
            "(epoch: 197, iters: 400, time: 0.983, data: 0.004) G_GAN: 0.763 G_L1: 0.000 D_real: 0.765 D_fake: 0.630 \n",
            "(epoch: 197, iters: 500, time: 0.053, data: 0.005) G_GAN: 7.857 G_L1: 3.467 D_real: 0.723 D_fake: 0.001 \n",
            "(epoch: 197, iters: 600, time: 0.060, data: 0.004) G_GAN: 0.763 G_L1: 0.000 D_real: 0.764 D_fake: 0.629 \n",
            "(epoch: 197, iters: 700, time: 0.058, data: 0.009) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.700 \n",
            "(epoch: 197, iters: 800, time: 0.151, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.701 \n",
            "(epoch: 197, iters: 900, time: 0.057, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.732 D_fake: 0.659 \n",
            "(epoch: 197, iters: 1000, time: 0.058, data: 0.003) G_GAN: 0.692 G_L1: 0.000 D_real: 0.695 D_fake: 0.698 \n",
            "End of epoch 197 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.055, data: 0.205) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
            "(epoch: 198, iters: 200, time: 1.174, data: 0.003) G_GAN: 6.676 G_L1: 18.855 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 198, iters: 300, time: 0.059, data: 0.003) G_GAN: 0.672 G_L1: 0.000 D_real: 0.671 D_fake: 0.717 \n",
            "(epoch: 198, iters: 400, time: 0.064, data: 0.004) G_GAN: 2.757 G_L1: 1.816 D_real: 0.005 D_fake: 0.085 \n",
            "(epoch: 198, iters: 500, time: 0.059, data: 0.003) G_GAN: 0.832 G_L1: 0.000 D_real: 0.835 D_fake: 0.575 \n",
            "(epoch: 198, iters: 600, time: 0.169, data: 0.003) G_GAN: 7.909 G_L1: 6.926 D_real: 0.039 D_fake: 0.001 \n",
            "(epoch: 198, iters: 700, time: 0.057, data: 0.004) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.655 \n",
            "(epoch: 198, iters: 800, time: 0.059, data: 0.003) G_GAN: 1.932 G_L1: 2.016 D_real: 0.001 D_fake: 0.201 \n",
            "(epoch: 198, iters: 900, time: 0.055, data: 0.002) G_GAN: 2.948 G_L1: 8.688 D_real: 0.002 D_fake: 0.078 \n",
            "(epoch: 198, iters: 1000, time: 0.847, data: 0.003) G_GAN: 0.666 G_L1: 0.000 D_real: 0.666 D_fake: 0.726 \n",
            "End of epoch 198 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.059, data: 0.209) G_GAN: 2.756 G_L1: 11.892 D_real: 0.003 D_fake: 0.085 \n",
            "(epoch: 199, iters: 200, time: 0.058, data: 0.003) G_GAN: 2.739 G_L1: 3.213 D_real: 0.010 D_fake: 0.079 \n",
            "(epoch: 199, iters: 300, time: 0.058, data: 0.003) G_GAN: 5.661 G_L1: 3.835 D_real: 0.414 D_fake: 0.007 \n",
            "(epoch: 199, iters: 400, time: 1.026, data: 0.004) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.691 \n",
            "(epoch: 199, iters: 500, time: 0.060, data: 0.003) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.678 \n",
            "(epoch: 199, iters: 600, time: 0.054, data: 0.003) G_GAN: 1.295 G_L1: 3.948 D_real: 0.042 D_fake: 0.377 \n",
            "(epoch: 199, iters: 700, time: 0.057, data: 0.003) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.698 \n",
            "(epoch: 199, iters: 800, time: 0.165, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.719 D_fake: 0.669 \n",
            "(epoch: 199, iters: 900, time: 0.056, data: 0.004) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.681 \n",
            "(epoch: 199, iters: 1000, time: 0.058, data: 0.011) G_GAN: 0.669 G_L1: 0.000 D_real: 0.668 D_fake: 0.721 \n",
            "End of epoch 199 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 0.066, data: 0.165) G_GAN: 1.187 G_L1: 0.249 D_real: 0.382 D_fake: 0.379 \n",
            "(epoch: 200, iters: 200, time: 1.152, data: 0.004) G_GAN: 0.857 G_L1: 4.568 D_real: 0.009 D_fake: 0.628 \n",
            "(epoch: 200, iters: 300, time: 0.054, data: 0.002) G_GAN: 2.918 G_L1: 1.459 D_real: 0.087 D_fake: 0.067 \n",
            "(epoch: 200, iters: 400, time: 0.056, data: 0.003) G_GAN: 2.128 G_L1: 0.777 D_real: 0.217 D_fake: 0.150 \n",
            "(epoch: 200, iters: 500, time: 0.055, data: 0.004) G_GAN: 6.169 G_L1: 16.009 D_real: 0.053 D_fake: 0.010 \n",
            "(epoch: 200, iters: 600, time: 0.161, data: 0.003) G_GAN: 0.759 G_L1: 0.000 D_real: 0.759 D_fake: 0.637 \n",
            "(epoch: 200, iters: 700, time: 0.056, data: 0.005) G_GAN: 0.676 G_L1: 0.000 D_real: 0.676 D_fake: 0.712 \n",
            "(epoch: 200, iters: 800, time: 0.055, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.728 D_fake: 0.665 \n",
            "(epoch: 200, iters: 900, time: 0.058, data: 0.003) G_GAN: 2.267 G_L1: 13.446 D_real: 0.032 D_fake: 0.147 \n",
            "(epoch: 200, iters: 1000, time: 0.862, data: 0.004) G_GAN: 0.907 G_L1: 0.004 D_real: 0.815 D_fake: 0.522 \n",
            "saving the latest model (epoch 200, total_iters 200000)\n",
            "saving the model at the end of epoch 200, iters 200000\n",
            "End of epoch 200 / 200 \t Time Taken: 50 sec\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: D_fake ▄▁▄▂▅▁▃▁▁▁▁▄▄▃▅▄▂▅▅▁▁▄▁▅▂▁▂▁▅▄▁▄█▁▄▄▅▂▅▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: D_real ▅▁▅▁▄▁▇▁▁▁▁▆▅█▄▅▁▄▄▁▂▅▄▄▂▄▄▁▄▁▁▅▁▆▅▅▄▁▄▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  G_GAN ▁▃▁▂▁▆▁▆▄▄▄▁▁▁▁▁▃▁▁█▃▁▇▁▂▆▂▅▁▁▅▁▁▃▁▁▁▃▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   G_L1 ▁█▁▁▁▆▁▄▂▂▃▁▁▁▁▁▃▁▁▇▁▁▁▁▁▁▂▂▁▂▂▁▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: D_fake 0.5224\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: D_real 0.81455\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  G_GAN 0.90733\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   G_L1 0.00393\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfacades_pix2pix\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kshitizkhanal7/CycleGAN-and-pix2pix/runs/26jejaw0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1700 media file(s), 537 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220805_215951-26jejaw0/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot ./new_roof/ --name facades_pix2pix --model pix2pix --direction BtoA --use_wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
        "\n",
        "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
        "\n",
        "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
        "\n",
        "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mey7o6j-0368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b841da34-f867-4acc-ef34-313b8878a316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "facades_label2photo_pretrained\tfacades_pix2pix\n"
          ]
        }
      ],
      "source": [
        "!ls checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/shrub.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCRy44Qe6azx",
        "outputId": "1a0de4b8-5c91-410b-a2d0-93ec6d8da58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/shrub.zip\n",
            "   creating: shrub/test/\n",
            "  inflating: shrub/test/image0.jpg   \n",
            "  inflating: shrub/test/image1.jpg   \n",
            "  inflating: shrub/test/image10.jpg  \n",
            "  inflating: shrub/test/image100.jpg  \n",
            "  inflating: shrub/test/image101.jpg  \n",
            "  inflating: shrub/test/image102.jpg  \n",
            "  inflating: shrub/test/image103.jpg  \n",
            "  inflating: shrub/test/image104.jpg  \n",
            "  inflating: shrub/test/image105.jpg  \n",
            "  inflating: shrub/test/image106.jpg  \n",
            "  inflating: shrub/test/image107.jpg  \n",
            "  inflating: shrub/test/image108.jpg  \n",
            "  inflating: shrub/test/image109.jpg  \n",
            "  inflating: shrub/test/image11.jpg  \n",
            "  inflating: shrub/test/image110.jpg  \n",
            "  inflating: shrub/test/image111.jpg  \n",
            "  inflating: shrub/test/image112.jpg  \n",
            "  inflating: shrub/test/image113.jpg  \n",
            "  inflating: shrub/test/image114.jpg  \n",
            "  inflating: shrub/test/image115.jpg  \n",
            "  inflating: shrub/test/image116.jpg  \n",
            "  inflating: shrub/test/image117.jpg  \n",
            "  inflating: shrub/test/image118.jpg  \n",
            "  inflating: shrub/test/image119.jpg  \n",
            "  inflating: shrub/test/image12.jpg  \n",
            "  inflating: shrub/test/image120.jpg  \n",
            "  inflating: shrub/test/image121.jpg  \n",
            "  inflating: shrub/test/image122.jpg  \n",
            "  inflating: shrub/test/image123.jpg  \n",
            "  inflating: shrub/test/image124.jpg  \n",
            "  inflating: shrub/test/image125.jpg  \n",
            "  inflating: shrub/test/image126.jpg  \n",
            "  inflating: shrub/test/image127.jpg  \n",
            "  inflating: shrub/test/image128.jpg  \n",
            "  inflating: shrub/test/image129.jpg  \n",
            "  inflating: shrub/test/image13.jpg  \n",
            "  inflating: shrub/test/image130.jpg  \n",
            "  inflating: shrub/test/image131.jpg  \n",
            "  inflating: shrub/test/image132.jpg  \n",
            "  inflating: shrub/test/image133.jpg  \n",
            "  inflating: shrub/test/image134.jpg  \n",
            "  inflating: shrub/test/image135.jpg  \n",
            "  inflating: shrub/test/image136.jpg  \n",
            "  inflating: shrub/test/image137.jpg  \n",
            "  inflating: shrub/test/image138.jpg  \n",
            "  inflating: shrub/test/image139.jpg  \n",
            "  inflating: shrub/test/image14.jpg  \n",
            "  inflating: shrub/test/image140.jpg  \n",
            "  inflating: shrub/test/image141.jpg  \n",
            "  inflating: shrub/test/image142.jpg  \n",
            "  inflating: shrub/test/image143.jpg  \n",
            "  inflating: shrub/test/image144.jpg  \n",
            "  inflating: shrub/test/image145.jpg  \n",
            "  inflating: shrub/test/image146.jpg  \n",
            "  inflating: shrub/test/image147.jpg  \n",
            "  inflating: shrub/test/image148.jpg  \n",
            "  inflating: shrub/test/image149.jpg  \n",
            "  inflating: shrub/test/image15.jpg  \n",
            "  inflating: shrub/test/image150.jpg  \n",
            "  inflating: shrub/test/image151.jpg  \n",
            "  inflating: shrub/test/image152.jpg  \n",
            "  inflating: shrub/test/image153.jpg  \n",
            "  inflating: shrub/test/image154.jpg  \n",
            "  inflating: shrub/test/image155.jpg  \n",
            "  inflating: shrub/test/image156.jpg  \n",
            "  inflating: shrub/test/image157.jpg  \n",
            "  inflating: shrub/test/image158.jpg  \n",
            "  inflating: shrub/test/image159.jpg  \n",
            "  inflating: shrub/test/image16.jpg  \n",
            "  inflating: shrub/test/image160.jpg  \n",
            "  inflating: shrub/test/image161.jpg  \n",
            "  inflating: shrub/test/image162.jpg  \n",
            "  inflating: shrub/test/image163.jpg  \n",
            "  inflating: shrub/test/image164.jpg  \n",
            "  inflating: shrub/test/image165.jpg  \n",
            "  inflating: shrub/test/image166.jpg  \n",
            "  inflating: shrub/test/image167.jpg  \n",
            "  inflating: shrub/test/image168.jpg  \n",
            "  inflating: shrub/test/image169.jpg  \n",
            "  inflating: shrub/test/image17.jpg  \n",
            "  inflating: shrub/test/image170.jpg  \n",
            "  inflating: shrub/test/image171.jpg  \n",
            "  inflating: shrub/test/image172.jpg  \n",
            "  inflating: shrub/test/image173.jpg  \n",
            "  inflating: shrub/test/image174.jpg  \n",
            "  inflating: shrub/test/image175.jpg  \n",
            "  inflating: shrub/test/image176.jpg  \n",
            "  inflating: shrub/test/image177.jpg  \n",
            "  inflating: shrub/test/image178.jpg  \n",
            "  inflating: shrub/test/image179.jpg  \n",
            "  inflating: shrub/test/image18.jpg  \n",
            "  inflating: shrub/test/image180.jpg  \n",
            "  inflating: shrub/test/image181.jpg  \n",
            "  inflating: shrub/test/image182.jpg  \n",
            "  inflating: shrub/test/image183.jpg  \n",
            "  inflating: shrub/test/image184.jpg  \n",
            "  inflating: shrub/test/image185.jpg  \n",
            "  inflating: shrub/test/image186.jpg  \n",
            "  inflating: shrub/test/image187.jpg  \n",
            "  inflating: shrub/test/image188.jpg  \n",
            "  inflating: shrub/test/image189.jpg  \n",
            "  inflating: shrub/test/image19.jpg  \n",
            "  inflating: shrub/test/image190.jpg  \n",
            "  inflating: shrub/test/image191.jpg  \n",
            "  inflating: shrub/test/image192.jpg  \n",
            "  inflating: shrub/test/image193.jpg  \n",
            "  inflating: shrub/test/image194.jpg  \n",
            "  inflating: shrub/test/image195.jpg  \n",
            "  inflating: shrub/test/image196.jpg  \n",
            "  inflating: shrub/test/image197.jpg  \n",
            "  inflating: shrub/test/image198.jpg  \n",
            "  inflating: shrub/test/image199.jpg  \n",
            "  inflating: shrub/test/image2.jpg   \n",
            "  inflating: shrub/test/image20.jpg  \n",
            "  inflating: shrub/test/image200.jpg  \n",
            "  inflating: shrub/test/image201.jpg  \n",
            "  inflating: shrub/test/image202.jpg  \n",
            "  inflating: shrub/test/image203.jpg  \n",
            "  inflating: shrub/test/image204.jpg  \n",
            "  inflating: shrub/test/image205.jpg  \n",
            "  inflating: shrub/test/image206.jpg  \n",
            "  inflating: shrub/test/image207.jpg  \n",
            "  inflating: shrub/test/image208.jpg  \n",
            "  inflating: shrub/test/image209.jpg  \n",
            "  inflating: shrub/test/image21.jpg  \n",
            "  inflating: shrub/test/image210.jpg  \n",
            "  inflating: shrub/test/image211.jpg  \n",
            "  inflating: shrub/test/image212.jpg  \n",
            "  inflating: shrub/test/image213.jpg  \n",
            "  inflating: shrub/test/image214.jpg  \n",
            "  inflating: shrub/test/image215.jpg  \n",
            "  inflating: shrub/test/image216.jpg  \n",
            "  inflating: shrub/test/image217.jpg  \n",
            "  inflating: shrub/test/image218.jpg  \n",
            "  inflating: shrub/test/image219.jpg  \n",
            "  inflating: shrub/test/image22.jpg  \n",
            "  inflating: shrub/test/image220.jpg  \n",
            "  inflating: shrub/test/image221.jpg  \n",
            "  inflating: shrub/test/image222.jpg  \n",
            "  inflating: shrub/test/image223.jpg  \n",
            "  inflating: shrub/test/image224.jpg  \n",
            "  inflating: shrub/test/image225.jpg  \n",
            "  inflating: shrub/test/image226.jpg  \n",
            "  inflating: shrub/test/image227.jpg  \n",
            "  inflating: shrub/test/image228.jpg  \n",
            "  inflating: shrub/test/image229.jpg  \n",
            "  inflating: shrub/test/image23.jpg  \n",
            "  inflating: shrub/test/image230.jpg  \n",
            "  inflating: shrub/test/image231.jpg  \n",
            "  inflating: shrub/test/image232.jpg  \n",
            "  inflating: shrub/test/image233.jpg  \n",
            "  inflating: shrub/test/image234.jpg  \n",
            "  inflating: shrub/test/image235.jpg  \n",
            "  inflating: shrub/test/image236.jpg  \n",
            "  inflating: shrub/test/image237.jpg  \n",
            "  inflating: shrub/test/image238.jpg  \n",
            "  inflating: shrub/test/image239.jpg  \n",
            "  inflating: shrub/test/image24.jpg  \n",
            "  inflating: shrub/test/image240.jpg  \n",
            "  inflating: shrub/test/image241.jpg  \n",
            "  inflating: shrub/test/image242.jpg  \n",
            "  inflating: shrub/test/image243.jpg  \n",
            "  inflating: shrub/test/image244.jpg  \n",
            "  inflating: shrub/test/image245.jpg  \n",
            "  inflating: shrub/test/image246.jpg  \n",
            "  inflating: shrub/test/image247.jpg  \n",
            "  inflating: shrub/test/image248.jpg  \n",
            "  inflating: shrub/test/image249.jpg  \n",
            "  inflating: shrub/test/image25.jpg  \n",
            "  inflating: shrub/test/image250.jpg  \n",
            "  inflating: shrub/test/image251.jpg  \n",
            "  inflating: shrub/test/image252.jpg  \n",
            "  inflating: shrub/test/image253.jpg  \n",
            "  inflating: shrub/test/image254.jpg  \n",
            "  inflating: shrub/test/image255.jpg  \n",
            "  inflating: shrub/test/image256.jpg  \n",
            "  inflating: shrub/test/image257.jpg  \n",
            "  inflating: shrub/test/image258.jpg  \n",
            "  inflating: shrub/test/image259.jpg  \n",
            "  inflating: shrub/test/image26.jpg  \n",
            "  inflating: shrub/test/image260.jpg  \n",
            "  inflating: shrub/test/image261.jpg  \n",
            "  inflating: shrub/test/image262.jpg  \n",
            "  inflating: shrub/test/image263.jpg  \n",
            "  inflating: shrub/test/image264.jpg  \n",
            "  inflating: shrub/test/image265.jpg  \n",
            "  inflating: shrub/test/image266.jpg  \n",
            "  inflating: shrub/test/image267.jpg  \n",
            "  inflating: shrub/test/image268.jpg  \n",
            "  inflating: shrub/test/image269.jpg  \n",
            "  inflating: shrub/test/image27.jpg  \n",
            "  inflating: shrub/test/image270.jpg  \n",
            "  inflating: shrub/test/image271.jpg  \n",
            "  inflating: shrub/test/image272.jpg  \n",
            "  inflating: shrub/test/image273.jpg  \n",
            "  inflating: shrub/test/image274.jpg  \n",
            "  inflating: shrub/test/image275.jpg  \n",
            "  inflating: shrub/test/image276.jpg  \n",
            "  inflating: shrub/test/image277.jpg  \n",
            "  inflating: shrub/test/image278.jpg  \n",
            "  inflating: shrub/test/image279.jpg  \n",
            "  inflating: shrub/test/image28.jpg  \n",
            "  inflating: shrub/test/image280.jpg  \n",
            "  inflating: shrub/test/image281.jpg  \n",
            "  inflating: shrub/test/image282.jpg  \n",
            "  inflating: shrub/test/image283.jpg  \n",
            "  inflating: shrub/test/image284.jpg  \n",
            "  inflating: shrub/test/image285.jpg  \n",
            "  inflating: shrub/test/image286.jpg  \n",
            "  inflating: shrub/test/image287.jpg  \n",
            "  inflating: shrub/test/image288.jpg  \n",
            "  inflating: shrub/test/image289.jpg  \n",
            "  inflating: shrub/test/image29.jpg  \n",
            "  inflating: shrub/test/image290.jpg  \n",
            "  inflating: shrub/test/image291.jpg  \n",
            "  inflating: shrub/test/image292.jpg  \n",
            "  inflating: shrub/test/image293.jpg  \n",
            "  inflating: shrub/test/image294.jpg  \n",
            "  inflating: shrub/test/image295.jpg  \n",
            "  inflating: shrub/test/image296.jpg  \n",
            "  inflating: shrub/test/image297.jpg  \n",
            "  inflating: shrub/test/image298.jpg  \n",
            "  inflating: shrub/test/image299.jpg  \n",
            "  inflating: shrub/test/image3.jpg   \n",
            "  inflating: shrub/test/image30.jpg  \n",
            "  inflating: shrub/test/image31.jpg  \n",
            "  inflating: shrub/test/image32.jpg  \n",
            "  inflating: shrub/test/image33.jpg  \n",
            "  inflating: shrub/test/image34.jpg  \n",
            "  inflating: shrub/test/image35.jpg  \n",
            "  inflating: shrub/test/image36.jpg  \n",
            "  inflating: shrub/test/image37.jpg  \n",
            "  inflating: shrub/test/image38.jpg  \n",
            "  inflating: shrub/test/image39.jpg  \n",
            "  inflating: shrub/test/image4.jpg   \n",
            "  inflating: shrub/test/image40.jpg  \n",
            "  inflating: shrub/test/image41.jpg  \n",
            "  inflating: shrub/test/image42.jpg  \n",
            "  inflating: shrub/test/image43.jpg  \n",
            "  inflating: shrub/test/image44.jpg  \n",
            "  inflating: shrub/test/image45.jpg  \n",
            "  inflating: shrub/test/image46.jpg  \n",
            "  inflating: shrub/test/image47.jpg  \n",
            "  inflating: shrub/test/image48.jpg  \n",
            "  inflating: shrub/test/image49.jpg  \n",
            "  inflating: shrub/test/image5.jpg   \n",
            "  inflating: shrub/test/image50.jpg  \n",
            "  inflating: shrub/test/image51.jpg  \n",
            "  inflating: shrub/test/image52.jpg  \n",
            "  inflating: shrub/test/image53.jpg  \n",
            "  inflating: shrub/test/image54.jpg  \n",
            "  inflating: shrub/test/image55.jpg  \n",
            "  inflating: shrub/test/image56.jpg  \n",
            "  inflating: shrub/test/image57.jpg  \n",
            "  inflating: shrub/test/image58.jpg  \n",
            "  inflating: shrub/test/image59.jpg  \n",
            "  inflating: shrub/test/image6.jpg   \n",
            "  inflating: shrub/test/image60.jpg  \n",
            "  inflating: shrub/test/image61.jpg  \n",
            "  inflating: shrub/test/image62.jpg  \n",
            "  inflating: shrub/test/image63.jpg  \n",
            "  inflating: shrub/test/image64.jpg  \n",
            "  inflating: shrub/test/image65.jpg  \n",
            "  inflating: shrub/test/image66.jpg  \n",
            "  inflating: shrub/test/image67.jpg  \n",
            "  inflating: shrub/test/image68.jpg  \n",
            "  inflating: shrub/test/image69.jpg  \n",
            "  inflating: shrub/test/image7.jpg   \n",
            "  inflating: shrub/test/image70.jpg  \n",
            "  inflating: shrub/test/image71.jpg  \n",
            "  inflating: shrub/test/image72.jpg  \n",
            "  inflating: shrub/test/image73.jpg  \n",
            "  inflating: shrub/test/image74.jpg  \n",
            "  inflating: shrub/test/image75.jpg  \n",
            "  inflating: shrub/test/image76.jpg  \n",
            "  inflating: shrub/test/image77.jpg  \n",
            "  inflating: shrub/test/image78.jpg  \n",
            "  inflating: shrub/test/image79.jpg  \n",
            "  inflating: shrub/test/image8.jpg   \n",
            "  inflating: shrub/test/image80.jpg  \n",
            "  inflating: shrub/test/image81.jpg  \n",
            "  inflating: shrub/test/image82.jpg  \n",
            "  inflating: shrub/test/image83.jpg  \n",
            "  inflating: shrub/test/image84.jpg  \n",
            "  inflating: shrub/test/image85.jpg  \n",
            "  inflating: shrub/test/image86.jpg  \n",
            "  inflating: shrub/test/image87.jpg  \n",
            "  inflating: shrub/test/image88.jpg  \n",
            "  inflating: shrub/test/image89.jpg  \n",
            "  inflating: shrub/test/image9.jpg   \n",
            "  inflating: shrub/test/image90.jpg  \n",
            "  inflating: shrub/test/image91.jpg  \n",
            "  inflating: shrub/test/image92.jpg  \n",
            "  inflating: shrub/test/image93.jpg  \n",
            "  inflating: shrub/test/image94.jpg  \n",
            "  inflating: shrub/test/image95.jpg  \n",
            "  inflating: shrub/test/image96.jpg  \n",
            "  inflating: shrub/test/image97.jpg  \n",
            "  inflating: shrub/test/image98.jpg  \n",
            "  inflating: shrub/test/image99.jpg  \n",
            "   creating: shrub/train/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCsKkEq0yGh0",
        "outputId": "9401a39d-5dcf-4985-e543-33e6d161109e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./shrub/                      \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: BtoA                          \t[default: AtoB]\n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: facades_pix2pix               \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: True                          \t[default: False]\n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/facades_pix2pix/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "-----------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkshitizkhanal7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.1 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/wandb/run-20220806_022830-5wfg45uj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfacades_pix2pix\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kshitizkhanal7/CycleGAN-and-pix2pix\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kshitizkhanal7/CycleGAN-and-pix2pix/runs/5wfg45uj\u001b[0m\n",
            "creating web directory ./results/facades_pix2pix/test_latest\n",
            "processing (0000)-th image... ['./shrub/test/image0.jpg']\n",
            "processing (0005)-th image... ['./shrub/test/image102.jpg']\n",
            "processing (0010)-th image... ['./shrub/test/image107.jpg']\n",
            "processing (0015)-th image... ['./shrub/test/image111.jpg']\n",
            "processing (0020)-th image... ['./shrub/test/image116.jpg']\n",
            "processing (0025)-th image... ['./shrub/test/image120.jpg']\n",
            "processing (0030)-th image... ['./shrub/test/image125.jpg']\n",
            "processing (0035)-th image... ['./shrub/test/image13.jpg']\n",
            "processing (0040)-th image... ['./shrub/test/image134.jpg']\n",
            "processing (0045)-th image... ['./shrub/test/image139.jpg']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfacades_pix2pix\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kshitizkhanal7/CycleGAN-and-pix2pix/runs/5wfg45uj\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 150 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220806_022830-5wfg45uj/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python test.py --dataroot ./shrub/ --direction BtoA --model pix2pix --name facades_pix2pix --use_wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r/content/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images"
      ],
      "metadata": {
        "id": "fhdHHnMw4Z1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSKIPUByfiN"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r test_shrub.zip /content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images"
      ],
      "metadata": {
        "id": "oFRtoqkLcErO",
        "outputId": "d8aa5427-db43-4619-eac2-68e979c5a107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/ (stored 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image114_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image123_real_B.png (deflated 29%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image119_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image104_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image127_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image132_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image1_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image126_real_B.png (deflated 29%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image10_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image125_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image122_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image138_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image129_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image133_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image14_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image112_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image100_fake_B.png (deflated 44%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image141_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image122_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image112_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image127_real_B.png (deflated 65%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image138_fake_B.png (deflated 44%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image110_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image142_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image116_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image135_fake_B.png (deflated 5%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image115_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image14_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image109_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image101_real_B.png (stored 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image10_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image108_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image128_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image117_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image118_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image120_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image141_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image108_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image119_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image138_real_B.png (deflated 42%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image104_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image125_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image123_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image11_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image136_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image133_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image126_fake_B.png (deflated 28%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image118_real_B.png (deflated 34%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image136_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image130_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image102_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image117_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image109_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image124_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image133_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image110_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image139_real_B.png (deflated 34%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image113_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image102_real_B.png (deflated 4%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image140_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image12_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image131_real_B.png (deflated 13%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image106_real_B.png (deflated 15%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image113_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image100_real_B.png (deflated 15%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image134_fake_B.png (deflated 47%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image121_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image134_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image136_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image139_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image122_real_B.png (deflated 6%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image12_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image107_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image135_real_B.png (deflated 24%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image118_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image140_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image132_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image120_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image115_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image103_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image106_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image101_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image123_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image13_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image0_real_B.png (deflated 72%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image111_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image103_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image131_fake_B.png (deflated 5%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image108_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image137_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image105_real_B.png (deflated 2%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image129_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image112_fake_B.png (deflated 2%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image116_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image127_fake_B.png (deflated 5%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image105_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image106_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image128_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image124_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image107_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image131_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image137_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image124_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image107_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image114_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image12_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image113_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image100_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image14_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image114_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image126_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image103_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image128_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image13_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image0_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image120_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image109_fake_B.png (deflated 13%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image110_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image141_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image104_real_B.png (deflated 15%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image139_fake_B.png (deflated 9%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image119_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image111_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image11_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image10_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image115_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image132_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image101_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image117_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image1_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image121_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image105_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image129_real_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image125_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image140_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image116_fake_B.png (deflated 58%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image130_real_B.png (deflated 13%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image137_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image111_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image135_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image13_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image11_fake_B.png (deflated 39%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image121_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image1_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image130_fake_B.png (deflated 1%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image142_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image102_real_A.png (deflated 0%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image134_real_B.png (deflated 20%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image0_fake_B.png (deflated 71%)\n",
            "  adding: content/pytorch-CycleGAN-and-pix2pix/pytorch-CycleGAN-and-pix2pix/results/facades_pix2pix/test_latest/images/image142_real_B.png (deflated 71%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G3oVH9DyqLQ"
      },
      "outputs": [],
      "source": [
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErK5OC1j1LH4"
      },
      "outputs": [],
      "source": [
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
        "plt.imshow(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "environment": {
      "name": "tf2-gpu.2-3.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}